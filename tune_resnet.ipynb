{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fde579-c955-4a16-a019-5ab53a8e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n",
    "from random import shuffle\n",
    "import datetime\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "051cfc09-6a01-4a20-ba55-d8ad7e7fc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f12c078-c191-4287-9704-f1ffca001cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# data_dir = pathlib.Path('E:/Users/sentinel_industry/downloaded_aois/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd5a4a4-fad7-449a-99c2-7f42e8090a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 230\n",
    "y_size = 230\n",
    "def load_features(name):\n",
    "    decoded = name.decode(\"UTF-8\")\n",
    "    if os.path.exists(decoded):\n",
    "        with open(decoded, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            label = tf.strings.split(tf.strings.split(name, '/')[-1], '\\\\')[-2]\n",
    "            if label == 'coal':\n",
    "                label = [1,0,0]\n",
    "            elif label == 'steel':\n",
    "                label = [0,1,0]\n",
    "            else: label = [0,0,1]\n",
    "            if (file[\"B02\"].shape[1]<230 or file[\"B02\"].shape[2]<230): \n",
    "                print(\"oh oh, downloaded patch too smol:\", decoded)\n",
    "            B02, B03, B04, B08 = file['B02'][0][0:x_size,0:y_size], file['B03'][0][0:x_size,0:y_size], file['B04'][0][0:x_size,0:y_size],file['B08'][0][0:x_size,0:y_size]\n",
    "            for channel in [ B02, B03, B04, B08]: channel = channel/channel.max()\n",
    "            features = np.array([ B02, B03, B04, B08]).transpose(1,2,0)\n",
    "            # features = np.expand_dims(features, axis=0)\n",
    "            return features, label\n",
    "            # I have commented the line below but this should return\n",
    "            # the features and the label in a one hot vector\n",
    "            # return file['features'], file['targets']\n",
    "    else:\n",
    "        print(\"Something went wrong!\")\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8d3b08-b09b-480d-8d8d-bf44131c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Users/sentinel_industry/downloaded_aois/coal/'\n",
    "\n",
    "pkl_files = glob.glob((path+\"*.pickle\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7def905d-f2c1-45f1-985c-aaf123860dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15f640f-7002-40d2-899a-21b4090c2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel = 'E:/Users/sentinel_industry/downloaded_aois/steel/'\n",
    "pkl_files_steel = glob.glob((path_steel+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5a78e7-514d-4f65-a831-57faa0c5df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/steel/no_ind/'\n",
    "pkl_files_steel_no_ind = glob.glob((path_steel_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076b0a09-9866-4fee-a244-2bd75892bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_coal_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/coal/no_ind/'\n",
    "pkl_files_coal_no_ind = glob.glob((path_coal_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da24ac7d-0f3f-4cfe-b518-fef29417d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files_steel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af872199-9192-48eb-8cea-9693c2291fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_files = pkl_files + pkl_files_steel + pkl_files_steel_no_ind + pkl_files_coal_no_ind\n",
    "shuffle(pkl_files)\n",
    "# pkl_files=pkl_files[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe3ca4f-ca84-4d80-9218-95fc89e8fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "\n",
    "# pkl_files = list(chain.from_iterable(zip(pkl_files, pkl_files_steel)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07182a88-11f4-4b7d-a461-4debb2944063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8077\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc46d5e-854e-42c6-af9c-97123ce4b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len=len(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e3f5d5-620d-4e9d-8abb-ecee1ba2dac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((pkl_files))\n",
    "\n",
    "def data_loader(filename):\n",
    "    features, labels = tf.numpy_function(load_features, [filename], [tf.uint16, tf.int32])\n",
    "    # features.set_shape((None, 242,242,4))\n",
    "    # labels.set_shape(( 1))\n",
    "    return features, labels\n",
    "\n",
    "dataset = dataset.map(data_loader)\n",
    "               # load_features, [filename], [tf.uint16, tf.string])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaadc4a-c328-4c33-b9b7-3d2e140f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle(100, seed=42)\n",
    "\n",
    "train_size = np.floor(0.8 * dataset_len)\n",
    "valid_size = np.floor(0.1 * dataset_len)\n",
    "test_size = np.floor(0.1 * dataset_len)\n",
    "\n",
    "train = dataset.take(train_size, )\n",
    "remaining = dataset.skip(train_size)\n",
    "valid = remaining.take(valid_size,\n",
    ")\n",
    "test = remaining.skip(valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f35197-11ee-40af-bc9c-c5181c99583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.shuffle(100,  reshuffle_each_iteration=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d6f7362-af28-45a7-b2a8-df8464e309a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b431c20b-995d-4d0f-969c-b0029d9652ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/new/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3d2ec65-044d-4736-b6c9-f4921a6d7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    in_seed = 42\n",
    "    c_crop = hp.Choice('center_crop', [200, 170, 140,120])\n",
    "    resize_rescale_augment = tf.keras.Sequential([\n",
    "        layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values,\n",
    "        layers.CenterCrop(c_crop,c_crop ),\n",
    "        layers.RandomCrop(120,120, seed=in_seed, input_shape=(x_size,y_size,4)),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "        # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "    ])\n",
    "    model = tf.keras.Sequential([\n",
    "        resize_rescale_augment,\n",
    "        layers.Conv2D(3, 5, padding='same', activation='relu'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                                # maybe try changing the source so it accepts 4 channels?\n",
    "        tf.keras.applications.resnet50.ResNet50(\n",
    "            include_top=False,\n",
    "            weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "            input_shape=(120, 120, 3),\n",
    "            pooling=max ,\n",
    "            classes=3,),\n",
    "        layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "        layers.Dense(3)\n",
    "    ])\n",
    "\n",
    "\n",
    "   \n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405fe90-2344-4c4b-abd6-a8d0c51d152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_4ch(hp):\n",
    "    in_seed = 42\n",
    "    resize_rescale_augment = tf.keras.Sequential([\n",
    "        layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values,\n",
    "        layers.CenterCrop(140,140 ),\n",
    "        layers.RandomCrop(120,120, seed=in_seed, input_shape=(x_size,y_size,4)),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "        # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "    ])\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        resize_rescale_augment,\n",
    "        layers.Conv2D(3, 5, padding='same', activation='relu'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                                # maybe try changing the source so it accepts 4 channels?\n",
    "        tf.keras.applications.resnet50.ResNet50(\n",
    "            include_top=False,\n",
    "            weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "            input_shape=(120, 120, 3),\n",
    "            pooling=max ,\n",
    "            classes=3,),\n",
    "        layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "        layers.Dense(3)\n",
    "    ])\n",
    "\n",
    "\n",
    "   \n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61a4893c-dc79-429a-9db4-07b6448b26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "080187fe-ffc5-4377-a03e-f9dedd1185e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [04h 40m 34s]\n",
      "val_loss: 0.6551841497421265\n",
      "\n",
      "Best val_loss So Far: 0.49662327766418457\n",
      "Total elapsed time: 18h 48m 50s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "batch_size = 20\n",
    "tuner.search( train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "             validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "            validation_steps=1,\n",
    "            overwrite=True,\n",
    "            epochs=epochs,\n",
    "            callbacks=[lr_callback])\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfa3fbdf-7066-43e7-96cc-659672e467d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters(num_trials=1)[0].get('center_crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5562cb60-b8d6-4768-8d53-b3b319dd6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "befec726-725f-4a3a-91cb-53edd07eb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !env LD_LIBRARY_PATH=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_LIBRARY_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_INCLUDE_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# # !set LD_INCLUDE_PATH=:/usr/local/cuda/include:/usr/local/cuda/extras/CUPTI/include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac0f2df1-a1c4-4256-8207-c604ecb682a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25928), started 4 days, 18:57:10 ago. (Use '!kill 25928' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-84b93297278968ea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-84b93297278968ea\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir='E:/Users/sentinel_industry/logs/train/new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be530648-e9dc-4672-8686-9370d346b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.8781 - categorical_accuracy: 0.5963"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "batch_size = 20\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb171cdb-c5d8-4f7d-b778-18aa7efc08bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e5265-142f-4b61-ab38-2cab5289760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90470b-a402-4948-9fe4-f57618c7d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=tf.compat.v1.data.make_one_shot_iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d64b-2ba7-4826-b54b-3d641f741a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    next_element = iterator.get_next()\n",
    "    im = resize_rescale_augment(next_element[0])\n",
    "    plt.imshow(np.flip(im[0,:,:,0:3], axis=2))\n",
    "    plt.title(convert_onehot(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21253b84-bc80-4976-8816-b49dee2293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onehot(next_element):\n",
    "    if (next_element[1].numpy() == np.array([0, 0, 1])).all(): return 'no industry'\n",
    "    elif (next_element[1].numpy() == np.array([0, 1, 0])).all(): return 'steel'\n",
    "    elif (next_element[1].numpy() == np.array([1, 0, 0])).all(): return 'coal'\n",
    "    else: return 'not valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f89dc-23ea-4317-a8ff-376357f954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_element[1].numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372a01e-8e19-45ee-a7fc-0a5540f19f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/path/to/file.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = foo\n",
    "spec.loader.exec_module(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6827d1-167e-47c0-ae4c-441f24174694",
   "metadata": {},
   "outputs": [],
   "source": [
    "! PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311393-972b-421b-b164-3f62c9effb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
