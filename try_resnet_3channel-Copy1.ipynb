{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fde579-c955-4a16-a019-5ab53a8e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n",
    "from random import shuffle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051cfc09-6a01-4a20-ba55-d8ad7e7fc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f12c078-c191-4287-9704-f1ffca001cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# data_dir = pathlib.Path('E:/Users/sentinel_industry/downloaded_aois/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd5a4a4-fad7-449a-99c2-7f42e8090a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_size = 230\n",
    "# y_size = 230\n",
    "# ch1_mean, ch1_std = 970.4162, 1051.8454\n",
    "# ch2_mean, ch2_std = 1176.249, 1031.262\n",
    "# ch3_mean, ch3_std = 1273.2376, 1117.068\n",
    "# ch4_mean, ch4_std = 2266.9050, 1241.5509\n",
    "# means = [ch1_mean,ch2_mean,ch3_mean,ch4_mean]\n",
    "# vari = [ch1_std, ch2_std, ch3_std, ch4_std]\n",
    "\n",
    "# def load_features(name):\n",
    "#     decoded = name.decode(\"UTF-8\")\n",
    "#     if os.path.exists(decoded):\n",
    "#         with open(decoded, 'rb') as f:\n",
    "#             file = pickle.load(f)\n",
    "#             label = tf.strings.split(tf.strings.split(name, '/')[-1], '\\\\')[-2]\n",
    "#             if label == 'coal':\n",
    "#                 label = [1,0,0]\n",
    "#             elif label == 'steel':\n",
    "#                 label = [0,1,0]\n",
    "#             else: label = [0,0,1]\n",
    "#             if (file[\"B02\"].shape[1]<230 or file[\"B02\"].shape[2]<230): \n",
    "#                 print(\"oh oh, downloaded patch too smol:\", decoded)\n",
    "#             B02, B03, B08 = file['B02'][0][0:x_size,0:y_size], file['B03'][0][0:x_size,0:y_size],file['B08'][0][0:x_size,0:y_size]\n",
    "#             B02 = (B02-ch1_mean)/ch1_std\n",
    "#             B03 = (B03-ch2_mean)/ch2_std\n",
    "#             # B04 = (B04-ch3_mean)/ch3_std\n",
    "#             B08 = (B08-ch4_mean)/ch4_std\n",
    "#             features = np.array([ B02, B03, B08]).transpose(1,2,0)\n",
    "#             # features = np.expand_dims(features, axis=0)\n",
    "#             return features, label\n",
    "#             # I have commented the line below but this should return\n",
    "#             # the features and the label in a one hot vector\n",
    "#             # return file['features'], file['targets']\n",
    "#     else:\n",
    "#         print(\"Something went wrong!\")\n",
    "#         exit(-1)\n",
    "        \n",
    "# def data_loader(filename):\n",
    "#     features, labels = tf.numpy_function(load_features, [filename], [tf.double, tf.int32])\n",
    "#     # features.set_shape((None, 242,242,4))\n",
    "#     # labels.set_shape(( 1))\n",
    "#     return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa310424-8b15-4830-a20c-cb8d335cd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ch1_mean, ch1_std = 970.4162, 1051.8454\n",
    "ch2_mean, ch2_std = 1176.249, 1031.262\n",
    "ch3_mean, ch3_std = 1273.2376, 1117.068\n",
    "ch4_mean, ch4_std = 2266.9050, 1241.5509\n",
    "means = [ch1_mean,ch2_mean,ch3_mean,ch4_mean]\n",
    "vari = [ch1_std, ch2_std, ch3_std, ch4_std]\n",
    "\n",
    "def load_features(name):\n",
    "    decoded = name.decode(\"UTF-8\")\n",
    "    if os.path.exists(decoded):\n",
    "        with open(decoded, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            label = tf.strings.split(tf.strings.split(name, '/')[-1], '\\\\')[-2]\n",
    "            if label == 'coal':\n",
    "                label = [1,0,0]\n",
    "            elif label == 'steel':\n",
    "                label = [0,1,0]\n",
    "            else: label = [0,0,1]\n",
    "            if (file[\"B02\"].shape[1]<230 or file[\"B02\"].shape[2]<230): \n",
    "                print(\"oh oh, downloaded patch too smol:\", decoded)\n",
    "            B02, B03, B04, B08 = file['B02'][0][0:x_size,0:y_size], file['B03'][0][0:x_size,0:y_size], file['B04'][0][0:x_size,0:y_size],file['B08'][0][0:x_size,0:y_size]\n",
    "            B02 = (B02-ch1_mean)/ch1_std\n",
    "            B03 = (B03-ch2_mean)/ch2_std\n",
    "            B04 = (B04-ch3_mean)/ch3_std\n",
    "            B08 = (B08-ch4_mean)/ch4_std\n",
    "            features = np.array([ B02, B03, B04, B08]).transpose(1,2,0)\n",
    "            # features = np.expand_dims(features, axis=0)\n",
    "            return features, label\n",
    "            # I have commented the line below but this should return\n",
    "            # the features and the label in a one hot vector\n",
    "            # return file['features'], file['targets']\n",
    "    else:\n",
    "        print(\"Something went wrong!\")\n",
    "        exit(-1)\n",
    "        \n",
    "def data_loader(filename):\n",
    "    features, labels = tf.numpy_function(load_features, [filename], [tf.double, tf.int32])\n",
    "    # features.set_shape((None, 242,242,4))\n",
    "    # labels.set_shape(( 1))\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8d3b08-b09b-480d-8d8d-bf44131c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Users/sentinel_industry/downloaded_aois/coal/'\n",
    "\n",
    "pkl_files = glob.glob((path+\"*.pickle\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7def905d-f2c1-45f1-985c-aaf123860dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2238\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15f640f-7002-40d2-899a-21b4090c2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel = 'E:/Users/sentinel_industry/downloaded_aois/steel/'\n",
    "pkl_files_steel = glob.glob((path_steel+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e5a78e7-514d-4f65-a831-57faa0c5df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/steel/no_ind/'\n",
    "pkl_files_steel_no_ind = glob.glob((path_steel_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "076b0a09-9866-4fee-a244-2bd75892bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_coal_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/coal/no_ind/'\n",
    "pkl_files_coal_no_ind = glob.glob((path_coal_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da24ac7d-0f3f-4cfe-b518-fef29417d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files_steel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af872199-9192-48eb-8cea-9693c2291fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_files = pkl_files + pkl_files_steel + pkl_files_steel_no_ind + pkl_files_coal_no_ind\n",
    "shuffle(pkl_files)\n",
    "# pkl_files=pkl_files[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfe3ca4f-ca84-4d80-9218-95fc89e8fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "\n",
    "# pkl_files = list(chain.from_iterable(zip(pkl_files, pkl_files_steel)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07182a88-11f4-4b7d-a461-4debb2944063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7966\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfc46d5e-854e-42c6-af9c-97123ce4b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len=len(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e3f5d5-620d-4e9d-8abb-ecee1ba2dac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((pkl_files))\n",
    "\n",
    "def data_loader(filename):\n",
    "    features, labels = tf.numpy_function(load_features, [filename], [tf.double, tf.int32])\n",
    "    # features.set_shape((None, 242,242,4))\n",
    "    # labels.set_shape(( 1))\n",
    "    return features, labels\n",
    "\n",
    "dataset = dataset.map(data_loader)\n",
    "               # load_features, [filename], [tf.uint16, tf.string])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adaadc4a-c328-4c33-b9b7-3d2e140f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len=len(pkl_files)\n",
    "\n",
    "train_size = int(np.floor(0.5 * dataset_len))\n",
    "valid_size = int(np.floor(0.5 * dataset_len))\n",
    "test_size = int(np.floor(0.0 * dataset_len))\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices(pkl_files[0:train_size]).map(data_loader,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "valid = tf.data.Dataset.from_tensor_slices(pkl_files[train_size:train_size+valid_size]).map(data_loader,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test = tf.data.Dataset.from_tensor_slices(pkl_files[train_size+valid_size:]).map(data_loader,num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80f35197-11ee-40af-bc9c-c5181c99583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.shuffle(100,  reshuffle_each_iteration=True, )\n",
    "valid = valid.shuffle(100,  reshuffle_each_iteration=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ac712-d2ef-43e7-bc46-cfda264dc190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb8f934b-2604-4cae-90e3-c805ebb2c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map((\n",
    "#   lambda x, y: (resize_and_rescale(x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31d628e-b02a-4e9a-b488-621dbd9c6f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1792\\2273428579.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in dataset:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d27b0ce3-1d0b-45b1-ae8b-2d93678fab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float64, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff9eae1f-d440-48fc-901e-214c9956fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch1_mean, ch1_std = 970.4162903392252, 1051.8454702994397\n",
    "# ch2_mean, ch2_std = 1176.249944943864, 1031.262597521539\n",
    "# # ch3_mean, ch3_std = 1273.2376818390699, 1117.068939085472\n",
    "# ch4_mean, ch4_std = 2266.9050137827385, 1241.5509461215606\n",
    "# norm_layer=keras.layers.Normalization(mean=[ch1_mean, ch2_mean, ch4_mean], variance=[ch1_std**2, ch2_std**2, ch4_std**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "676ae2c1-03cd-42bf-b40d-fe2926f9f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 230\n",
    "y_size = 230\n",
    "in_seed = 42\n",
    "resize_rescale_augment = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,3)),  # here, maybe try larger values\n",
    "    layers.CenterCrop(140,140, ),\n",
    "    layers.RandomCrop(120,120, seed=in_seed, ),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "    \n",
    "    # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "    # norm_layer,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3d2ec65-044d-4736-b6c9-f4921a6d7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     resize_rescale_augment,\n",
    "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(3)\n",
    "# ])\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    # layers.Conv2D(3, 5, padding='same', activation='relu'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=None ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/new/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.03)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "61a4893c-dc79-429a-9db4-07b6448b26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "080187fe-ffc5-4377-a03e-f9dedd1185e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_3 (Sequential)   (None, 120, 120, 3)       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,686,019\n",
      "Trainable params: 23,632,899\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5562cb60-b8d6-4768-8d53-b3b319dd6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "befec726-725f-4a3a-91cb-53edd07eb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !env LD_LIBRARY_PATH=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_LIBRARY_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_INCLUDE_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# # !set LD_INCLUDE_PATH=:/usr/local/cuda/include:/usr/local/cuda/extras/CUPTI/include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf8bd085-6960-4fd9-b181-a397dba92350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "env: â€˜LD_LIBRARY_PATHâ€™: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!env LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a9d77-970f-4a15-8b88-72e435b512de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac0f2df1-a1c4-4256-8207-c604ecb682a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22096), started 5:48:34 ago. (Use '!kill 22096' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-372b4332e586ea90\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-372b4332e586ea90\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir='E:/Users/sentinel_industry/logs/train/new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be530648-e9dc-4672-8686-9370d346b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "318/318 [==============================] - 197s 579ms/step - loss: 3.5475 - categorical_accuracy: 0.4912 - val_loss: 2.0789 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "318/318 [==============================] - 125s 388ms/step - loss: 1.2336 - categorical_accuracy: 0.6714 - val_loss: 2.0053 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "318/318 [==============================] - 123s 382ms/step - loss: 0.9123 - categorical_accuracy: 0.7000 - val_loss: 99.5648 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "318/318 [==============================] - 128s 396ms/step - loss: 0.9099 - categorical_accuracy: 0.6932 - val_loss: 0.6429 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "318/318 [==============================] - 123s 382ms/step - loss: 1.1077 - categorical_accuracy: 0.6263 - val_loss: 3.8628 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "318/318 [==============================] - 123s 383ms/step - loss: 0.8885 - categorical_accuracy: 0.6645 - val_loss: 0.9991 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "318/318 [==============================] - 126s 391ms/step - loss: 0.8025 - categorical_accuracy: 0.7014 - val_loss: 0.5946 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "318/318 [==============================] - 122s 380ms/step - loss: 0.8610 - categorical_accuracy: 0.6811 - val_loss: 3.5266 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "318/318 [==============================] - 122s 378ms/step - loss: 0.6967 - categorical_accuracy: 0.7311 - val_loss: 0.7160 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "318/318 [==============================] - 123s 383ms/step - loss: 0.6155 - categorical_accuracy: 0.7439 - val_loss: 0.5898 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "318/318 [==============================] - 129s 400ms/step - loss: 0.6063 - categorical_accuracy: 0.7549 - val_loss: 0.5549 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "318/318 [==============================] - 121s 376ms/step - loss: 0.8202 - categorical_accuracy: 0.6904 - val_loss: 0.7552 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "318/318 [==============================] - 120s 373ms/step - loss: 0.6493 - categorical_accuracy: 0.7314 - val_loss: 0.5560 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "318/318 [==============================] - 121s 376ms/step - loss: 0.7146 - categorical_accuracy: 0.7248 - val_loss: 17.2245 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "318/318 [==============================] - 120s 372ms/step - loss: 0.6200 - categorical_accuracy: 0.7520 - val_loss: 0.6096 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "318/318 [==============================] - 121s 375ms/step - loss: 0.6115 - categorical_accuracy: 0.7555 - val_loss: 0.4539 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "318/318 [==============================] - 120s 373ms/step - loss: 0.6126 - categorical_accuracy: 0.7546 - val_loss: 0.5401 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "318/318 [==============================] - 120s 371ms/step - loss: 0.6975 - categorical_accuracy: 0.7314 - val_loss: 10.5481 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "318/318 [==============================] - 119s 370ms/step - loss: 0.6486 - categorical_accuracy: 0.7431 - val_loss: 0.5910 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "318/318 [==============================] - 123s 382ms/step - loss: 0.6129 - categorical_accuracy: 0.7494 - val_loss: 0.5050 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "318/318 [==============================] - 128s 397ms/step - loss: 0.5676 - categorical_accuracy: 0.7706 - val_loss: 0.4417 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "318/318 [==============================] - 127s 393ms/step - loss: 0.5576 - categorical_accuracy: 0.7692 - val_loss: 0.4766 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "318/318 [==============================] - 119s 371ms/step - loss: 0.5657 - categorical_accuracy: 0.7693 - val_loss: 0.5612 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "318/318 [==============================] - 121s 375ms/step - loss: 0.5902 - categorical_accuracy: 0.7638 - val_loss: 0.5392 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "318/318 [==============================] - 120s 372ms/step - loss: 0.5679 - categorical_accuracy: 0.7752 - val_loss: 1.4930 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "318/318 [==============================] - 120s 372ms/step - loss: 0.6324 - categorical_accuracy: 0.7615 - val_loss: 4.3463 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "318/318 [==============================] - 119s 368ms/step - loss: 0.5484 - categorical_accuracy: 0.7789 - val_loss: 0.4900 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "318/318 [==============================] - 119s 368ms/step - loss: 0.5397 - categorical_accuracy: 0.7855 - val_loss: 0.4766 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "318/318 [==============================] - 126s 393ms/step - loss: 0.5188 - categorical_accuracy: 0.7873 - val_loss: 0.5159 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "318/318 [==============================] - 121s 375ms/step - loss: 0.8968 - categorical_accuracy: 0.6914 - val_loss: 10.7944 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "318/318 [==============================] - 119s 368ms/step - loss: 0.8289 - categorical_accuracy: 0.6239 - val_loss: 0.8186 - val_categorical_accuracy: 0.7500 - lr: 9.5123e-04\n",
      "Epoch 32/100\n",
      "318/318 [==============================] - 119s 371ms/step - loss: 0.7101 - categorical_accuracy: 0.6846 - val_loss: 0.8090 - val_categorical_accuracy: 0.7500 - lr: 9.0484e-04\n",
      "Epoch 33/100\n",
      "318/318 [==============================] - 124s 384ms/step - loss: 0.6821 - categorical_accuracy: 0.6936 - val_loss: 0.7123 - val_categorical_accuracy: 0.7000 - lr: 8.6071e-04\n",
      "Epoch 34/100\n",
      "318/318 [==============================] - 119s 371ms/step - loss: 0.6589 - categorical_accuracy: 0.7115 - val_loss: 0.9098 - val_categorical_accuracy: 0.6500 - lr: 8.1873e-04\n",
      "Epoch 35/100\n",
      "318/318 [==============================] - 120s 373ms/step - loss: 0.6175 - categorical_accuracy: 0.7305 - val_loss: 0.6082 - val_categorical_accuracy: 0.7500 - lr: 7.7880e-04\n",
      "Epoch 36/100\n",
      "318/318 [==============================] - 126s 391ms/step - loss: 0.6008 - categorical_accuracy: 0.7410 - val_loss: 0.5418 - val_categorical_accuracy: 0.7500 - lr: 7.4082e-04\n",
      "Epoch 37/100\n",
      "318/318 [==============================] - 120s 371ms/step - loss: 0.5988 - categorical_accuracy: 0.7481 - val_loss: 0.5623 - val_categorical_accuracy: 0.7500 - lr: 7.0469e-04\n",
      "Epoch 38/100\n",
      "318/318 [==============================] - 126s 391ms/step - loss: 0.5630 - categorical_accuracy: 0.7660 - val_loss: 0.5530 - val_categorical_accuracy: 0.7000 - lr: 6.7032e-04\n",
      "Epoch 39/100\n",
      "318/318 [==============================] - 120s 372ms/step - loss: 0.5596 - categorical_accuracy: 0.7664 - val_loss: 0.4768 - val_categorical_accuracy: 0.7500 - lr: 6.3763e-04\n",
      "Epoch 40/100\n",
      "318/318 [==============================] - 122s 380ms/step - loss: 0.5433 - categorical_accuracy: 0.7736 - val_loss: 0.5053 - val_categorical_accuracy: 0.7500 - lr: 6.0653e-04\n",
      "Epoch 41/100\n",
      "318/318 [==============================] - 122s 379ms/step - loss: 0.5290 - categorical_accuracy: 0.7791 - val_loss: 0.4980 - val_categorical_accuracy: 0.7500 - lr: 5.7695e-04\n",
      "Epoch 42/100\n",
      "318/318 [==============================] - 126s 393ms/step - loss: 0.5231 - categorical_accuracy: 0.7830 - val_loss: 0.4181 - val_categorical_accuracy: 0.8000 - lr: 5.4881e-04\n",
      "Epoch 43/100\n",
      "318/318 [==============================] - 123s 380ms/step - loss: 0.5268 - categorical_accuracy: 0.7825 - val_loss: 0.4256 - val_categorical_accuracy: 0.8000 - lr: 5.2205e-04\n",
      "Epoch 44/100\n",
      "318/318 [==============================] - 122s 380ms/step - loss: 0.5192 - categorical_accuracy: 0.7827 - val_loss: 0.4113 - val_categorical_accuracy: 0.8000 - lr: 4.9659e-04\n",
      "Epoch 45/100\n",
      "318/318 [==============================] - 131s 408ms/step - loss: 0.4994 - categorical_accuracy: 0.7991 - val_loss: 0.4503 - val_categorical_accuracy: 0.8500 - lr: 4.7237e-04\n",
      "Epoch 46/100\n",
      "318/318 [==============================] - 120s 373ms/step - loss: 0.4968 - categorical_accuracy: 0.7929 - val_loss: 0.3952 - val_categorical_accuracy: 0.8000 - lr: 4.4933e-04\n",
      "Epoch 47/100\n",
      "318/318 [==============================] - 121s 376ms/step - loss: 0.4850 - categorical_accuracy: 0.7969 - val_loss: 0.4881 - val_categorical_accuracy: 0.8000 - lr: 4.2742e-04\n",
      "Epoch 48/100\n",
      "318/318 [==============================] - 119s 371ms/step - loss: 0.4839 - categorical_accuracy: 0.8014 - val_loss: 0.4803 - val_categorical_accuracy: 0.8500 - lr: 4.0657e-04\n",
      "Epoch 49/100\n",
      "318/318 [==============================] - 121s 374ms/step - loss: 0.4886 - categorical_accuracy: 0.7961 - val_loss: 0.4543 - val_categorical_accuracy: 0.8500 - lr: 3.8674e-04\n",
      "Epoch 50/100\n",
      "318/318 [==============================] - 121s 376ms/step - loss: 0.4748 - categorical_accuracy: 0.8060 - val_loss: 0.4123 - val_categorical_accuracy: 0.8000 - lr: 3.6788e-04\n",
      "Epoch 51/100\n",
      "318/318 [==============================] - 120s 373ms/step - loss: 0.4703 - categorical_accuracy: 0.8031 - val_loss: 0.4930 - val_categorical_accuracy: 0.8000 - lr: 3.4994e-04\n",
      "Epoch 52/100\n",
      "318/318 [==============================] - 119s 369ms/step - loss: 0.4620 - categorical_accuracy: 0.8159 - val_loss: 0.5103 - val_categorical_accuracy: 0.8000 - lr: 3.3287e-04\n",
      "Epoch 53/100\n",
      "318/318 [==============================] - 120s 374ms/step - loss: 0.4517 - categorical_accuracy: 0.8167 - val_loss: 0.4183 - val_categorical_accuracy: 0.7500 - lr: 3.1664e-04\n",
      "Epoch 54/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.4531 - categorical_accuracy: 0.8156 - val_loss: 0.4230 - val_categorical_accuracy: 0.8500 - lr: 3.0119e-04\n",
      "Epoch 55/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.4434 - categorical_accuracy: 0.8170 - val_loss: 0.4673 - val_categorical_accuracy: 0.7500 - lr: 2.8651e-04\n",
      "Epoch 56/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.4331 - categorical_accuracy: 0.8237 - val_loss: 0.5066 - val_categorical_accuracy: 0.8500 - lr: 2.7253e-04\n",
      "Epoch 57/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.4406 - categorical_accuracy: 0.8222 - val_loss: 0.4464 - val_categorical_accuracy: 0.8500 - lr: 2.5924e-04\n",
      "Epoch 58/100\n",
      "318/318 [==============================] - 118s 367ms/step - loss: 0.4304 - categorical_accuracy: 0.8264 - val_loss: 0.4815 - val_categorical_accuracy: 0.8500 - lr: 2.4660e-04\n",
      "Epoch 59/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.4259 - categorical_accuracy: 0.8255 - val_loss: 0.4364 - val_categorical_accuracy: 0.8500 - lr: 2.3457e-04\n",
      "Epoch 60/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.4220 - categorical_accuracy: 0.8311 - val_loss: 0.3875 - val_categorical_accuracy: 0.7500 - lr: 2.2313e-04\n",
      "Epoch 61/100\n",
      "318/318 [==============================] - 119s 369ms/step - loss: 0.4171 - categorical_accuracy: 0.8283 - val_loss: 0.4129 - val_categorical_accuracy: 0.8000 - lr: 2.1225e-04\n",
      "Epoch 62/100\n",
      "318/318 [==============================] - 117s 364ms/step - loss: 0.4109 - categorical_accuracy: 0.8286 - val_loss: 0.4158 - val_categorical_accuracy: 0.8500 - lr: 2.0190e-04\n",
      "Epoch 63/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.4170 - categorical_accuracy: 0.8316 - val_loss: 0.3803 - val_categorical_accuracy: 0.8500 - lr: 1.9205e-04\n",
      "Epoch 64/100\n",
      "318/318 [==============================] - 117s 364ms/step - loss: 0.4007 - categorical_accuracy: 0.8358 - val_loss: 0.3524 - val_categorical_accuracy: 0.8500 - lr: 1.8268e-04\n",
      "Epoch 65/100\n",
      "318/318 [==============================] - 118s 367ms/step - loss: 0.4076 - categorical_accuracy: 0.8373 - val_loss: 0.5309 - val_categorical_accuracy: 0.8000 - lr: 1.7377e-04\n",
      "Epoch 66/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3960 - categorical_accuracy: 0.8385 - val_loss: 0.3349 - val_categorical_accuracy: 0.9000 - lr: 1.6530e-04\n",
      "Epoch 67/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.4078 - categorical_accuracy: 0.8330 - val_loss: 0.3452 - val_categorical_accuracy: 0.8500 - lr: 1.5724e-04\n",
      "Epoch 68/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3962 - categorical_accuracy: 0.8354 - val_loss: 0.4009 - val_categorical_accuracy: 0.8500 - lr: 1.4957e-04\n",
      "Epoch 69/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.3804 - categorical_accuracy: 0.8495 - val_loss: 0.3799 - val_categorical_accuracy: 0.8500 - lr: 1.4227e-04\n",
      "Epoch 70/100\n",
      "318/318 [==============================] - 117s 364ms/step - loss: 0.3764 - categorical_accuracy: 0.8538 - val_loss: 0.4227 - val_categorical_accuracy: 0.8000 - lr: 1.3534e-04\n",
      "Epoch 71/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3849 - categorical_accuracy: 0.8447 - val_loss: 0.3406 - val_categorical_accuracy: 0.8000 - lr: 1.2874e-04\n",
      "Epoch 72/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.3757 - categorical_accuracy: 0.8475 - val_loss: 0.4172 - val_categorical_accuracy: 0.8000 - lr: 1.2246e-04\n",
      "Epoch 73/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3604 - categorical_accuracy: 0.8547 - val_loss: 0.3951 - val_categorical_accuracy: 0.8500 - lr: 1.1648e-04\n",
      "Epoch 74/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.3669 - categorical_accuracy: 0.8524 - val_loss: 0.4334 - val_categorical_accuracy: 0.8000 - lr: 1.1080e-04\n",
      "Epoch 75/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3731 - categorical_accuracy: 0.8476 - val_loss: 0.3470 - val_categorical_accuracy: 0.8500 - lr: 1.0540e-04\n",
      "Epoch 76/100\n",
      "318/318 [==============================] - 118s 367ms/step - loss: 0.3564 - categorical_accuracy: 0.8586 - val_loss: 0.4248 - val_categorical_accuracy: 0.8000 - lr: 1.0026e-04\n",
      "Epoch 77/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.3623 - categorical_accuracy: 0.8533 - val_loss: 0.3676 - val_categorical_accuracy: 0.9000 - lr: 9.5369e-05\n",
      "Epoch 78/100\n",
      "318/318 [==============================] - 118s 367ms/step - loss: 0.3533 - categorical_accuracy: 0.8547 - val_loss: 0.4244 - val_categorical_accuracy: 0.8000 - lr: 9.0718e-05\n",
      "Epoch 79/100\n",
      "318/318 [==============================] - 117s 364ms/step - loss: 0.3559 - categorical_accuracy: 0.8568 - val_loss: 0.4313 - val_categorical_accuracy: 0.8500 - lr: 8.6294e-05\n",
      "Epoch 80/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.3486 - categorical_accuracy: 0.8593 - val_loss: 0.3921 - val_categorical_accuracy: 0.8500 - lr: 8.2085e-05\n",
      "Epoch 81/100\n",
      "318/318 [==============================] - 117s 365ms/step - loss: 0.3542 - categorical_accuracy: 0.8585 - val_loss: 0.3584 - val_categorical_accuracy: 0.8500 - lr: 7.8082e-05\n",
      "Epoch 82/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3609 - categorical_accuracy: 0.8544 - val_loss: 0.4106 - val_categorical_accuracy: 0.9000 - lr: 7.4274e-05\n",
      "Epoch 83/100\n",
      "318/318 [==============================] - 118s 365ms/step - loss: 0.3425 - categorical_accuracy: 0.8664 - val_loss: 0.3607 - val_categorical_accuracy: 0.8500 - lr: 7.0651e-05\n",
      "Epoch 84/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3485 - categorical_accuracy: 0.8621 - val_loss: 0.4188 - val_categorical_accuracy: 0.8000 - lr: 6.7206e-05\n",
      "Epoch 85/100\n",
      "318/318 [==============================] - 117s 364ms/step - loss: 0.3379 - categorical_accuracy: 0.8668 - val_loss: 0.3780 - val_categorical_accuracy: 0.8000 - lr: 6.3928e-05\n",
      "Epoch 86/100\n",
      "318/318 [==============================] - 119s 370ms/step - loss: 0.3358 - categorical_accuracy: 0.8656 - val_loss: 0.3350 - val_categorical_accuracy: 0.8500 - lr: 6.0810e-05\n",
      "Epoch 87/100\n",
      "318/318 [==============================] - 117s 363ms/step - loss: 0.3400 - categorical_accuracy: 0.8605 - val_loss: 0.3419 - val_categorical_accuracy: 0.8000 - lr: 5.7844e-05\n",
      "Epoch 88/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3423 - categorical_accuracy: 0.8599 - val_loss: 0.4311 - val_categorical_accuracy: 0.7500 - lr: 5.5023e-05\n",
      "Epoch 89/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3359 - categorical_accuracy: 0.8651 - val_loss: 0.3356 - val_categorical_accuracy: 0.8000 - lr: 5.2340e-05\n",
      "Epoch 90/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3359 - categorical_accuracy: 0.8624 - val_loss: 0.3930 - val_categorical_accuracy: 0.8500 - lr: 4.9787e-05\n",
      "Epoch 91/100\n",
      "318/318 [==============================] - 119s 370ms/step - loss: 0.3296 - categorical_accuracy: 0.8682 - val_loss: 0.3614 - val_categorical_accuracy: 0.8500 - lr: 4.7359e-05\n",
      "Epoch 92/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3284 - categorical_accuracy: 0.8753 - val_loss: 0.3479 - val_categorical_accuracy: 0.8500 - lr: 4.5049e-05\n",
      "Epoch 93/100\n",
      "318/318 [==============================] - 118s 367ms/step - loss: 0.3211 - categorical_accuracy: 0.8739 - val_loss: 0.3755 - val_categorical_accuracy: 0.8500 - lr: 4.2852e-05\n",
      "Epoch 94/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3403 - categorical_accuracy: 0.8631 - val_loss: 0.3446 - val_categorical_accuracy: 0.8000 - lr: 4.0762e-05\n",
      "Epoch 95/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3334 - categorical_accuracy: 0.8690 - val_loss: 0.3765 - val_categorical_accuracy: 0.8000 - lr: 3.8774e-05\n",
      "Epoch 96/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3136 - categorical_accuracy: 0.8742 - val_loss: 0.3545 - val_categorical_accuracy: 0.8500 - lr: 3.6883e-05\n",
      "Epoch 97/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3171 - categorical_accuracy: 0.8734 - val_loss: 0.3400 - val_categorical_accuracy: 0.8500 - lr: 3.5084e-05\n",
      "Epoch 98/100\n",
      "318/318 [==============================] - 117s 365ms/step - loss: 0.3190 - categorical_accuracy: 0.8755 - val_loss: 0.3216 - val_categorical_accuracy: 0.8000 - lr: 3.3373e-05\n",
      "Epoch 99/100\n",
      "318/318 [==============================] - 118s 366ms/step - loss: 0.3279 - categorical_accuracy: 0.8706 - val_loss: 0.3908 - val_categorical_accuracy: 0.8000 - lr: 3.1746e-05\n",
      "Epoch 100/100\n",
      "318/318 [==============================] - 117s 363ms/step - loss: 0.3217 - categorical_accuracy: 0.8745 - val_loss: 0.3679 - val_categorical_accuracy: 0.8000 - lr: 3.0197e-05\n"
     ]
    }
   ],
   "source": [
    "# now with 3ch only\n",
    "epochs=100\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb171cdb-c5d8-4f7d-b778-18aa7efc08bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 4, 4, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,663,410\n",
      "Trainable params: 23,617,970\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "99/99 [==============================] - 150s 1s/step - loss: 1.8369 - categorical_accuracy: 0.5616 - val_loss: 2380.9944 - val_categorical_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "99/99 [==============================] - 90s 895ms/step - loss: 1.5255 - categorical_accuracy: 0.6386 - val_loss: 1406.6564 - val_categorical_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "99/99 [==============================] - 79s 785ms/step - loss: 1.4504 - categorical_accuracy: 0.6169 - val_loss: 342.0109 - val_categorical_accuracy: 0.5400 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "99/99 [==============================] - 120s 1s/step - loss: 0.9950 - categorical_accuracy: 0.6679 - val_loss: 27.2263 - val_categorical_accuracy: 0.6600 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "99/99 [==============================] - 79s 781ms/step - loss: 0.7958 - categorical_accuracy: 0.7086 - val_loss: 0.9850 - val_categorical_accuracy: 0.6425 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "99/99 [==============================] - 78s 770ms/step - loss: 0.8418 - categorical_accuracy: 0.6866 - val_loss: 867.3106 - val_categorical_accuracy: 0.4425 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "99/99 [==============================] - 84s 830ms/step - loss: 0.9843 - categorical_accuracy: 0.6669 - val_loss: 36.4941 - val_categorical_accuracy: 0.6050 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "99/99 [==============================] - 83s 821ms/step - loss: 0.9127 - categorical_accuracy: 0.6972 - val_loss: 30.4548 - val_categorical_accuracy: 0.6575 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "99/99 [==============================] - 81s 806ms/step - loss: 0.6858 - categorical_accuracy: 0.7278 - val_loss: 0.6517 - val_categorical_accuracy: 0.7350 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "99/99 [==============================] - 83s 820ms/step - loss: 1.0490 - categorical_accuracy: 0.6962 - val_loss: 0.5666 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "99/99 [==============================] - 83s 826ms/step - loss: 1.1278 - categorical_accuracy: 0.6955 - val_loss: 0.7227 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "99/99 [==============================] - 83s 822ms/step - loss: 0.8028 - categorical_accuracy: 0.7316 - val_loss: 0.6986 - val_categorical_accuracy: 0.6975 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "99/99 [==============================] - 91s 909ms/step - loss: 0.6261 - categorical_accuracy: 0.7495 - val_loss: 0.5592 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "99/99 [==============================] - 80s 791ms/step - loss: 0.5823 - categorical_accuracy: 0.7604 - val_loss: 0.5760 - val_categorical_accuracy: 0.7375 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "99/99 [==============================] - 80s 791ms/step - loss: 0.5749 - categorical_accuracy: 0.7652 - val_loss: 0.5440 - val_categorical_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "99/99 [==============================] - 80s 792ms/step - loss: 0.5688 - categorical_accuracy: 0.7626 - val_loss: 0.5282 - val_categorical_accuracy: 0.7675 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "99/99 [==============================] - 99s 986ms/step - loss: 0.5692 - categorical_accuracy: 0.7697 - val_loss: 0.6806 - val_categorical_accuracy: 0.7625 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "99/99 [==============================] - 91s 900ms/step - loss: 0.5622 - categorical_accuracy: 0.7727 - val_loss: 0.5555 - val_categorical_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "99/99 [==============================] - 80s 796ms/step - loss: 0.5431 - categorical_accuracy: 0.7712 - val_loss: 0.4664 - val_categorical_accuracy: 0.8025 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "99/99 [==============================] - 80s 798ms/step - loss: 0.5384 - categorical_accuracy: 0.7758 - val_loss: 0.4699 - val_categorical_accuracy: 0.8075 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "99/99 [==============================] - 102s 1s/step - loss: 0.5428 - categorical_accuracy: 0.7689 - val_loss: 0.4952 - val_categorical_accuracy: 0.7850 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "99/99 [==============================] - 90s 892ms/step - loss: 0.5571 - categorical_accuracy: 0.7780 - val_loss: 53.9383 - val_categorical_accuracy: 0.5825 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "99/99 [==============================] - 95s 944ms/step - loss: 0.5354 - categorical_accuracy: 0.7823 - val_loss: 0.5780 - val_categorical_accuracy: 0.7475 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "99/99 [==============================] - 80s 797ms/step - loss: 0.5106 - categorical_accuracy: 0.7886 - val_loss: 0.4935 - val_categorical_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "99/99 [==============================] - 80s 792ms/step - loss: 0.5117 - categorical_accuracy: 0.7874 - val_loss: 0.4449 - val_categorical_accuracy: 0.8025 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "99/99 [==============================] - 80s 790ms/step - loss: 0.5166 - categorical_accuracy: 0.7912 - val_loss: 0.4961 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "99/99 [==============================] - 80s 789ms/step - loss: 0.5200 - categorical_accuracy: 0.7838 - val_loss: 0.4685 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "99/99 [==============================] - 90s 892ms/step - loss: 0.5033 - categorical_accuracy: 0.7874 - val_loss: 0.4696 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "99/99 [==============================] - 80s 791ms/step - loss: 0.5258 - categorical_accuracy: 0.7859 - val_loss: 0.4412 - val_categorical_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "99/99 [==============================] - 80s 791ms/step - loss: 0.5933 - categorical_accuracy: 0.7783 - val_loss: 1.4097 - val_categorical_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "99/99 [==============================] - 113s 1s/step - loss: 0.6105 - categorical_accuracy: 0.7659 - val_loss: 0.5221 - val_categorical_accuracy: 0.7800 - lr: 9.7045e-04\n",
      "Epoch 32/150\n",
      "99/99 [==============================] - 93s 929ms/step - loss: 0.5181 - categorical_accuracy: 0.7864 - val_loss: 0.5502 - val_categorical_accuracy: 0.7600 - lr: 9.4176e-04\n",
      "Epoch 33/150\n",
      "99/99 [==============================] - 119s 1s/step - loss: 0.5049 - categorical_accuracy: 0.7944 - val_loss: 0.6885 - val_categorical_accuracy: 0.6950 - lr: 9.1393e-04\n",
      "Epoch 34/150\n",
      "99/99 [==============================] - 90s 892ms/step - loss: 0.4821 - categorical_accuracy: 0.8149 - val_loss: 0.4089 - val_categorical_accuracy: 0.8125 - lr: 8.8692e-04\n",
      "Epoch 35/150\n",
      "99/99 [==============================] - 119s 1s/step - loss: 0.4879 - categorical_accuracy: 0.8023 - val_loss: 0.4325 - val_categorical_accuracy: 0.8175 - lr: 8.6071e-04\n",
      "Epoch 36/150\n",
      "99/99 [==============================] - 98s 929ms/step - loss: 0.4722 - categorical_accuracy: 0.8040 - val_loss: 0.4565 - val_categorical_accuracy: 0.8025 - lr: 8.3527e-04\n",
      "Epoch 37/150\n",
      "99/99 [==============================] - 108s 1s/step - loss: 0.4669 - categorical_accuracy: 0.8104 - val_loss: 0.4222 - val_categorical_accuracy: 0.8225 - lr: 8.1058e-04\n",
      "Epoch 38/150\n",
      "99/99 [==============================] - 91s 886ms/step - loss: 0.4645 - categorical_accuracy: 0.8098 - val_loss: 0.5175 - val_categorical_accuracy: 0.7700 - lr: 7.8663e-04\n",
      "Epoch 39/150\n",
      "99/99 [==============================] - 79s 785ms/step - loss: 0.4633 - categorical_accuracy: 0.8134 - val_loss: 0.3866 - val_categorical_accuracy: 0.8250 - lr: 7.6338e-04\n",
      "Epoch 40/150\n",
      "99/99 [==============================] - 82s 814ms/step - loss: 0.4653 - categorical_accuracy: 0.8111 - val_loss: 0.4249 - val_categorical_accuracy: 0.8025 - lr: 7.4082e-04\n",
      "Epoch 41/150\n",
      "99/99 [==============================] - 82s 811ms/step - loss: 0.4607 - categorical_accuracy: 0.8179 - val_loss: 0.4058 - val_categorical_accuracy: 0.8250 - lr: 7.1892e-04\n",
      "Epoch 42/150\n",
      "99/99 [==============================] - 86s 832ms/step - loss: 0.4572 - categorical_accuracy: 0.8043 - val_loss: 0.4394 - val_categorical_accuracy: 0.8075 - lr: 6.9768e-04\n",
      "Epoch 43/150\n",
      "99/99 [==============================] - 79s 783ms/step - loss: 0.4618 - categorical_accuracy: 0.8136 - val_loss: 7.8140 - val_categorical_accuracy: 0.7500 - lr: 6.7706e-04\n",
      "Epoch 44/150\n",
      "99/99 [==============================] - 132s 1s/step - loss: 0.5079 - categorical_accuracy: 0.7970 - val_loss: 0.4524 - val_categorical_accuracy: 0.8050 - lr: 6.5705e-04\n",
      "Epoch 45/150\n",
      "99/99 [==============================] - 134s 1s/step - loss: 0.4859 - categorical_accuracy: 0.8053 - val_loss: 0.7125 - val_categorical_accuracy: 0.6900 - lr: 6.3763e-04\n",
      "Epoch 46/150\n",
      "99/99 [==============================] - 83s 825ms/step - loss: 0.5008 - categorical_accuracy: 0.8040 - val_loss: 0.5328 - val_categorical_accuracy: 0.7450 - lr: 6.1878e-04\n",
      "Epoch 47/150\n",
      "99/99 [==============================] - 86s 858ms/step - loss: 0.6455 - categorical_accuracy: 0.7566 - val_loss: 1.2901 - val_categorical_accuracy: 0.7100 - lr: 6.0050e-04\n",
      "Epoch 48/150\n",
      "99/99 [==============================] - 89s 882ms/step - loss: 0.5266 - categorical_accuracy: 0.7891 - val_loss: 0.4434 - val_categorical_accuracy: 0.8175 - lr: 5.8275e-04\n",
      "Epoch 49/150\n",
      "99/99 [==============================] - 80s 793ms/step - loss: 0.5158 - categorical_accuracy: 0.8000 - val_loss: 0.7886 - val_categorical_accuracy: 0.7475 - lr: 5.6553e-04\n",
      "Epoch 50/150\n",
      "99/99 [==============================] - 81s 802ms/step - loss: 0.4796 - categorical_accuracy: 0.8088 - val_loss: 0.6668 - val_categorical_accuracy: 0.7625 - lr: 5.4881e-04\n",
      "Epoch 51/150\n",
      "99/99 [==============================] - 82s 815ms/step - loss: 0.4829 - categorical_accuracy: 0.8091 - val_loss: 2.6687 - val_categorical_accuracy: 0.7025 - lr: 5.3259e-04\n",
      "Epoch 52/150\n",
      "99/99 [==============================] - 98s 974ms/step - loss: 0.4709 - categorical_accuracy: 0.8051 - val_loss: 0.5037 - val_categorical_accuracy: 0.7775 - lr: 5.1685e-04\n",
      "Epoch 53/150\n",
      "99/99 [==============================] - 88s 879ms/step - loss: 0.4417 - categorical_accuracy: 0.8202 - val_loss: 0.5337 - val_categorical_accuracy: 0.7700 - lr: 5.0158e-04\n",
      "Epoch 54/150\n",
      "99/99 [==============================] - 80s 790ms/step - loss: 0.4360 - categorical_accuracy: 0.8222 - val_loss: 0.4680 - val_categorical_accuracy: 0.8375 - lr: 4.8675e-04\n",
      "Epoch 55/150\n",
      "99/99 [==============================] - 80s 794ms/step - loss: 0.4373 - categorical_accuracy: 0.8295 - val_loss: 0.4559 - val_categorical_accuracy: 0.8100 - lr: 4.7237e-04\n",
      "Epoch 56/150\n",
      "99/99 [==============================] - 80s 791ms/step - loss: 0.4187 - categorical_accuracy: 0.8280 - val_loss: 0.4054 - val_categorical_accuracy: 0.8250 - lr: 4.5841e-04\n",
      "Epoch 57/150\n",
      "99/99 [==============================] - 81s 800ms/step - loss: 0.4196 - categorical_accuracy: 0.8301 - val_loss: 0.4143 - val_categorical_accuracy: 0.8075 - lr: 4.4486e-04\n",
      "Epoch 58/150\n",
      "99/99 [==============================] - 82s 816ms/step - loss: 0.4130 - categorical_accuracy: 0.8318 - val_loss: 0.5014 - val_categorical_accuracy: 0.8025 - lr: 4.3171e-04\n",
      "Epoch 59/150\n",
      "99/99 [==============================] - 86s 856ms/step - loss: 0.4134 - categorical_accuracy: 0.8255 - val_loss: 0.4703 - val_categorical_accuracy: 0.8125 - lr: 4.1895e-04\n",
      "Epoch 60/150\n",
      "99/99 [==============================] - 81s 806ms/step - loss: 0.4248 - categorical_accuracy: 0.8253 - val_loss: 0.4129 - val_categorical_accuracy: 0.8250 - lr: 4.0657e-04\n",
      "Epoch 61/150\n",
      "99/99 [==============================] - 82s 813ms/step - loss: 0.4032 - categorical_accuracy: 0.8326 - val_loss: 0.3761 - val_categorical_accuracy: 0.8500 - lr: 3.9455e-04\n",
      "Epoch 62/150\n",
      "99/99 [==============================] - 81s 807ms/step - loss: 0.4005 - categorical_accuracy: 0.8369 - val_loss: 0.5146 - val_categorical_accuracy: 0.8075 - lr: 3.8289e-04\n",
      "Epoch 63/150\n",
      "99/99 [==============================] - 82s 813ms/step - loss: 0.3974 - categorical_accuracy: 0.8361 - val_loss: 0.3655 - val_categorical_accuracy: 0.8350 - lr: 3.7158e-04\n",
      "Epoch 64/150\n",
      "99/99 [==============================] - 81s 804ms/step - loss: 0.3935 - categorical_accuracy: 0.8404 - val_loss: 0.5372 - val_categorical_accuracy: 0.7975 - lr: 3.6060e-04\n",
      "Epoch 65/150\n",
      "99/99 [==============================] - 82s 815ms/step - loss: 0.3883 - categorical_accuracy: 0.8422 - val_loss: 0.4097 - val_categorical_accuracy: 0.8150 - lr: 3.4994e-04\n",
      "Epoch 66/150\n",
      "99/99 [==============================] - 82s 812ms/step - loss: 0.4070 - categorical_accuracy: 0.8346 - val_loss: 0.4398 - val_categorical_accuracy: 0.7775 - lr: 3.3960e-04\n",
      "Epoch 67/150\n",
      "99/99 [==============================] - 82s 816ms/step - loss: 0.3676 - categorical_accuracy: 0.8487 - val_loss: 0.4444 - val_categorical_accuracy: 0.7950 - lr: 3.2956e-04\n",
      "Epoch 68/150\n",
      "99/99 [==============================] - 82s 811ms/step - loss: 0.3711 - categorical_accuracy: 0.8465 - val_loss: 0.3895 - val_categorical_accuracy: 0.8425 - lr: 3.1982e-04\n",
      "Epoch 69/150\n",
      "99/99 [==============================] - 86s 849ms/step - loss: 0.3908 - categorical_accuracy: 0.8366 - val_loss: 0.4056 - val_categorical_accuracy: 0.8300 - lr: 3.1037e-04\n",
      "Epoch 70/150\n",
      "99/99 [==============================] - 86s 849ms/step - loss: 0.3759 - categorical_accuracy: 0.8457 - val_loss: 0.3806 - val_categorical_accuracy: 0.8300 - lr: 3.0119e-04\n",
      "Epoch 71/150\n",
      "99/99 [==============================] - 86s 849ms/step - loss: 0.3745 - categorical_accuracy: 0.8465 - val_loss: 0.3437 - val_categorical_accuracy: 0.8550 - lr: 2.9229e-04\n",
      "Epoch 72/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.3757 - categorical_accuracy: 0.8444 - val_loss: 0.3959 - val_categorical_accuracy: 0.8350 - lr: 2.8365e-04\n",
      "Epoch 73/150\n",
      "99/99 [==============================] - 87s 863ms/step - loss: 0.3639 - categorical_accuracy: 0.8505 - val_loss: 0.4080 - val_categorical_accuracy: 0.8225 - lr: 2.7527e-04\n",
      "Epoch 74/150\n",
      "99/99 [==============================] - 87s 858ms/step - loss: 0.3562 - categorical_accuracy: 0.8548 - val_loss: 0.3773 - val_categorical_accuracy: 0.8275 - lr: 2.6714e-04\n",
      "Epoch 75/150\n",
      "99/99 [==============================] - 87s 860ms/step - loss: 0.3667 - categorical_accuracy: 0.8497 - val_loss: 0.4070 - val_categorical_accuracy: 0.8300 - lr: 2.5924e-04\n",
      "Epoch 76/150\n",
      "99/99 [==============================] - 84s 835ms/step - loss: 0.3507 - categorical_accuracy: 0.8593 - val_loss: 0.3537 - val_categorical_accuracy: 0.8550 - lr: 2.5158e-04\n",
      "Epoch 77/150\n",
      "99/99 [==============================] - 86s 859ms/step - loss: 0.3423 - categorical_accuracy: 0.8641 - val_loss: 0.3626 - val_categorical_accuracy: 0.8500 - lr: 2.4414e-04\n",
      "Epoch 78/150\n",
      "99/99 [==============================] - 87s 862ms/step - loss: 0.3379 - categorical_accuracy: 0.8611 - val_loss: 0.4455 - val_categorical_accuracy: 0.8200 - lr: 2.3693e-04\n",
      "Epoch 79/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.3526 - categorical_accuracy: 0.8563 - val_loss: 0.4382 - val_categorical_accuracy: 0.7950 - lr: 2.2993e-04\n",
      "Epoch 80/150\n",
      "99/99 [==============================] - 86s 858ms/step - loss: 0.3392 - categorical_accuracy: 0.8598 - val_loss: 0.4207 - val_categorical_accuracy: 0.8325 - lr: 2.2313e-04\n",
      "Epoch 81/150\n",
      "99/99 [==============================] - 85s 845ms/step - loss: 0.3394 - categorical_accuracy: 0.8644 - val_loss: 0.4358 - val_categorical_accuracy: 0.8125 - lr: 2.1654e-04\n",
      "Epoch 82/150\n",
      "99/99 [==============================] - 87s 859ms/step - loss: 0.3273 - categorical_accuracy: 0.8717 - val_loss: 0.3692 - val_categorical_accuracy: 0.8600 - lr: 2.1014e-04\n",
      "Epoch 83/150\n",
      "99/99 [==============================] - 86s 855ms/step - loss: 0.3331 - categorical_accuracy: 0.8699 - val_loss: 0.3682 - val_categorical_accuracy: 0.8275 - lr: 2.0393e-04\n",
      "Epoch 84/150\n",
      "99/99 [==============================] - 99s 977ms/step - loss: 0.3324 - categorical_accuracy: 0.8694 - val_loss: 0.3738 - val_categorical_accuracy: 0.8400 - lr: 1.9790e-04\n",
      "Epoch 85/150\n",
      "99/99 [==============================] - 87s 865ms/step - loss: 0.3282 - categorical_accuracy: 0.8682 - val_loss: 0.4505 - val_categorical_accuracy: 0.8100 - lr: 1.9205e-04\n",
      "Epoch 86/150\n",
      "99/99 [==============================] - 86s 853ms/step - loss: 0.3203 - categorical_accuracy: 0.8692 - val_loss: 0.4209 - val_categorical_accuracy: 0.8250 - lr: 1.8637e-04\n",
      "Epoch 87/150\n",
      "99/99 [==============================] - 84s 837ms/step - loss: 0.3159 - categorical_accuracy: 0.8775 - val_loss: 0.4290 - val_categorical_accuracy: 0.8300 - lr: 1.8087e-04\n",
      "Epoch 88/150\n",
      "99/99 [==============================] - 86s 851ms/step - loss: 0.3158 - categorical_accuracy: 0.8707 - val_loss: 0.3804 - val_categorical_accuracy: 0.8550 - lr: 1.7552e-04\n",
      "Epoch 89/150\n",
      "99/99 [==============================] - 85s 846ms/step - loss: 0.3114 - categorical_accuracy: 0.8811 - val_loss: 0.3519 - val_categorical_accuracy: 0.8725 - lr: 1.7033e-04\n",
      "Epoch 90/150\n",
      "99/99 [==============================] - 85s 844ms/step - loss: 0.3174 - categorical_accuracy: 0.8753 - val_loss: 0.3585 - val_categorical_accuracy: 0.8650 - lr: 1.6530e-04\n",
      "Epoch 91/150\n",
      "99/99 [==============================] - 85s 848ms/step - loss: 0.2990 - categorical_accuracy: 0.8780 - val_loss: 0.4571 - val_categorical_accuracy: 0.8125 - lr: 1.6041e-04\n",
      "Epoch 92/150\n",
      "99/99 [==============================] - 84s 836ms/step - loss: 0.3032 - categorical_accuracy: 0.8793 - val_loss: 0.4075 - val_categorical_accuracy: 0.8300 - lr: 1.5567e-04\n",
      "Epoch 93/150\n",
      "99/99 [==============================] - 86s 854ms/step - loss: 0.3095 - categorical_accuracy: 0.8747 - val_loss: 0.3880 - val_categorical_accuracy: 0.8350 - lr: 1.5107e-04\n",
      "Epoch 94/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.3031 - categorical_accuracy: 0.8826 - val_loss: 0.3721 - val_categorical_accuracy: 0.8625 - lr: 1.4661e-04\n",
      "Epoch 95/150\n",
      "99/99 [==============================] - 86s 851ms/step - loss: 0.2983 - categorical_accuracy: 0.8795 - val_loss: 0.3924 - val_categorical_accuracy: 0.8500 - lr: 1.4227e-04\n",
      "Epoch 96/150\n",
      "99/99 [==============================] - 85s 844ms/step - loss: 0.3021 - categorical_accuracy: 0.8801 - val_loss: 0.3992 - val_categorical_accuracy: 0.8350 - lr: 1.3807e-04\n",
      "Epoch 97/150\n",
      "99/99 [==============================] - 84s 839ms/step - loss: 0.2909 - categorical_accuracy: 0.8836 - val_loss: 0.3696 - val_categorical_accuracy: 0.8625 - lr: 1.3399e-04\n",
      "Epoch 98/150\n",
      "99/99 [==============================] - 85s 845ms/step - loss: 0.2945 - categorical_accuracy: 0.8831 - val_loss: 0.3904 - val_categorical_accuracy: 0.8450 - lr: 1.3003e-04\n",
      "Epoch 99/150\n",
      "99/99 [==============================] - 86s 852ms/step - loss: 0.2925 - categorical_accuracy: 0.8851 - val_loss: 0.4047 - val_categorical_accuracy: 0.8525 - lr: 1.2619e-04\n",
      "Epoch 100/150\n",
      "99/99 [==============================] - 85s 843ms/step - loss: 0.2868 - categorical_accuracy: 0.8854 - val_loss: 0.3734 - val_categorical_accuracy: 0.8525 - lr: 1.2246e-04\n",
      "Epoch 101/150\n",
      "99/99 [==============================] - 85s 846ms/step - loss: 0.2786 - categorical_accuracy: 0.8907 - val_loss: 0.5153 - val_categorical_accuracy: 0.8050 - lr: 1.1884e-04\n",
      "Epoch 102/150\n",
      "99/99 [==============================] - 83s 827ms/step - loss: 0.2830 - categorical_accuracy: 0.8856 - val_loss: 0.5266 - val_categorical_accuracy: 0.8000 - lr: 1.1533e-04\n",
      "Epoch 103/150\n",
      "99/99 [==============================] - 86s 854ms/step - loss: 0.2787 - categorical_accuracy: 0.8884 - val_loss: 0.3812 - val_categorical_accuracy: 0.8625 - lr: 1.1192e-04\n",
      "Epoch 104/150\n",
      "99/99 [==============================] - 97s 965ms/step - loss: 0.2742 - categorical_accuracy: 0.8927 - val_loss: 0.4097 - val_categorical_accuracy: 0.8500 - lr: 1.0861e-04\n",
      "Epoch 105/150\n",
      "99/99 [==============================] - 86s 851ms/step - loss: 0.2806 - categorical_accuracy: 0.8861 - val_loss: 0.4081 - val_categorical_accuracy: 0.8425 - lr: 1.0540e-04\n",
      "Epoch 106/150\n",
      "99/99 [==============================] - 84s 835ms/step - loss: 0.2750 - categorical_accuracy: 0.8894 - val_loss: 0.3561 - val_categorical_accuracy: 0.8775 - lr: 1.0228e-04\n",
      "Epoch 107/150\n",
      "99/99 [==============================] - 85s 840ms/step - loss: 0.2566 - categorical_accuracy: 0.9018 - val_loss: 0.4071 - val_categorical_accuracy: 0.8300 - lr: 9.9262e-05\n",
      "Epoch 108/150\n",
      "99/99 [==============================] - 85s 844ms/step - loss: 0.2610 - categorical_accuracy: 0.8972 - val_loss: 0.3819 - val_categorical_accuracy: 0.8525 - lr: 9.6328e-05\n",
      "Epoch 109/150\n",
      "99/99 [==============================] - 86s 852ms/step - loss: 0.2699 - categorical_accuracy: 0.8942 - val_loss: 0.4020 - val_categorical_accuracy: 0.8600 - lr: 9.3481e-05\n",
      "Epoch 110/150\n",
      "99/99 [==============================] - 87s 867ms/step - loss: 0.2663 - categorical_accuracy: 0.8957 - val_loss: 0.3636 - val_categorical_accuracy: 0.8775 - lr: 9.0718e-05\n",
      "Epoch 111/150\n",
      "99/99 [==============================] - 85s 840ms/step - loss: 0.2609 - categorical_accuracy: 0.9020 - val_loss: 0.3356 - val_categorical_accuracy: 0.8850 - lr: 8.8037e-05\n",
      "Epoch 112/150\n",
      "99/99 [==============================] - 85s 843ms/step - loss: 0.2621 - categorical_accuracy: 0.8934 - val_loss: 0.3798 - val_categorical_accuracy: 0.8625 - lr: 8.5435e-05\n",
      "Epoch 113/150\n",
      "99/99 [==============================] - 85s 844ms/step - loss: 0.2547 - categorical_accuracy: 0.8982 - val_loss: 0.3982 - val_categorical_accuracy: 0.8550 - lr: 8.2910e-05\n",
      "Epoch 114/150\n",
      "99/99 [==============================] - 84s 831ms/step - loss: 0.2561 - categorical_accuracy: 0.9000 - val_loss: 0.3456 - val_categorical_accuracy: 0.8825 - lr: 8.0460e-05\n",
      "Epoch 115/150\n",
      "99/99 [==============================] - 85s 842ms/step - loss: 0.2458 - categorical_accuracy: 0.9010 - val_loss: 0.3706 - val_categorical_accuracy: 0.8750 - lr: 7.8082e-05\n",
      "Epoch 116/150\n",
      "99/99 [==============================] - 86s 850ms/step - loss: 0.2421 - categorical_accuracy: 0.9068 - val_loss: 0.3827 - val_categorical_accuracy: 0.8625 - lr: 7.5774e-05\n",
      "Epoch 117/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.2502 - categorical_accuracy: 0.8982 - val_loss: 0.3520 - val_categorical_accuracy: 0.8750 - lr: 7.3535e-05\n",
      "Epoch 118/150\n",
      "99/99 [==============================] - 87s 861ms/step - loss: 0.2496 - categorical_accuracy: 0.9035 - val_loss: 0.3821 - val_categorical_accuracy: 0.8625 - lr: 7.1362e-05\n",
      "Epoch 119/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.2469 - categorical_accuracy: 0.9020 - val_loss: 0.3638 - val_categorical_accuracy: 0.8800 - lr: 6.9252e-05\n",
      "Epoch 120/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.2412 - categorical_accuracy: 0.9063 - val_loss: 0.3733 - val_categorical_accuracy: 0.8650 - lr: 6.7206e-05\n",
      "Epoch 121/150\n",
      "99/99 [==============================] - 85s 839ms/step - loss: 0.2385 - categorical_accuracy: 0.9053 - val_loss: 0.3961 - val_categorical_accuracy: 0.8575 - lr: 6.5220e-05\n",
      "Epoch 122/150\n",
      "99/99 [==============================] - 85s 839ms/step - loss: 0.2366 - categorical_accuracy: 0.9086 - val_loss: 0.3750 - val_categorical_accuracy: 0.8675 - lr: 6.3292e-05\n",
      "Epoch 123/150\n",
      "99/99 [==============================] - 86s 852ms/step - loss: 0.2381 - categorical_accuracy: 0.9068 - val_loss: 0.3520 - val_categorical_accuracy: 0.8775 - lr: 6.1421e-05\n",
      "Epoch 124/150\n",
      "99/99 [==============================] - 84s 836ms/step - loss: 0.2381 - categorical_accuracy: 0.9071 - val_loss: 0.3813 - val_categorical_accuracy: 0.8675 - lr: 5.9606e-05\n",
      "Epoch 125/150\n",
      "99/99 [==============================] - 86s 852ms/step - loss: 0.2357 - categorical_accuracy: 0.9061 - val_loss: 0.3521 - val_categorical_accuracy: 0.8825 - lr: 5.7845e-05\n",
      "Epoch 126/150\n",
      "99/99 [==============================] - 85s 840ms/step - loss: 0.2387 - categorical_accuracy: 0.9030 - val_loss: 0.3661 - val_categorical_accuracy: 0.8675 - lr: 5.6135e-05\n",
      "Epoch 127/150\n",
      "99/99 [==============================] - 85s 839ms/step - loss: 0.2229 - categorical_accuracy: 0.9101 - val_loss: 0.3412 - val_categorical_accuracy: 0.8875 - lr: 5.4476e-05\n",
      "Epoch 128/150\n",
      "99/99 [==============================] - 92s 916ms/step - loss: 0.2217 - categorical_accuracy: 0.9083 - val_loss: 0.3569 - val_categorical_accuracy: 0.8825 - lr: 5.2866e-05\n",
      "Epoch 129/150\n",
      "99/99 [==============================] - 84s 829ms/step - loss: 0.2277 - categorical_accuracy: 0.9088 - val_loss: 0.3702 - val_categorical_accuracy: 0.8700 - lr: 5.1304e-05\n",
      "Epoch 130/150\n",
      "99/99 [==============================] - 85s 839ms/step - loss: 0.2410 - categorical_accuracy: 0.9071 - val_loss: 0.3945 - val_categorical_accuracy: 0.8625 - lr: 4.9787e-05\n",
      "Epoch 131/150\n",
      "99/99 [==============================] - 84s 835ms/step - loss: 0.2169 - categorical_accuracy: 0.9174 - val_loss: 0.3664 - val_categorical_accuracy: 0.8750 - lr: 4.8316e-05\n",
      "Epoch 132/150\n",
      "99/99 [==============================] - 83s 828ms/step - loss: 0.2274 - categorical_accuracy: 0.9081 - val_loss: 0.3481 - val_categorical_accuracy: 0.8750 - lr: 4.6888e-05\n",
      "Epoch 133/150\n",
      "99/99 [==============================] - 85s 840ms/step - loss: 0.2151 - categorical_accuracy: 0.9144 - val_loss: 0.3889 - val_categorical_accuracy: 0.8625 - lr: 4.5502e-05\n",
      "Epoch 134/150\n",
      "99/99 [==============================] - 84s 838ms/step - loss: 0.2234 - categorical_accuracy: 0.9146 - val_loss: 0.4037 - val_categorical_accuracy: 0.8550 - lr: 4.4157e-05\n",
      "Epoch 135/150\n",
      "99/99 [==============================] - 85s 847ms/step - loss: 0.2189 - categorical_accuracy: 0.9136 - val_loss: 0.3788 - val_categorical_accuracy: 0.8725 - lr: 4.2852e-05\n",
      "Epoch 136/150\n",
      "99/99 [==============================] - 84s 835ms/step - loss: 0.2324 - categorical_accuracy: 0.9152 - val_loss: 0.3591 - val_categorical_accuracy: 0.8750 - lr: 4.1586e-05\n",
      "Epoch 137/150\n",
      "99/99 [==============================] - 86s 856ms/step - loss: 0.2188 - categorical_accuracy: 0.9139 - val_loss: 0.3579 - val_categorical_accuracy: 0.8825 - lr: 4.0357e-05\n",
      "Epoch 138/150\n",
      "99/99 [==============================] - 85s 844ms/step - loss: 0.2148 - categorical_accuracy: 0.9159 - val_loss: 0.3671 - val_categorical_accuracy: 0.8800 - lr: 3.9164e-05\n",
      "Epoch 139/150\n",
      "99/99 [==============================] - 84s 836ms/step - loss: 0.2281 - categorical_accuracy: 0.9136 - val_loss: 0.3666 - val_categorical_accuracy: 0.8650 - lr: 3.8007e-05\n",
      "Epoch 140/150\n",
      "99/99 [==============================] - 85s 841ms/step - loss: 0.2260 - categorical_accuracy: 0.9106 - val_loss: 0.3713 - val_categorical_accuracy: 0.8650 - lr: 3.6883e-05\n",
      "Epoch 141/150\n",
      "99/99 [==============================] - 83s 826ms/step - loss: 0.2284 - categorical_accuracy: 0.9078 - val_loss: 0.3626 - val_categorical_accuracy: 0.8825 - lr: 3.5793e-05\n",
      "Epoch 142/150\n",
      "99/99 [==============================] - 86s 853ms/step - loss: 0.2130 - categorical_accuracy: 0.9136 - val_loss: 0.3576 - val_categorical_accuracy: 0.8800 - lr: 3.4735e-05\n",
      "Epoch 143/150\n",
      "99/99 [==============================] - 86s 851ms/step - loss: 0.2174 - categorical_accuracy: 0.9116 - val_loss: 0.3805 - val_categorical_accuracy: 0.8725 - lr: 3.3709e-05\n",
      "Epoch 144/150\n",
      "99/99 [==============================] - 84s 834ms/step - loss: 0.2186 - categorical_accuracy: 0.9146 - val_loss: 0.3651 - val_categorical_accuracy: 0.8775 - lr: 3.2713e-05\n",
      "Epoch 145/150\n",
      "99/99 [==============================] - 83s 825ms/step - loss: 0.2075 - categorical_accuracy: 0.9172 - val_loss: 0.4019 - val_categorical_accuracy: 0.8550 - lr: 3.1746e-05\n",
      "Epoch 146/150\n",
      "99/99 [==============================] - 83s 825ms/step - loss: 0.2044 - categorical_accuracy: 0.9192 - val_loss: 0.3663 - val_categorical_accuracy: 0.8675 - lr: 3.0808e-05\n",
      "Epoch 147/150\n",
      "99/99 [==============================] - 84s 834ms/step - loss: 0.2036 - categorical_accuracy: 0.9174 - val_loss: 0.3476 - val_categorical_accuracy: 0.8850 - lr: 2.9897e-05\n",
      "Epoch 148/150\n",
      "99/99 [==============================] - 84s 835ms/step - loss: 0.2115 - categorical_accuracy: 0.9152 - val_loss: 0.3796 - val_categorical_accuracy: 0.8650 - lr: 2.9013e-05\n",
      "Epoch 149/150\n",
      "99/99 [==============================] - 83s 823ms/step - loss: 0.2029 - categorical_accuracy: 0.9159 - val_loss: 0.3645 - val_categorical_accuracy: 0.8725 - lr: 2.8156e-05\n",
      "Epoch 150/150\n",
      "99/99 [==============================] - 85s 842ms/step - loss: 0.2035 - categorical_accuracy: 0.9230 - val_loss: 0.3616 - val_categorical_accuracy: 0.8750 - lr: 2.7324e-05\n"
     ]
    }
   ],
   "source": [
    "# valid = tf.data.experimental.load('savedata_valid')\n",
    "# train = tf.data.experimental.load('savedata_train')\n",
    "# train = train.shuffle(100,  reshuffle_each_iteration=True)\n",
    "\n",
    "x_size = 230\n",
    "y_size = 230\n",
    "in_seed = 42\n",
    "resize_rescale_augment = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values\n",
    "    layers.CenterCrop(140,140, ),\n",
    "    layers.RandomCrop(120,120, seed=in_seed, ),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "    \n",
    "    # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='tanh'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=max ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/threemod/resnet50v2_firsth\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.03)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "model.build()\n",
    "model.summary()\n",
    "\n",
    "# now with normalisation\n",
    "epochs=150\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=10,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461561a4-bd73-4fd7-ad8b-84eaee27bfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46647eff-f12c-4f55-bd21-09eb71452857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/resnet50v2_firsth\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/resnet50v2_firsth\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_models/resnet50v2_firsth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f906f3e-5a5a-4d3c-ab0d-b932679a7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_5 (Sequential)   (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 4, 4, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,663,410\n",
      "Trainable params: 23,617,970\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "99/99 [==============================] - 108s 1s/step - loss: 1.9343 - categorical_accuracy: 0.6119 - val_loss: 141.6560 - val_categorical_accuracy: 0.4875 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "99/99 [==============================] - 99s 987ms/step - loss: 1.5498 - categorical_accuracy: 0.6210 - val_loss: 28.7722 - val_categorical_accuracy: 0.4725 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "99/99 [==============================] - 90s 886ms/step - loss: 1.0289 - categorical_accuracy: 0.6755 - val_loss: 9.4059 - val_categorical_accuracy: 0.6025 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "99/99 [==============================] - 216s 2s/step - loss: 0.8390 - categorical_accuracy: 0.6932 - val_loss: 0.7451 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "99/99 [==============================] - 92s 908ms/step - loss: 1.0010 - categorical_accuracy: 0.6896 - val_loss: 174.2137 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "99/99 [==============================] - 228s 2s/step - loss: 0.9155 - categorical_accuracy: 0.7061 - val_loss: 0.7210 - val_categorical_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "99/99 [==============================] - 94s 931ms/step - loss: 0.8120 - categorical_accuracy: 0.7222 - val_loss: 0.8513 - val_categorical_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "99/99 [==============================] - 107s 1s/step - loss: 0.7081 - categorical_accuracy: 0.7343 - val_loss: 0.7789 - val_categorical_accuracy: 0.6675 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "99/99 [==============================] - 96s 955ms/step - loss: 0.7299 - categorical_accuracy: 0.7369 - val_loss: 0.7728 - val_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "99/99 [==============================] - 89s 882ms/step - loss: 0.6665 - categorical_accuracy: 0.7298 - val_loss: 4.2806 - val_categorical_accuracy: 0.6375 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "99/99 [==============================] - 89s 884ms/step - loss: 0.6380 - categorical_accuracy: 0.7434 - val_loss: 0.6478 - val_categorical_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "99/99 [==============================] - 89s 880ms/step - loss: 0.6238 - categorical_accuracy: 0.7487 - val_loss: 0.6776 - val_categorical_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "99/99 [==============================] - 89s 880ms/step - loss: 0.6155 - categorical_accuracy: 0.7523 - val_loss: 0.6880 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "99/99 [==============================] - 89s 879ms/step - loss: 0.6318 - categorical_accuracy: 0.7492 - val_loss: 0.7881 - val_categorical_accuracy: 0.6775 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "99/99 [==============================] - 89s 884ms/step - loss: 0.5750 - categorical_accuracy: 0.7626 - val_loss: 0.6857 - val_categorical_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "99/99 [==============================] - 89s 882ms/step - loss: 0.6282 - categorical_accuracy: 0.7573 - val_loss: 0.8328 - val_categorical_accuracy: 0.6675 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "99/99 [==============================] - 89s 879ms/step - loss: 0.7399 - categorical_accuracy: 0.7293 - val_loss: 5.9591 - val_categorical_accuracy: 0.5225 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "99/99 [==============================] - 89s 882ms/step - loss: 0.6030 - categorical_accuracy: 0.7677 - val_loss: 0.8468 - val_categorical_accuracy: 0.7625 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "99/99 [==============================] - 91s 897ms/step - loss: 0.6072 - categorical_accuracy: 0.7664 - val_loss: 0.8540 - val_categorical_accuracy: 0.6400 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "99/99 [==============================] - 90s 894ms/step - loss: 0.5919 - categorical_accuracy: 0.7614 - val_loss: 0.7960 - val_categorical_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "99/99 [==============================] - 90s 887ms/step - loss: 0.5645 - categorical_accuracy: 0.7775 - val_loss: 0.6510 - val_categorical_accuracy: 0.7325 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "99/99 [==============================] - 90s 888ms/step - loss: 0.5535 - categorical_accuracy: 0.7793 - val_loss: 0.6718 - val_categorical_accuracy: 0.7050 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "99/99 [==============================] - 90s 888ms/step - loss: 0.5675 - categorical_accuracy: 0.7692 - val_loss: 0.6308 - val_categorical_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "99/99 [==============================] - 89s 885ms/step - loss: 0.5408 - categorical_accuracy: 0.7722 - val_loss: 0.7128 - val_categorical_accuracy: 0.6950 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "99/99 [==============================] - 89s 880ms/step - loss: 0.5358 - categorical_accuracy: 0.7765 - val_loss: 1.2731 - val_categorical_accuracy: 0.7825 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "99/99 [==============================] - 99s 980ms/step - loss: 0.5386 - categorical_accuracy: 0.7889 - val_loss: 0.5432 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.5132 - categorical_accuracy: 0.7947 - val_loss: 15.1523 - val_categorical_accuracy: 0.6975 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "99/99 [==============================] - 111s 1s/step - loss: 0.5175 - categorical_accuracy: 0.7972 - val_loss: 0.5501 - val_categorical_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "99/99 [==============================] - 113s 1s/step - loss: 0.4982 - categorical_accuracy: 0.8061 - val_loss: 0.6825 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "99/99 [==============================] - 99s 982ms/step - loss: 0.4871 - categorical_accuracy: 0.8126 - val_loss: 1.1416 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "99/99 [==============================] - 119s 1s/step - loss: 0.4859 - categorical_accuracy: 0.8038 - val_loss: 0.5324 - val_categorical_accuracy: 0.8050 - lr: 9.7045e-04\n",
      "Epoch 32/150\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.4624 - categorical_accuracy: 0.8126 - val_loss: 0.5249 - val_categorical_accuracy: 0.7950 - lr: 9.4176e-04\n",
      "Epoch 33/150\n",
      "99/99 [==============================] - 90s 888ms/step - loss: 0.4423 - categorical_accuracy: 0.8230 - val_loss: 0.4622 - val_categorical_accuracy: 0.8375 - lr: 9.1393e-04\n",
      "Epoch 34/150\n",
      "99/99 [==============================] - 96s 947ms/step - loss: 0.4493 - categorical_accuracy: 0.8157 - val_loss: 0.4632 - val_categorical_accuracy: 0.8150 - lr: 8.8692e-04\n",
      "Epoch 35/150\n",
      "99/99 [==============================] - 108s 1s/step - loss: 0.4550 - categorical_accuracy: 0.8126 - val_loss: 0.4484 - val_categorical_accuracy: 0.8150 - lr: 8.6071e-04\n",
      "Epoch 36/150\n",
      "99/99 [==============================] - 97s 965ms/step - loss: 0.4227 - categorical_accuracy: 0.8308 - val_loss: 0.7373 - val_categorical_accuracy: 0.7500 - lr: 8.3527e-04\n",
      "Epoch 37/150\n",
      "99/99 [==============================] - 104s 1s/step - loss: 0.4356 - categorical_accuracy: 0.8222 - val_loss: 0.4638 - val_categorical_accuracy: 0.8175 - lr: 8.1058e-04\n",
      "Epoch 38/150\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.4372 - categorical_accuracy: 0.8260 - val_loss: 0.4524 - val_categorical_accuracy: 0.8175 - lr: 7.8663e-04\n",
      "Epoch 39/150\n",
      "99/99 [==============================] - 118s 1s/step - loss: 0.4138 - categorical_accuracy: 0.8326 - val_loss: 0.5550 - val_categorical_accuracy: 0.7975 - lr: 7.6338e-04\n",
      "Epoch 40/150\n",
      "99/99 [==============================] - 123s 1s/step - loss: 0.4073 - categorical_accuracy: 0.8366 - val_loss: 0.4764 - val_categorical_accuracy: 0.8175 - lr: 7.4082e-04\n",
      "Epoch 41/150\n",
      "99/99 [==============================] - 101s 1000ms/step - loss: 0.4082 - categorical_accuracy: 0.8386 - val_loss: 0.5148 - val_categorical_accuracy: 0.8225 - lr: 7.1892e-04\n",
      "Epoch 42/150\n",
      "99/99 [==============================] - 100s 970ms/step - loss: 0.3936 - categorical_accuracy: 0.8470 - val_loss: 0.4307 - val_categorical_accuracy: 0.8525 - lr: 6.9768e-04\n",
      "Epoch 43/150\n",
      "99/99 [==============================] - 94s 932ms/step - loss: 0.3917 - categorical_accuracy: 0.8447 - val_loss: 0.4263 - val_categorical_accuracy: 0.8475 - lr: 6.7706e-04\n",
      "Epoch 44/150\n",
      "99/99 [==============================] - 93s 920ms/step - loss: 0.3799 - categorical_accuracy: 0.8465 - val_loss: 0.5066 - val_categorical_accuracy: 0.7975 - lr: 6.5705e-04\n",
      "Epoch 45/150\n",
      "99/99 [==============================] - 93s 920ms/step - loss: 0.3898 - categorical_accuracy: 0.8414 - val_loss: 0.9984 - val_categorical_accuracy: 0.7550 - lr: 6.3763e-04\n",
      "Epoch 46/150\n",
      "99/99 [==============================] - 93s 925ms/step - loss: 0.3756 - categorical_accuracy: 0.8556 - val_loss: 0.3930 - val_categorical_accuracy: 0.8500 - lr: 6.1878e-04\n",
      "Epoch 47/150\n",
      "99/99 [==============================] - 94s 929ms/step - loss: 0.3680 - categorical_accuracy: 0.8533 - val_loss: 0.5103 - val_categorical_accuracy: 0.8150 - lr: 6.0050e-04\n",
      "Epoch 48/150\n",
      "99/99 [==============================] - 94s 934ms/step - loss: 0.3728 - categorical_accuracy: 0.8503 - val_loss: 0.4898 - val_categorical_accuracy: 0.8225 - lr: 5.8275e-04\n",
      "Epoch 49/150\n",
      "99/99 [==============================] - 94s 929ms/step - loss: 0.3707 - categorical_accuracy: 0.8535 - val_loss: 0.4538 - val_categorical_accuracy: 0.8150 - lr: 5.6553e-04\n",
      "Epoch 50/150\n",
      "99/99 [==============================] - 93s 919ms/step - loss: 0.3648 - categorical_accuracy: 0.8533 - val_loss: 0.4446 - val_categorical_accuracy: 0.8300 - lr: 5.4881e-04\n",
      "Epoch 51/150\n",
      "99/99 [==============================] - 94s 931ms/step - loss: 0.3691 - categorical_accuracy: 0.8586 - val_loss: 0.4494 - val_categorical_accuracy: 0.8300 - lr: 5.3259e-04\n",
      "Epoch 52/150\n",
      "99/99 [==============================] - 98s 967ms/step - loss: 0.3732 - categorical_accuracy: 0.8561 - val_loss: 0.4234 - val_categorical_accuracy: 0.8550 - lr: 5.1685e-04\n",
      "Epoch 53/150\n",
      "99/99 [==============================] - 98s 976ms/step - loss: 0.3530 - categorical_accuracy: 0.8553 - val_loss: 0.4666 - val_categorical_accuracy: 0.8175 - lr: 5.0158e-04\n",
      "Epoch 54/150\n",
      "99/99 [==============================] - 99s 986ms/step - loss: 0.3407 - categorical_accuracy: 0.8614 - val_loss: 0.5088 - val_categorical_accuracy: 0.7875 - lr: 4.8675e-04\n",
      "Epoch 55/150\n",
      "99/99 [==============================] - 98s 974ms/step - loss: 0.3464 - categorical_accuracy: 0.8629 - val_loss: 0.4286 - val_categorical_accuracy: 0.8450 - lr: 4.7237e-04\n",
      "Epoch 56/150\n",
      "99/99 [==============================] - 100s 994ms/step - loss: 0.3444 - categorical_accuracy: 0.8707 - val_loss: 0.4658 - val_categorical_accuracy: 0.8275 - lr: 4.5841e-04\n",
      "Epoch 57/150\n",
      "99/99 [==============================] - 99s 980ms/step - loss: 0.3241 - categorical_accuracy: 0.8730 - val_loss: 1.2557 - val_categorical_accuracy: 0.7975 - lr: 4.4486e-04\n",
      "Epoch 58/150\n",
      "99/99 [==============================] - 100s 990ms/step - loss: 0.3390 - categorical_accuracy: 0.8694 - val_loss: 0.4538 - val_categorical_accuracy: 0.8425 - lr: 4.3171e-04\n",
      "Epoch 59/150\n",
      "99/99 [==============================] - 99s 983ms/step - loss: 0.3178 - categorical_accuracy: 0.8740 - val_loss: 0.4262 - val_categorical_accuracy: 0.8475 - lr: 4.1895e-04\n",
      "Epoch 60/150\n",
      "99/99 [==============================] - 99s 979ms/step - loss: 0.3207 - categorical_accuracy: 0.8770 - val_loss: 0.5312 - val_categorical_accuracy: 0.8350 - lr: 4.0657e-04\n",
      "Epoch 61/150\n",
      "99/99 [==============================] - 98s 975ms/step - loss: 0.3281 - categorical_accuracy: 0.8720 - val_loss: 0.4051 - val_categorical_accuracy: 0.8600 - lr: 3.9455e-04\n",
      "Epoch 62/150\n",
      "99/99 [==============================] - 99s 985ms/step - loss: 0.3141 - categorical_accuracy: 0.8755 - val_loss: 0.4355 - val_categorical_accuracy: 0.8425 - lr: 3.8289e-04\n",
      "Epoch 63/150\n",
      "99/99 [==============================] - 99s 977ms/step - loss: 0.3339 - categorical_accuracy: 0.8730 - val_loss: 0.6845 - val_categorical_accuracy: 0.8275 - lr: 3.7158e-04\n",
      "Epoch 64/150\n",
      "99/99 [==============================] - 98s 975ms/step - loss: 0.3211 - categorical_accuracy: 0.8722 - val_loss: 0.4069 - val_categorical_accuracy: 0.8475 - lr: 3.6060e-04\n",
      "Epoch 65/150\n",
      "99/99 [==============================] - 99s 976ms/step - loss: 0.3139 - categorical_accuracy: 0.8806 - val_loss: 0.3938 - val_categorical_accuracy: 0.8550 - lr: 3.4994e-04\n",
      "Epoch 66/150\n",
      "99/99 [==============================] - 98s 976ms/step - loss: 0.3192 - categorical_accuracy: 0.8725 - val_loss: 0.4082 - val_categorical_accuracy: 0.8475 - lr: 3.3960e-04\n",
      "Epoch 67/150\n",
      "99/99 [==============================] - 98s 965ms/step - loss: 0.2829 - categorical_accuracy: 0.8909 - val_loss: 0.5189 - val_categorical_accuracy: 0.8225 - lr: 3.2956e-04\n",
      "Epoch 68/150\n",
      "99/99 [==============================] - 98s 974ms/step - loss: 0.3081 - categorical_accuracy: 0.8803 - val_loss: 0.3847 - val_categorical_accuracy: 0.8625 - lr: 3.1982e-04\n",
      "Epoch 69/150\n",
      "99/99 [==============================] - 99s 976ms/step - loss: 0.2826 - categorical_accuracy: 0.8902 - val_loss: 0.4640 - val_categorical_accuracy: 0.8325 - lr: 3.1037e-04\n",
      "Epoch 70/150\n",
      "99/99 [==============================] - 98s 974ms/step - loss: 0.2808 - categorical_accuracy: 0.8927 - val_loss: 0.4555 - val_categorical_accuracy: 0.8500 - lr: 3.0119e-04\n",
      "Epoch 71/150\n",
      "99/99 [==============================] - 100s 991ms/step - loss: 0.2964 - categorical_accuracy: 0.8831 - val_loss: 0.3957 - val_categorical_accuracy: 0.8525 - lr: 2.9229e-04\n",
      "Epoch 72/150\n",
      "99/99 [==============================] - 99s 978ms/step - loss: 0.2867 - categorical_accuracy: 0.8876 - val_loss: 0.4152 - val_categorical_accuracy: 0.8375 - lr: 2.8365e-04\n",
      "Epoch 73/150\n",
      "99/99 [==============================] - 99s 985ms/step - loss: 0.2878 - categorical_accuracy: 0.8907 - val_loss: 0.3743 - val_categorical_accuracy: 0.8600 - lr: 2.7527e-04\n",
      "Epoch 74/150\n",
      "99/99 [==============================] - 98s 975ms/step - loss: 0.2850 - categorical_accuracy: 0.8886 - val_loss: 0.3852 - val_categorical_accuracy: 0.8600 - lr: 2.6714e-04\n",
      "Epoch 75/150\n",
      "99/99 [==============================] - 99s 982ms/step - loss: 0.2732 - categorical_accuracy: 0.8924 - val_loss: 0.3638 - val_categorical_accuracy: 0.8650 - lr: 2.5924e-04\n",
      "Epoch 76/150\n",
      "99/99 [==============================] - 99s 981ms/step - loss: 0.2857 - categorical_accuracy: 0.8891 - val_loss: 0.4492 - val_categorical_accuracy: 0.8300 - lr: 2.5158e-04\n",
      "Epoch 77/150\n",
      "99/99 [==============================] - 99s 986ms/step - loss: 0.2758 - categorical_accuracy: 0.8965 - val_loss: 0.4609 - val_categorical_accuracy: 0.8375 - lr: 2.4414e-04\n",
      "Epoch 78/150\n",
      "99/99 [==============================] - 99s 978ms/step - loss: 0.2869 - categorical_accuracy: 0.8899 - val_loss: 0.7227 - val_categorical_accuracy: 0.8475 - lr: 2.3693e-04\n",
      "Epoch 79/150\n",
      "99/99 [==============================] - 98s 966ms/step - loss: 0.2725 - categorical_accuracy: 0.8927 - val_loss: 0.3541 - val_categorical_accuracy: 0.8750 - lr: 2.2993e-04\n",
      "Epoch 80/150\n",
      "99/99 [==============================] - 99s 980ms/step - loss: 0.2656 - categorical_accuracy: 0.8934 - val_loss: 0.3571 - val_categorical_accuracy: 0.8600 - lr: 2.2313e-04\n",
      "Epoch 81/150\n",
      "99/99 [==============================] - 99s 980ms/step - loss: 0.2579 - categorical_accuracy: 0.8952 - val_loss: 0.3987 - val_categorical_accuracy: 0.8500 - lr: 2.1654e-04\n",
      "Epoch 82/150\n",
      "99/99 [==============================] - 98s 971ms/step - loss: 0.2578 - categorical_accuracy: 0.8967 - val_loss: 0.3697 - val_categorical_accuracy: 0.8700 - lr: 2.1014e-04\n",
      "Epoch 83/150\n",
      "99/99 [==============================] - 98s 968ms/step - loss: 0.2602 - categorical_accuracy: 0.8982 - val_loss: 0.3486 - val_categorical_accuracy: 0.8625 - lr: 2.0393e-04\n",
      "Epoch 84/150\n",
      "99/99 [==============================] - 96s 951ms/step - loss: 0.2515 - categorical_accuracy: 0.9015 - val_loss: 0.4388 - val_categorical_accuracy: 0.8400 - lr: 1.9790e-04\n",
      "Epoch 85/150\n",
      "99/99 [==============================] - 98s 974ms/step - loss: 0.2309 - categorical_accuracy: 0.9109 - val_loss: 0.4061 - val_categorical_accuracy: 0.8600 - lr: 1.9205e-04\n",
      "Epoch 86/150\n",
      "99/99 [==============================] - 94s 928ms/step - loss: 0.2465 - categorical_accuracy: 0.9023 - val_loss: 0.3912 - val_categorical_accuracy: 0.8650 - lr: 1.8637e-04\n",
      "Epoch 87/150\n",
      "99/99 [==============================] - 93s 917ms/step - loss: 0.2459 - categorical_accuracy: 0.9040 - val_loss: 0.4011 - val_categorical_accuracy: 0.8550 - lr: 1.8087e-04\n",
      "Epoch 88/150\n",
      "99/99 [==============================] - 94s 931ms/step - loss: 0.2387 - categorical_accuracy: 0.9119 - val_loss: 0.3960 - val_categorical_accuracy: 0.8525 - lr: 1.7552e-04\n",
      "Epoch 89/150\n",
      "99/99 [==============================] - 95s 938ms/step - loss: 0.2362 - categorical_accuracy: 0.9091 - val_loss: 0.3705 - val_categorical_accuracy: 0.8600 - lr: 1.7033e-04\n",
      "Epoch 90/150\n",
      "99/99 [==============================] - 94s 931ms/step - loss: 0.2274 - categorical_accuracy: 0.9126 - val_loss: 0.3952 - val_categorical_accuracy: 0.8500 - lr: 1.6530e-04\n",
      "Epoch 91/150\n",
      "99/99 [==============================] - 114s 1s/step - loss: 0.2328 - categorical_accuracy: 0.9134 - val_loss: 0.3904 - val_categorical_accuracy: 0.8700 - lr: 1.6041e-04\n",
      "Epoch 92/150\n",
      "99/99 [==============================] - 110s 1s/step - loss: 0.2310 - categorical_accuracy: 0.9086 - val_loss: 0.3650 - val_categorical_accuracy: 0.8750 - lr: 1.5567e-04\n",
      "Epoch 93/150\n",
      "99/99 [==============================] - 122s 1s/step - loss: 0.2236 - categorical_accuracy: 0.9088 - val_loss: 0.3627 - val_categorical_accuracy: 0.8725 - lr: 1.5107e-04\n",
      "Epoch 94/150\n",
      "99/99 [==============================] - 131s 1s/step - loss: 0.2280 - categorical_accuracy: 0.9121 - val_loss: 0.3849 - val_categorical_accuracy: 0.8650 - lr: 1.4661e-04\n",
      "Epoch 95/150\n",
      "99/99 [==============================] - 123s 1s/step - loss: 0.2153 - categorical_accuracy: 0.9172 - val_loss: 0.3646 - val_categorical_accuracy: 0.8725 - lr: 1.4227e-04\n",
      "Epoch 96/150\n",
      "99/99 [==============================] - 123s 1s/step - loss: 0.2185 - categorical_accuracy: 0.9139 - val_loss: 0.6912 - val_categorical_accuracy: 0.8175 - lr: 1.3807e-04\n",
      "Epoch 97/150\n",
      "99/99 [==============================] - 123s 1s/step - loss: 0.2169 - categorical_accuracy: 0.9177 - val_loss: 0.3777 - val_categorical_accuracy: 0.8750 - lr: 1.3399e-04\n",
      "Epoch 98/150\n",
      "99/99 [==============================] - 101s 996ms/step - loss: 0.2088 - categorical_accuracy: 0.9179 - val_loss: 0.4048 - val_categorical_accuracy: 0.8650 - lr: 1.3003e-04\n",
      "Epoch 99/150\n",
      "99/99 [==============================] - 112s 1s/step - loss: 0.2080 - categorical_accuracy: 0.9210 - val_loss: 0.3937 - val_categorical_accuracy: 0.8575 - lr: 1.2619e-04\n",
      "Epoch 100/150\n",
      "99/99 [==============================] - 111s 1s/step - loss: 0.2101 - categorical_accuracy: 0.9167 - val_loss: 0.3877 - val_categorical_accuracy: 0.8800 - lr: 1.2246e-04\n",
      "Epoch 101/150\n",
      "99/99 [==============================] - 113s 1s/step - loss: 0.2105 - categorical_accuracy: 0.9159 - val_loss: 0.3780 - val_categorical_accuracy: 0.8650 - lr: 1.1884e-04\n",
      "Epoch 102/150\n",
      "99/99 [==============================] - 112s 1s/step - loss: 0.2078 - categorical_accuracy: 0.9164 - val_loss: 0.3735 - val_categorical_accuracy: 0.8850 - lr: 1.1533e-04\n",
      "Epoch 103/150\n",
      "99/99 [==============================] - 106s 1s/step - loss: 0.1900 - categorical_accuracy: 0.9295 - val_loss: 0.3819 - val_categorical_accuracy: 0.8800 - lr: 1.1192e-04\n",
      "Epoch 104/150\n",
      "99/99 [==============================] - 94s 929ms/step - loss: 0.1887 - categorical_accuracy: 0.9285 - val_loss: 0.3770 - val_categorical_accuracy: 0.8850 - lr: 1.0861e-04\n",
      "Epoch 105/150\n",
      "99/99 [==============================] - 91s 897ms/step - loss: 0.1980 - categorical_accuracy: 0.9237 - val_loss: 0.3894 - val_categorical_accuracy: 0.8825 - lr: 1.0540e-04\n",
      "Epoch 106/150\n",
      "99/99 [==============================] - 96s 948ms/step - loss: 0.1940 - categorical_accuracy: 0.9293 - val_loss: 0.4024 - val_categorical_accuracy: 0.8675 - lr: 1.0228e-04\n",
      "Epoch 107/150\n",
      "99/99 [==============================] - 100s 990ms/step - loss: 0.1887 - categorical_accuracy: 0.9273 - val_loss: 0.3950 - val_categorical_accuracy: 0.8650 - lr: 9.9262e-05\n",
      "Epoch 108/150\n",
      " 8/99 [=>............................] - ETA: 1:18 - loss: 0.2003 - categorical_accuracy: 0.9281"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1792\\3783182134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models/resnet50v2_secondh'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# valid = tf.data.experimental.load('savedata_valid')\n",
    "# train = tf.data.experimental.load('savedata_train')\n",
    "# train = train.shuffle(100,  reshuffle_each_iteration=True)\n",
    "\n",
    "x_size = 230\n",
    "y_size = 230\n",
    "in_seed = 42\n",
    "resize_rescale_augment = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values\n",
    "    layers.CenterCrop(140,140, ),\n",
    "    layers.RandomCrop(120,120, seed=in_seed, ),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "    \n",
    "    # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='tanh'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=max ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/threemod/resnet50v2_firsth\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.03)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "model.build()\n",
    "model.summary()\n",
    "\n",
    "# now with normalisation\n",
    "epochs=150\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=10,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")\n",
    "model.save('saved_models/resnet50v2_secondh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d8fb874-8e3a-4126-ad9c-a99f14acfb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/resnet50v2_secondh\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/resnet50v2_secondh\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save('saved_models/resnet50v2_secondh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bccf08a4-b429-4e1b-aa64-ed8d3d374032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_14 (Sequential)  (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,686,322\n",
      "Trainable params: 23,633,202\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Epoch 1/230\n",
      "159/159 [==============================] - 80s 434ms/step - loss: 3.1392 - categorical_accuracy: 0.5299 - val_loss: 18.4702 - val_categorical_accuracy: 0.4700 - lr: 0.0010\n",
      "Epoch 2/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 1.6402 - categorical_accuracy: 0.5520 - val_loss: 4296.1851 - val_categorical_accuracy: 0.5025 - lr: 0.0010\n",
      "Epoch 3/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 1.2918 - categorical_accuracy: 0.6176 - val_loss: 1070.1077 - val_categorical_accuracy: 0.5175 - lr: 0.0010\n",
      "Epoch 4/230\n",
      "159/159 [==============================] - 63s 390ms/step - loss: 1.6359 - categorical_accuracy: 0.5747 - val_loss: 1.3040 - val_categorical_accuracy: 0.4675 - lr: 0.0010\n",
      "Epoch 5/230\n",
      "159/159 [==============================] - 64s 397ms/step - loss: 1.0036 - categorical_accuracy: 0.6091 - val_loss: 20.0547 - val_categorical_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 6/230\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.9695 - categorical_accuracy: 0.6447 - val_loss: 16.7100 - val_categorical_accuracy: 0.6325 - lr: 0.0010\n",
      "Epoch 7/230\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.9605 - categorical_accuracy: 0.6498 - val_loss: 0.7552 - val_categorical_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 8/230\n",
      "159/159 [==============================] - 63s 395ms/step - loss: 1.1838 - categorical_accuracy: 0.6547 - val_loss: 1.0376 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 9/230\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.9251 - categorical_accuracy: 0.6605 - val_loss: 11.0661 - val_categorical_accuracy: 0.6225 - lr: 0.0010\n",
      "Epoch 10/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.7395 - categorical_accuracy: 0.7050 - val_loss: 0.7088 - val_categorical_accuracy: 0.6900 - lr: 0.0010\n",
      "Epoch 11/230\n",
      "159/159 [==============================] - 64s 397ms/step - loss: 0.7057 - categorical_accuracy: 0.7132 - val_loss: 0.7989 - val_categorical_accuracy: 0.6300 - lr: 0.0010\n",
      "Epoch 12/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.7578 - categorical_accuracy: 0.7340 - val_loss: 0.6714 - val_categorical_accuracy: 0.7325 - lr: 0.0010\n",
      "Epoch 13/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.6683 - categorical_accuracy: 0.7398 - val_loss: 0.6851 - val_categorical_accuracy: 0.6975 - lr: 0.0010\n",
      "Epoch 14/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.6136 - categorical_accuracy: 0.7429 - val_loss: 0.5630 - val_categorical_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 15/230\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.6185 - categorical_accuracy: 0.7558 - val_loss: 0.5421 - val_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 16/230\n",
      "159/159 [==============================] - 63s 395ms/step - loss: 0.8002 - categorical_accuracy: 0.7108 - val_loss: 9.0774 - val_categorical_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 17/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.6946 - categorical_accuracy: 0.7423 - val_loss: 0.6430 - val_categorical_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 18/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 1.2538 - categorical_accuracy: 0.7143 - val_loss: 15.9568 - val_categorical_accuracy: 0.3775 - lr: 0.0010\n",
      "Epoch 19/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 1.5361 - categorical_accuracy: 0.6035 - val_loss: 7.0563 - val_categorical_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 20/230\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.8032 - categorical_accuracy: 0.6950 - val_loss: 1.0586 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 21/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.8051 - categorical_accuracy: 0.7077 - val_loss: 0.6163 - val_categorical_accuracy: 0.7475 - lr: 0.0010\n",
      "Epoch 22/230\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.7077 - categorical_accuracy: 0.7233 - val_loss: 16.1906 - val_categorical_accuracy: 0.7325 - lr: 0.0010\n",
      "Epoch 23/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.6872 - categorical_accuracy: 0.7299 - val_loss: 0.5532 - val_categorical_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 24/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.6263 - categorical_accuracy: 0.7403 - val_loss: 0.5576 - val_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 25/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.6326 - categorical_accuracy: 0.7458 - val_loss: 0.6200 - val_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 26/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.7320 - categorical_accuracy: 0.7086 - val_loss: 4.2038 - val_categorical_accuracy: 0.6525 - lr: 0.0010\n",
      "Epoch 27/230\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.6607 - categorical_accuracy: 0.7336 - val_loss: 0.6197 - val_categorical_accuracy: 0.7575 - lr: 0.0010\n",
      "Epoch 28/230\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.6435 - categorical_accuracy: 0.7415 - val_loss: 5.4533 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 29/230\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.6534 - categorical_accuracy: 0.7481 - val_loss: 0.6647 - val_categorical_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 30/230\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.6387 - categorical_accuracy: 0.7428 - val_loss: 1.4911 - val_categorical_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 31/230\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.6193 - categorical_accuracy: 0.7451 - val_loss: 0.5598 - val_categorical_accuracy: 0.8050 - lr: 9.7045e-04\n",
      "Epoch 32/230\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.6082 - categorical_accuracy: 0.7660 - val_loss: 0.6190 - val_categorical_accuracy: 0.7350 - lr: 9.4176e-04\n",
      "Epoch 33/230\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.5906 - categorical_accuracy: 0.7662 - val_loss: 1.2162 - val_categorical_accuracy: 0.7125 - lr: 9.1393e-04\n",
      "Epoch 34/230\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.5727 - categorical_accuracy: 0.7744 - val_loss: 0.4913 - val_categorical_accuracy: 0.8150 - lr: 8.8692e-04\n",
      "Epoch 35/230\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.5524 - categorical_accuracy: 0.7766 - val_loss: 0.5340 - val_categorical_accuracy: 0.7925 - lr: 8.6071e-04\n",
      "Epoch 36/230\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.5873 - categorical_accuracy: 0.7579 - val_loss: 0.5440 - val_categorical_accuracy: 0.7675 - lr: 8.3527e-04\n",
      "Epoch 37/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.5761 - categorical_accuracy: 0.7689 - val_loss: 0.5657 - val_categorical_accuracy: 0.7775 - lr: 8.1058e-04\n",
      "Epoch 38/230\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.5230 - categorical_accuracy: 0.7830 - val_loss: 0.4726 - val_categorical_accuracy: 0.8150 - lr: 7.8663e-04\n",
      "Epoch 39/230\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.5392 - categorical_accuracy: 0.7803 - val_loss: 0.7993 - val_categorical_accuracy: 0.7100 - lr: 7.6338e-04\n",
      "Epoch 40/230\n",
      "159/159 [==============================] - 123s 771ms/step - loss: 0.5119 - categorical_accuracy: 0.7926 - val_loss: 0.6879 - val_categorical_accuracy: 0.7000 - lr: 7.4082e-04\n",
      "Epoch 41/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5107 - categorical_accuracy: 0.7923 - val_loss: 1.1594 - val_categorical_accuracy: 0.7325 - lr: 7.1892e-04\n",
      "Epoch 42/230\n",
      "159/159 [==============================] - 63s 389ms/step - loss: 0.4935 - categorical_accuracy: 0.7986 - val_loss: 0.4587 - val_categorical_accuracy: 0.8325 - lr: 6.9768e-04\n",
      "Epoch 43/230\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.5247 - categorical_accuracy: 0.7920 - val_loss: 0.8038 - val_categorical_accuracy: 0.8125 - lr: 6.7706e-04\n",
      "Epoch 44/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4834 - categorical_accuracy: 0.8035 - val_loss: 0.4655 - val_categorical_accuracy: 0.8250 - lr: 6.5705e-04\n",
      "Epoch 45/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4950 - categorical_accuracy: 0.7950 - val_loss: 0.6949 - val_categorical_accuracy: 0.7500 - lr: 6.3763e-04\n",
      "Epoch 46/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4770 - categorical_accuracy: 0.8020 - val_loss: 0.5431 - val_categorical_accuracy: 0.8025 - lr: 6.1878e-04\n",
      "Epoch 47/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4687 - categorical_accuracy: 0.8113 - val_loss: 0.4809 - val_categorical_accuracy: 0.8025 - lr: 6.0050e-04\n",
      "Epoch 48/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4763 - categorical_accuracy: 0.8047 - val_loss: 0.4233 - val_categorical_accuracy: 0.8350 - lr: 5.8275e-04\n",
      "Epoch 49/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4827 - categorical_accuracy: 0.8039 - val_loss: 0.5735 - val_categorical_accuracy: 0.8100 - lr: 5.6553e-04\n",
      "Epoch 50/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4527 - categorical_accuracy: 0.8168 - val_loss: 0.4399 - val_categorical_accuracy: 0.8225 - lr: 5.4881e-04\n",
      "Epoch 51/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4608 - categorical_accuracy: 0.8105 - val_loss: 0.4712 - val_categorical_accuracy: 0.8300 - lr: 5.3259e-04\n",
      "Epoch 52/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4452 - categorical_accuracy: 0.8256 - val_loss: 0.4421 - val_categorical_accuracy: 0.8400 - lr: 5.1685e-04\n",
      "Epoch 53/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4428 - categorical_accuracy: 0.8176 - val_loss: 0.5088 - val_categorical_accuracy: 0.8125 - lr: 5.0158e-04\n",
      "Epoch 54/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4370 - categorical_accuracy: 0.8236 - val_loss: 0.4383 - val_categorical_accuracy: 0.8350 - lr: 4.8675e-04\n",
      "Epoch 55/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4373 - categorical_accuracy: 0.8286 - val_loss: 0.5691 - val_categorical_accuracy: 0.7975 - lr: 4.7237e-04\n",
      "Epoch 56/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4266 - categorical_accuracy: 0.8231 - val_loss: 0.4601 - val_categorical_accuracy: 0.8400 - lr: 4.5841e-04\n",
      "Epoch 57/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4259 - categorical_accuracy: 0.8289 - val_loss: 0.4283 - val_categorical_accuracy: 0.8575 - lr: 4.4486e-04\n",
      "Epoch 58/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4255 - categorical_accuracy: 0.8270 - val_loss: 0.5109 - val_categorical_accuracy: 0.8200 - lr: 4.3171e-04\n",
      "Epoch 59/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4210 - categorical_accuracy: 0.8321 - val_loss: 0.6933 - val_categorical_accuracy: 0.8325 - lr: 4.1895e-04\n",
      "Epoch 60/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4066 - categorical_accuracy: 0.8358 - val_loss: 0.4134 - val_categorical_accuracy: 0.8700 - lr: 4.0657e-04\n",
      "Epoch 61/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4138 - categorical_accuracy: 0.8360 - val_loss: 0.4472 - val_categorical_accuracy: 0.8600 - lr: 3.9455e-04\n",
      "Epoch 62/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3949 - categorical_accuracy: 0.8448 - val_loss: 0.4316 - val_categorical_accuracy: 0.8425 - lr: 3.8289e-04\n",
      "Epoch 63/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3987 - categorical_accuracy: 0.8332 - val_loss: 0.4434 - val_categorical_accuracy: 0.8475 - lr: 3.7158e-04\n",
      "Epoch 64/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3975 - categorical_accuracy: 0.8393 - val_loss: 0.4203 - val_categorical_accuracy: 0.8450 - lr: 3.6060e-04\n",
      "Epoch 65/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4500 - categorical_accuracy: 0.8256 - val_loss: 0.4918 - val_categorical_accuracy: 0.8150 - lr: 3.4994e-04\n",
      "Epoch 66/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4018 - categorical_accuracy: 0.8398 - val_loss: 0.4675 - val_categorical_accuracy: 0.8300 - lr: 3.3960e-04\n",
      "Epoch 67/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3995 - categorical_accuracy: 0.8399 - val_loss: 0.4688 - val_categorical_accuracy: 0.8525 - lr: 3.2956e-04\n",
      "Epoch 68/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3854 - categorical_accuracy: 0.8451 - val_loss: 0.4075 - val_categorical_accuracy: 0.8625 - lr: 3.1982e-04\n",
      "Epoch 69/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3858 - categorical_accuracy: 0.8456 - val_loss: 0.5290 - val_categorical_accuracy: 0.8300 - lr: 3.1037e-04\n",
      "Epoch 70/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3765 - categorical_accuracy: 0.8502 - val_loss: 0.4447 - val_categorical_accuracy: 0.8400 - lr: 3.0119e-04\n",
      "Epoch 71/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3714 - categorical_accuracy: 0.8513 - val_loss: 0.3858 - val_categorical_accuracy: 0.8475 - lr: 2.9229e-04\n",
      "Epoch 72/230\n",
      "159/159 [==============================] - 189s 1s/step - loss: 0.3670 - categorical_accuracy: 0.8500 - val_loss: 0.4333 - val_categorical_accuracy: 0.8400 - lr: 2.8365e-04\n",
      "Epoch 73/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3607 - categorical_accuracy: 0.8542 - val_loss: 0.4229 - val_categorical_accuracy: 0.8650 - lr: 2.7527e-04\n",
      "Epoch 74/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3610 - categorical_accuracy: 0.8579 - val_loss: 0.3802 - val_categorical_accuracy: 0.8525 - lr: 2.6714e-04\n",
      "Epoch 75/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3500 - categorical_accuracy: 0.8608 - val_loss: 0.4366 - val_categorical_accuracy: 0.8575 - lr: 2.5924e-04\n",
      "Epoch 76/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3476 - categorical_accuracy: 0.8602 - val_loss: 0.4225 - val_categorical_accuracy: 0.8475 - lr: 2.5158e-04\n",
      "Epoch 77/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3495 - categorical_accuracy: 0.8612 - val_loss: 0.4268 - val_categorical_accuracy: 0.8550 - lr: 2.4414e-04\n",
      "Epoch 78/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3427 - categorical_accuracy: 0.8640 - val_loss: 0.3924 - val_categorical_accuracy: 0.8600 - lr: 2.3693e-04\n",
      "Epoch 79/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3397 - categorical_accuracy: 0.8657 - val_loss: 0.4054 - val_categorical_accuracy: 0.8625 - lr: 2.2993e-04\n",
      "Epoch 80/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3389 - categorical_accuracy: 0.8671 - val_loss: 0.4700 - val_categorical_accuracy: 0.8275 - lr: 2.2313e-04\n",
      "Epoch 81/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3227 - categorical_accuracy: 0.8734 - val_loss: 0.5057 - val_categorical_accuracy: 0.8050 - lr: 2.1654e-04\n",
      "Epoch 82/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3252 - categorical_accuracy: 0.8745 - val_loss: 0.4357 - val_categorical_accuracy: 0.8525 - lr: 2.1014e-04\n",
      "Epoch 83/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3242 - categorical_accuracy: 0.8761 - val_loss: 0.4104 - val_categorical_accuracy: 0.8400 - lr: 2.0393e-04\n",
      "Epoch 84/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3282 - categorical_accuracy: 0.8720 - val_loss: 0.3964 - val_categorical_accuracy: 0.8725 - lr: 1.9790e-04\n",
      "Epoch 85/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3224 - categorical_accuracy: 0.8695 - val_loss: 0.3980 - val_categorical_accuracy: 0.8625 - lr: 1.9205e-04\n",
      "Epoch 86/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3148 - categorical_accuracy: 0.8748 - val_loss: 0.4100 - val_categorical_accuracy: 0.8650 - lr: 1.8637e-04\n",
      "Epoch 87/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3145 - categorical_accuracy: 0.8775 - val_loss: 0.4326 - val_categorical_accuracy: 0.8525 - lr: 1.8087e-04\n",
      "Epoch 88/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3128 - categorical_accuracy: 0.8792 - val_loss: 0.4156 - val_categorical_accuracy: 0.8550 - lr: 1.7552e-04\n",
      "Epoch 89/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2997 - categorical_accuracy: 0.8814 - val_loss: 0.3931 - val_categorical_accuracy: 0.8550 - lr: 1.7033e-04\n",
      "Epoch 90/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3105 - categorical_accuracy: 0.8788 - val_loss: 0.4323 - val_categorical_accuracy: 0.8800 - lr: 1.6530e-04\n",
      "Epoch 91/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3006 - categorical_accuracy: 0.8780 - val_loss: 0.5017 - val_categorical_accuracy: 0.8250 - lr: 1.6041e-04\n",
      "Epoch 92/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2965 - categorical_accuracy: 0.8807 - val_loss: 0.4100 - val_categorical_accuracy: 0.8650 - lr: 1.5567e-04\n",
      "Epoch 93/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3080 - categorical_accuracy: 0.8774 - val_loss: 0.4036 - val_categorical_accuracy: 0.8600 - lr: 1.5107e-04\n",
      "Epoch 94/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3139 - categorical_accuracy: 0.8803 - val_loss: 0.3765 - val_categorical_accuracy: 0.8750 - lr: 1.4661e-04\n",
      "Epoch 95/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3021 - categorical_accuracy: 0.8830 - val_loss: 0.3640 - val_categorical_accuracy: 0.8575 - lr: 1.4227e-04\n",
      "Epoch 96/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2915 - categorical_accuracy: 0.8854 - val_loss: 0.4608 - val_categorical_accuracy: 0.8600 - lr: 1.3807e-04\n",
      "Epoch 97/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2864 - categorical_accuracy: 0.8881 - val_loss: 0.4289 - val_categorical_accuracy: 0.8625 - lr: 1.3399e-04\n",
      "Epoch 98/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2913 - categorical_accuracy: 0.8874 - val_loss: 0.3916 - val_categorical_accuracy: 0.8550 - lr: 1.3003e-04\n",
      "Epoch 99/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2891 - categorical_accuracy: 0.8888 - val_loss: 0.3737 - val_categorical_accuracy: 0.8550 - lr: 1.2619e-04\n",
      "Epoch 100/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2887 - categorical_accuracy: 0.8876 - val_loss: 0.3784 - val_categorical_accuracy: 0.8600 - lr: 1.2246e-04\n",
      "Epoch 101/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2896 - categorical_accuracy: 0.8896 - val_loss: 0.4275 - val_categorical_accuracy: 0.8425 - lr: 1.1884e-04\n",
      "Epoch 102/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2724 - categorical_accuracy: 0.8926 - val_loss: 0.5099 - val_categorical_accuracy: 0.8400 - lr: 1.1533e-04\n",
      "Epoch 103/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2665 - categorical_accuracy: 0.8958 - val_loss: 0.3999 - val_categorical_accuracy: 0.8675 - lr: 1.1192e-04\n",
      "Epoch 104/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2543 - categorical_accuracy: 0.9005 - val_loss: 0.3961 - val_categorical_accuracy: 0.8450 - lr: 1.0861e-04\n",
      "Epoch 105/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2676 - categorical_accuracy: 0.8926 - val_loss: 0.3853 - val_categorical_accuracy: 0.8450 - lr: 1.0540e-04\n",
      "Epoch 106/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2699 - categorical_accuracy: 0.8967 - val_loss: 0.4288 - val_categorical_accuracy: 0.8625 - lr: 1.0228e-04\n",
      "Epoch 107/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2616 - categorical_accuracy: 0.8992 - val_loss: 0.4253 - val_categorical_accuracy: 0.8425 - lr: 9.9262e-05\n",
      "Epoch 108/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2558 - categorical_accuracy: 0.9020 - val_loss: 0.4072 - val_categorical_accuracy: 0.8550 - lr: 9.6328e-05\n",
      "Epoch 109/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2537 - categorical_accuracy: 0.9017 - val_loss: 0.4017 - val_categorical_accuracy: 0.8525 - lr: 9.3481e-05\n",
      "Epoch 110/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2525 - categorical_accuracy: 0.9008 - val_loss: 0.4166 - val_categorical_accuracy: 0.8525 - lr: 9.0718e-05\n",
      "Epoch 111/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2461 - categorical_accuracy: 0.9022 - val_loss: 0.4271 - val_categorical_accuracy: 0.8525 - lr: 8.8037e-05\n",
      "Epoch 112/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2476 - categorical_accuracy: 0.9019 - val_loss: 0.4741 - val_categorical_accuracy: 0.8150 - lr: 8.5435e-05\n",
      "Epoch 113/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2456 - categorical_accuracy: 0.9022 - val_loss: 0.4224 - val_categorical_accuracy: 0.8650 - lr: 8.2910e-05\n",
      "Epoch 114/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2452 - categorical_accuracy: 0.9017 - val_loss: 0.4780 - val_categorical_accuracy: 0.8500 - lr: 8.0460e-05\n",
      "Epoch 115/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2460 - categorical_accuracy: 0.9036 - val_loss: 0.4026 - val_categorical_accuracy: 0.8650 - lr: 7.8082e-05\n",
      "Epoch 116/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2482 - categorical_accuracy: 0.9066 - val_loss: 0.4164 - val_categorical_accuracy: 0.8400 - lr: 7.5774e-05\n",
      "Epoch 117/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2361 - categorical_accuracy: 0.9057 - val_loss: 0.4802 - val_categorical_accuracy: 0.8225 - lr: 7.3535e-05\n",
      "Epoch 118/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2392 - categorical_accuracy: 0.9118 - val_loss: 0.4086 - val_categorical_accuracy: 0.8450 - lr: 7.1362e-05\n",
      "Epoch 119/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2317 - categorical_accuracy: 0.9132 - val_loss: 0.4173 - val_categorical_accuracy: 0.8525 - lr: 6.9252e-05\n",
      "Epoch 120/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2386 - categorical_accuracy: 0.9108 - val_loss: 0.4191 - val_categorical_accuracy: 0.8475 - lr: 6.7206e-05\n",
      "Epoch 121/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2341 - categorical_accuracy: 0.9080 - val_loss: 0.4094 - val_categorical_accuracy: 0.8500 - lr: 6.5220e-05\n",
      "Epoch 122/230\n",
      "159/159 [==============================] - 189s 1s/step - loss: 0.2248 - categorical_accuracy: 0.9132 - val_loss: 0.3962 - val_categorical_accuracy: 0.8675 - lr: 6.3292e-05\n",
      "Epoch 123/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2268 - categorical_accuracy: 0.9142 - val_loss: 0.4326 - val_categorical_accuracy: 0.8475 - lr: 6.1421e-05\n",
      "Epoch 124/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2214 - categorical_accuracy: 0.9127 - val_loss: 0.4158 - val_categorical_accuracy: 0.8550 - lr: 5.9606e-05\n",
      "Epoch 125/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2351 - categorical_accuracy: 0.9115 - val_loss: 0.3779 - val_categorical_accuracy: 0.8550 - lr: 5.7845e-05\n",
      "Epoch 126/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2224 - categorical_accuracy: 0.9164 - val_loss: 0.3960 - val_categorical_accuracy: 0.8650 - lr: 5.6135e-05\n",
      "Epoch 127/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2223 - categorical_accuracy: 0.9119 - val_loss: 0.3909 - val_categorical_accuracy: 0.8525 - lr: 5.4476e-05\n",
      "Epoch 128/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2206 - categorical_accuracy: 0.9123 - val_loss: 0.3892 - val_categorical_accuracy: 0.8500 - lr: 5.2866e-05\n",
      "Epoch 129/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2240 - categorical_accuracy: 0.9151 - val_loss: 0.3922 - val_categorical_accuracy: 0.8600 - lr: 5.1304e-05\n",
      "Epoch 130/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2235 - categorical_accuracy: 0.9116 - val_loss: 0.4162 - val_categorical_accuracy: 0.8525 - lr: 4.9787e-05\n",
      "Epoch 131/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2161 - categorical_accuracy: 0.9135 - val_loss: 0.3919 - val_categorical_accuracy: 0.8575 - lr: 4.8316e-05\n",
      "Epoch 132/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2096 - categorical_accuracy: 0.9178 - val_loss: 0.3852 - val_categorical_accuracy: 0.8650 - lr: 4.6888e-05\n",
      "Epoch 133/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2050 - categorical_accuracy: 0.9192 - val_loss: 0.3957 - val_categorical_accuracy: 0.8625 - lr: 4.5502e-05\n",
      "Epoch 134/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2149 - categorical_accuracy: 0.9149 - val_loss: 0.4070 - val_categorical_accuracy: 0.8525 - lr: 4.4157e-05\n",
      "Epoch 135/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2124 - categorical_accuracy: 0.9182 - val_loss: 0.4198 - val_categorical_accuracy: 0.8400 - lr: 4.2852e-05\n",
      "Epoch 136/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2131 - categorical_accuracy: 0.9197 - val_loss: 0.4131 - val_categorical_accuracy: 0.8650 - lr: 4.1586e-05\n",
      "Epoch 137/230\n",
      "159/159 [==============================] - 189s 1s/step - loss: 0.2099 - categorical_accuracy: 0.9173 - val_loss: 0.4074 - val_categorical_accuracy: 0.8575 - lr: 4.0357e-05\n",
      "Epoch 138/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1998 - categorical_accuracy: 0.9259 - val_loss: 0.3838 - val_categorical_accuracy: 0.8525 - lr: 3.9164e-05\n",
      "Epoch 139/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2125 - categorical_accuracy: 0.9167 - val_loss: 0.3989 - val_categorical_accuracy: 0.8600 - lr: 3.8007e-05\n",
      "Epoch 140/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2117 - categorical_accuracy: 0.9190 - val_loss: 0.3890 - val_categorical_accuracy: 0.8525 - lr: 3.6883e-05\n",
      "Epoch 141/230\n",
      "159/159 [==============================] - 189s 1s/step - loss: 0.2103 - categorical_accuracy: 0.9182 - val_loss: 0.4090 - val_categorical_accuracy: 0.8650 - lr: 3.5793e-05\n",
      "Epoch 142/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2049 - categorical_accuracy: 0.9248 - val_loss: 0.4090 - val_categorical_accuracy: 0.8550 - lr: 3.4735e-05\n",
      "Epoch 143/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2060 - categorical_accuracy: 0.9219 - val_loss: 0.4185 - val_categorical_accuracy: 0.8475 - lr: 3.3709e-05\n",
      "Epoch 144/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1980 - categorical_accuracy: 0.9248 - val_loss: 0.3872 - val_categorical_accuracy: 0.8550 - lr: 3.2713e-05\n",
      "Epoch 145/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2083 - categorical_accuracy: 0.9184 - val_loss: 0.4123 - val_categorical_accuracy: 0.8550 - lr: 3.1746e-05\n",
      "Epoch 146/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2029 - categorical_accuracy: 0.9182 - val_loss: 0.3943 - val_categorical_accuracy: 0.8600 - lr: 3.0808e-05\n",
      "Epoch 147/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1879 - categorical_accuracy: 0.9283 - val_loss: 0.4015 - val_categorical_accuracy: 0.8525 - lr: 2.9897e-05\n",
      "Epoch 148/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1990 - categorical_accuracy: 0.9256 - val_loss: 0.4038 - val_categorical_accuracy: 0.8525 - lr: 2.9013e-05\n",
      "Epoch 149/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.1971 - categorical_accuracy: 0.9253 - val_loss: 0.3982 - val_categorical_accuracy: 0.8575 - lr: 2.8156e-05\n",
      "Epoch 150/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1879 - categorical_accuracy: 0.9278 - val_loss: 0.3967 - val_categorical_accuracy: 0.8475 - lr: 2.7324e-05\n",
      "Epoch 151/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1956 - categorical_accuracy: 0.9269 - val_loss: 0.3898 - val_categorical_accuracy: 0.8600 - lr: 2.6516e-05\n",
      "Epoch 152/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.1885 - categorical_accuracy: 0.9274 - val_loss: 0.3968 - val_categorical_accuracy: 0.8575 - lr: 2.5733e-05\n",
      "Epoch 153/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1868 - categorical_accuracy: 0.9266 - val_loss: 0.4022 - val_categorical_accuracy: 0.8525 - lr: 2.4972e-05\n",
      "Epoch 154/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1861 - categorical_accuracy: 0.9303 - val_loss: 0.3859 - val_categorical_accuracy: 0.8575 - lr: 2.4234e-05\n",
      "Epoch 155/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1925 - categorical_accuracy: 0.9259 - val_loss: 0.3822 - val_categorical_accuracy: 0.8575 - lr: 2.3518e-05\n",
      "Epoch 156/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1925 - categorical_accuracy: 0.9252 - val_loss: 0.3913 - val_categorical_accuracy: 0.8550 - lr: 2.2823e-05\n",
      "Epoch 157/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1981 - categorical_accuracy: 0.9193 - val_loss: 0.4051 - val_categorical_accuracy: 0.8600 - lr: 2.2148e-05\n",
      "Epoch 158/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.1853 - categorical_accuracy: 0.9272 - val_loss: 0.3933 - val_categorical_accuracy: 0.8525 - lr: 2.1494e-05\n",
      "Epoch 159/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1790 - categorical_accuracy: 0.9340 - val_loss: 0.3934 - val_categorical_accuracy: 0.8575 - lr: 2.0858e-05\n",
      "Epoch 160/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1902 - categorical_accuracy: 0.9237 - val_loss: 0.4210 - val_categorical_accuracy: 0.8600 - lr: 2.0242e-05\n",
      "Epoch 161/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1926 - categorical_accuracy: 0.9269 - val_loss: 0.4109 - val_categorical_accuracy: 0.8600 - lr: 1.9644e-05\n",
      "Epoch 162/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1828 - categorical_accuracy: 0.9314 - val_loss: 0.3957 - val_categorical_accuracy: 0.8600 - lr: 1.9063e-05\n",
      "Epoch 163/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1792 - categorical_accuracy: 0.9346 - val_loss: 0.4008 - val_categorical_accuracy: 0.8575 - lr: 1.8500e-05\n",
      "Epoch 164/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1862 - categorical_accuracy: 0.9277 - val_loss: 0.4037 - val_categorical_accuracy: 0.8450 - lr: 1.7953e-05\n",
      "Epoch 165/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.1761 - categorical_accuracy: 0.9299 - val_loss: 0.3949 - val_categorical_accuracy: 0.8550 - lr: 1.7422e-05\n",
      "Epoch 166/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1826 - categorical_accuracy: 0.9307 - val_loss: 0.3909 - val_categorical_accuracy: 0.8575 - lr: 1.6908e-05\n",
      "Epoch 167/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1834 - categorical_accuracy: 0.9294 - val_loss: 0.3974 - val_categorical_accuracy: 0.8550 - lr: 1.6408e-05\n",
      "Epoch 168/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1732 - categorical_accuracy: 0.9343 - val_loss: 0.3973 - val_categorical_accuracy: 0.8550 - lr: 1.5923e-05\n",
      "Epoch 169/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1795 - categorical_accuracy: 0.9313 - val_loss: 0.3919 - val_categorical_accuracy: 0.8625 - lr: 1.5452e-05\n",
      "Epoch 170/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1719 - categorical_accuracy: 0.9336 - val_loss: 0.4026 - val_categorical_accuracy: 0.8500 - lr: 1.4996e-05\n",
      "Epoch 171/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.1752 - categorical_accuracy: 0.9355 - val_loss: 0.3891 - val_categorical_accuracy: 0.8625 - lr: 1.4552e-05\n",
      "Epoch 172/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1746 - categorical_accuracy: 0.9329 - val_loss: 0.4050 - val_categorical_accuracy: 0.8525 - lr: 1.4122e-05\n",
      "Epoch 173/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1785 - categorical_accuracy: 0.9302 - val_loss: 0.4107 - val_categorical_accuracy: 0.8550 - lr: 1.3705e-05\n",
      "Epoch 174/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1760 - categorical_accuracy: 0.9343 - val_loss: 0.3907 - val_categorical_accuracy: 0.8600 - lr: 1.3300e-05\n",
      "Epoch 175/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1817 - categorical_accuracy: 0.9278 - val_loss: 0.4112 - val_categorical_accuracy: 0.8550 - lr: 1.2907e-05\n",
      "Epoch 176/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1720 - categorical_accuracy: 0.9349 - val_loss: 0.3919 - val_categorical_accuracy: 0.8575 - lr: 1.2525e-05\n",
      "Epoch 177/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1743 - categorical_accuracy: 0.9336 - val_loss: 0.4088 - val_categorical_accuracy: 0.8500 - lr: 1.2155e-05\n",
      "Epoch 178/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1690 - categorical_accuracy: 0.9363 - val_loss: 0.4074 - val_categorical_accuracy: 0.8525 - lr: 1.1796e-05\n",
      "Epoch 179/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1690 - categorical_accuracy: 0.9307 - val_loss: 0.4138 - val_categorical_accuracy: 0.8500 - lr: 1.1447e-05\n",
      "Epoch 180/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1709 - categorical_accuracy: 0.9349 - val_loss: 0.4067 - val_categorical_accuracy: 0.8625 - lr: 1.1109e-05\n",
      "Epoch 181/230\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.1679 - categorical_accuracy: 0.9354 - val_loss: 0.4092 - val_categorical_accuracy: 0.8525 - lr: 1.0781e-05\n",
      "Epoch 182/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1669 - categorical_accuracy: 0.9396 - val_loss: 0.4101 - val_categorical_accuracy: 0.8500 - lr: 1.0462e-05\n",
      "Epoch 183/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1728 - categorical_accuracy: 0.9349 - val_loss: 0.4077 - val_categorical_accuracy: 0.8550 - lr: 1.0153e-05\n",
      "Epoch 184/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1673 - categorical_accuracy: 0.9396 - val_loss: 0.4106 - val_categorical_accuracy: 0.8450 - lr: 9.8529e-06\n",
      "Epoch 185/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1666 - categorical_accuracy: 0.9363 - val_loss: 0.4173 - val_categorical_accuracy: 0.8450 - lr: 9.5617e-06\n",
      "Epoch 186/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1608 - categorical_accuracy: 0.9385 - val_loss: 0.4194 - val_categorical_accuracy: 0.8425 - lr: 9.2791e-06\n",
      "Epoch 187/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1767 - categorical_accuracy: 0.9327 - val_loss: 0.4148 - val_categorical_accuracy: 0.8475 - lr: 9.0048e-06\n",
      "Epoch 188/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1730 - categorical_accuracy: 0.9351 - val_loss: 0.4183 - val_categorical_accuracy: 0.8550 - lr: 8.7387e-06\n",
      "Epoch 189/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1690 - categorical_accuracy: 0.9343 - val_loss: 0.4085 - val_categorical_accuracy: 0.8475 - lr: 8.4804e-06\n",
      "Epoch 190/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1717 - categorical_accuracy: 0.9333 - val_loss: 0.4164 - val_categorical_accuracy: 0.8450 - lr: 8.2298e-06\n",
      "Epoch 191/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1714 - categorical_accuracy: 0.9336 - val_loss: 0.4088 - val_categorical_accuracy: 0.8500 - lr: 7.9866e-06\n",
      "Epoch 192/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1679 - categorical_accuracy: 0.9349 - val_loss: 0.4109 - val_categorical_accuracy: 0.8450 - lr: 7.7505e-06\n",
      "Epoch 193/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1701 - categorical_accuracy: 0.9351 - val_loss: 0.4113 - val_categorical_accuracy: 0.8450 - lr: 7.5215e-06\n",
      "Epoch 194/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1733 - categorical_accuracy: 0.9365 - val_loss: 0.4118 - val_categorical_accuracy: 0.8550 - lr: 7.2992e-06\n",
      "Epoch 195/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1624 - categorical_accuracy: 0.9399 - val_loss: 0.4096 - val_categorical_accuracy: 0.8525 - lr: 7.0835e-06\n",
      "Epoch 196/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1666 - categorical_accuracy: 0.9365 - val_loss: 0.4076 - val_categorical_accuracy: 0.8500 - lr: 6.8741e-06\n",
      "Epoch 197/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1682 - categorical_accuracy: 0.9352 - val_loss: 0.4152 - val_categorical_accuracy: 0.8450 - lr: 6.6709e-06\n",
      "Epoch 198/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1625 - categorical_accuracy: 0.9388 - val_loss: 0.4097 - val_categorical_accuracy: 0.8425 - lr: 6.4738e-06\n",
      "Epoch 199/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1617 - categorical_accuracy: 0.9415 - val_loss: 0.4181 - val_categorical_accuracy: 0.8500 - lr: 6.2825e-06\n",
      "Epoch 200/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1682 - categorical_accuracy: 0.9382 - val_loss: 0.4115 - val_categorical_accuracy: 0.8450 - lr: 6.0968e-06\n",
      "Epoch 201/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1687 - categorical_accuracy: 0.9352 - val_loss: 0.4076 - val_categorical_accuracy: 0.8450 - lr: 5.9166e-06\n",
      "Epoch 202/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1639 - categorical_accuracy: 0.9376 - val_loss: 0.4194 - val_categorical_accuracy: 0.8400 - lr: 5.7417e-06\n",
      "Epoch 203/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1572 - categorical_accuracy: 0.9392 - val_loss: 0.4209 - val_categorical_accuracy: 0.8450 - lr: 5.5720e-06\n",
      "Epoch 204/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1658 - categorical_accuracy: 0.9365 - val_loss: 0.4256 - val_categorical_accuracy: 0.8450 - lr: 5.4074e-06\n",
      "Epoch 205/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1571 - categorical_accuracy: 0.9417 - val_loss: 0.4205 - val_categorical_accuracy: 0.8475 - lr: 5.2476e-06\n",
      "Epoch 206/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1667 - categorical_accuracy: 0.9363 - val_loss: 0.4220 - val_categorical_accuracy: 0.8450 - lr: 5.0925e-06\n",
      "Epoch 207/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1647 - categorical_accuracy: 0.9385 - val_loss: 0.4223 - val_categorical_accuracy: 0.8500 - lr: 4.9420e-06\n",
      "Epoch 208/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1556 - categorical_accuracy: 0.9418 - val_loss: 0.4154 - val_categorical_accuracy: 0.8500 - lr: 4.7959e-06\n",
      "Epoch 209/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1653 - categorical_accuracy: 0.9347 - val_loss: 0.4221 - val_categorical_accuracy: 0.8450 - lr: 4.6542e-06\n",
      "Epoch 210/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1601 - categorical_accuracy: 0.9401 - val_loss: 0.4188 - val_categorical_accuracy: 0.8525 - lr: 4.5166e-06\n",
      "Epoch 211/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1614 - categorical_accuracy: 0.9396 - val_loss: 0.4197 - val_categorical_accuracy: 0.8450 - lr: 4.3831e-06\n",
      "Epoch 212/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1635 - categorical_accuracy: 0.9387 - val_loss: 0.4178 - val_categorical_accuracy: 0.8600 - lr: 4.2536e-06\n",
      "Epoch 213/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1571 - categorical_accuracy: 0.9409 - val_loss: 0.4215 - val_categorical_accuracy: 0.8500 - lr: 4.1279e-06\n",
      "Epoch 214/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1619 - categorical_accuracy: 0.9404 - val_loss: 0.4188 - val_categorical_accuracy: 0.8475 - lr: 4.0059e-06\n",
      "Epoch 215/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1741 - categorical_accuracy: 0.9346 - val_loss: 0.4290 - val_categorical_accuracy: 0.8500 - lr: 3.8875e-06\n",
      "Epoch 216/230\n",
      "159/159 [==============================] - 189s 1s/step - loss: 0.1650 - categorical_accuracy: 0.9340 - val_loss: 0.4264 - val_categorical_accuracy: 0.8425 - lr: 3.7726e-06\n",
      "Epoch 217/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1595 - categorical_accuracy: 0.9420 - val_loss: 0.4227 - val_categorical_accuracy: 0.8450 - lr: 3.6611e-06\n",
      "Epoch 218/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1588 - categorical_accuracy: 0.9414 - val_loss: 0.4206 - val_categorical_accuracy: 0.8500 - lr: 3.5529e-06\n",
      "Epoch 219/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1617 - categorical_accuracy: 0.9377 - val_loss: 0.4213 - val_categorical_accuracy: 0.8525 - lr: 3.4479e-06\n",
      "Epoch 220/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1696 - categorical_accuracy: 0.9390 - val_loss: 0.4269 - val_categorical_accuracy: 0.8475 - lr: 3.3460e-06\n",
      "Epoch 221/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1622 - categorical_accuracy: 0.9377 - val_loss: 0.4181 - val_categorical_accuracy: 0.8500 - lr: 3.2471e-06\n",
      "Epoch 222/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1522 - categorical_accuracy: 0.9436 - val_loss: 0.4207 - val_categorical_accuracy: 0.8475 - lr: 3.1511e-06\n",
      "Epoch 223/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1643 - categorical_accuracy: 0.9373 - val_loss: 0.4162 - val_categorical_accuracy: 0.8525 - lr: 3.0580e-06\n",
      "Epoch 224/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1626 - categorical_accuracy: 0.9387 - val_loss: 0.4195 - val_categorical_accuracy: 0.8500 - lr: 2.9676e-06\n",
      "Epoch 225/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1674 - categorical_accuracy: 0.9338 - val_loss: 0.4218 - val_categorical_accuracy: 0.8525 - lr: 2.8799e-06\n",
      "Epoch 226/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1580 - categorical_accuracy: 0.9414 - val_loss: 0.4212 - val_categorical_accuracy: 0.8550 - lr: 2.7948e-06\n",
      "Epoch 227/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1641 - categorical_accuracy: 0.9355 - val_loss: 0.4175 - val_categorical_accuracy: 0.8475 - lr: 2.7122e-06\n",
      "Epoch 228/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1497 - categorical_accuracy: 0.9423 - val_loss: 0.4219 - val_categorical_accuracy: 0.8450 - lr: 2.6321e-06\n",
      "Epoch 229/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1611 - categorical_accuracy: 0.9358 - val_loss: 0.4233 - val_categorical_accuracy: 0.8450 - lr: 2.5543e-06\n",
      "Epoch 230/230\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1621 - categorical_accuracy: 0.9369 - val_loss: 0.4234 - val_categorical_accuracy: 0.8500 - lr: 2.4788e-06\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='softmax'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=None ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/threemod/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.03)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "model.build()\n",
    "model.summary()\n",
    "\n",
    "# now with normalisation\n",
    "epochs=230\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=10,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f17bc799-664c-4881-b9dd-a9b50687ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_14 (Sequential)  (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,686,322\n",
      "Trainable params: 23,633,202\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Epoch 1/240\n",
      "159/159 [==============================] - 201s 1s/step - loss: 2.6153 - categorical_accuracy: 0.5329 - val_loss: 1.1494 - val_categorical_accuracy: 0.5250 - lr: 0.0010\n",
      "Epoch 2/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.9195 - categorical_accuracy: 0.6296 - val_loss: 256.3996 - val_categorical_accuracy: 0.5850 - lr: 0.0010\n",
      "Epoch 3/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.2533 - categorical_accuracy: 0.6786 - val_loss: 0.6319 - val_categorical_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 4/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.1229 - categorical_accuracy: 0.7270 - val_loss: 0.6043 - val_categorical_accuracy: 0.7675 - lr: 0.0010\n",
      "Epoch 5/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.1210 - categorical_accuracy: 0.7352 - val_loss: 137.8410 - val_categorical_accuracy: 0.6175 - lr: 0.0010\n",
      "Epoch 6/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.9097 - categorical_accuracy: 0.7387 - val_loss: 0.6857 - val_categorical_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 7/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.9063 - categorical_accuracy: 0.6906 - val_loss: 94.3377 - val_categorical_accuracy: 0.5250 - lr: 0.0010\n",
      "Epoch 8/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.7569 - categorical_accuracy: 0.7008 - val_loss: 0.7553 - val_categorical_accuracy: 0.6950 - lr: 0.0010\n",
      "Epoch 9/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.1468 - categorical_accuracy: 0.6533 - val_loss: 1.1018 - val_categorical_accuracy: 0.5300 - lr: 0.0010\n",
      "Epoch 10/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.9737 - categorical_accuracy: 0.5028 - val_loss: 420.6663 - val_categorical_accuracy: 0.4875 - lr: 0.0010\n",
      "Epoch 11/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.2271 - categorical_accuracy: 0.5616 - val_loss: 1.0095 - val_categorical_accuracy: 0.4475 - lr: 0.0010\n",
      "Epoch 12/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.0745 - categorical_accuracy: 0.5871 - val_loss: 4.0932 - val_categorical_accuracy: 0.6075 - lr: 0.0010\n",
      "Epoch 13/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.9327 - categorical_accuracy: 0.6016 - val_loss: 0.9251 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 14/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 1.3993 - categorical_accuracy: 0.5715 - val_loss: 0.9803 - val_categorical_accuracy: 0.5600 - lr: 0.0010\n",
      "Epoch 15/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.2450 - categorical_accuracy: 0.5695 - val_loss: 0.9472 - val_categorical_accuracy: 0.5650 - lr: 0.0010\n",
      "Epoch 16/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.9762 - categorical_accuracy: 0.5975 - val_loss: 1.5022 - val_categorical_accuracy: 0.6425 - lr: 0.0010\n",
      "Epoch 17/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 1.0105 - categorical_accuracy: 0.6014 - val_loss: 1.9513 - val_categorical_accuracy: 0.6350 - lr: 0.0010\n",
      "Epoch 18/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.9349 - categorical_accuracy: 0.6146 - val_loss: 2.5488 - val_categorical_accuracy: 0.6625 - lr: 0.0010\n",
      "Epoch 19/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.8780 - categorical_accuracy: 0.6270 - val_loss: 0.7620 - val_categorical_accuracy: 0.6725 - lr: 0.0010\n",
      "Epoch 20/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.8649 - categorical_accuracy: 0.6396 - val_loss: 1.5506 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n",
      "Epoch 21/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.8056 - categorical_accuracy: 0.6608 - val_loss: 0.7444 - val_categorical_accuracy: 0.6550 - lr: 0.0010\n",
      "Epoch 22/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.7622 - categorical_accuracy: 0.6854 - val_loss: 13.9043 - val_categorical_accuracy: 0.6950 - lr: 0.0010\n",
      "Epoch 23/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.7220 - categorical_accuracy: 0.7047 - val_loss: 0.7686 - val_categorical_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 24/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.6761 - categorical_accuracy: 0.7178 - val_loss: 0.6377 - val_categorical_accuracy: 0.7625 - lr: 0.0010\n",
      "Epoch 25/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.6645 - categorical_accuracy: 0.7217 - val_loss: 0.6092 - val_categorical_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 26/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.6544 - categorical_accuracy: 0.7308 - val_loss: 0.6713 - val_categorical_accuracy: 0.7325 - lr: 0.0010\n",
      "Epoch 27/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.6435 - categorical_accuracy: 0.7330 - val_loss: 1.9011 - val_categorical_accuracy: 0.7450 - lr: 0.0010\n",
      "Epoch 28/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.6120 - categorical_accuracy: 0.7467 - val_loss: 0.6217 - val_categorical_accuracy: 0.7325 - lr: 0.0010\n",
      "Epoch 29/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.6499 - categorical_accuracy: 0.7351 - val_loss: 18.9678 - val_categorical_accuracy: 0.7125 - lr: 0.0010\n",
      "Epoch 30/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.6202 - categorical_accuracy: 0.7417 - val_loss: 0.6465 - val_categorical_accuracy: 0.7675 - lr: 0.0010\n",
      "Epoch 31/240\n",
      "159/159 [==============================] - 190s 1s/step - loss: 0.6062 - categorical_accuracy: 0.7519 - val_loss: 0.5446 - val_categorical_accuracy: 0.7925 - lr: 9.7045e-04\n",
      "Epoch 32/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.6173 - categorical_accuracy: 0.7497 - val_loss: 0.5623 - val_categorical_accuracy: 0.7600 - lr: 9.4176e-04\n",
      "Epoch 33/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.5869 - categorical_accuracy: 0.7566 - val_loss: 0.5342 - val_categorical_accuracy: 0.7800 - lr: 9.1393e-04\n",
      "Epoch 34/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5764 - categorical_accuracy: 0.7612 - val_loss: 0.5709 - val_categorical_accuracy: 0.7400 - lr: 8.8692e-04\n",
      "Epoch 35/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5757 - categorical_accuracy: 0.7579 - val_loss: 0.5251 - val_categorical_accuracy: 0.7875 - lr: 8.6071e-04\n",
      "Epoch 36/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5757 - categorical_accuracy: 0.7615 - val_loss: 0.5254 - val_categorical_accuracy: 0.8000 - lr: 8.3527e-04\n",
      "Epoch 37/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.5705 - categorical_accuracy: 0.7637 - val_loss: 0.5125 - val_categorical_accuracy: 0.8025 - lr: 8.1058e-04\n",
      "Epoch 38/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5959 - categorical_accuracy: 0.7572 - val_loss: 3.9203 - val_categorical_accuracy: 0.7475 - lr: 7.8663e-04\n",
      "Epoch 39/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.5821 - categorical_accuracy: 0.7586 - val_loss: 0.6396 - val_categorical_accuracy: 0.7650 - lr: 7.6338e-04\n",
      "Epoch 40/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.5493 - categorical_accuracy: 0.7737 - val_loss: 0.5448 - val_categorical_accuracy: 0.7575 - lr: 7.4082e-04\n",
      "Epoch 41/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5498 - categorical_accuracy: 0.7777 - val_loss: 0.5206 - val_categorical_accuracy: 0.7975 - lr: 7.1892e-04\n",
      "Epoch 42/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5468 - categorical_accuracy: 0.7742 - val_loss: 0.5110 - val_categorical_accuracy: 0.7875 - lr: 6.9768e-04\n",
      "Epoch 43/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5494 - categorical_accuracy: 0.7766 - val_loss: 0.5019 - val_categorical_accuracy: 0.7975 - lr: 6.7706e-04\n",
      "Epoch 44/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5436 - categorical_accuracy: 0.7761 - val_loss: 0.6719 - val_categorical_accuracy: 0.8025 - lr: 6.5705e-04\n",
      "Epoch 45/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5239 - categorical_accuracy: 0.7800 - val_loss: 0.4834 - val_categorical_accuracy: 0.8075 - lr: 6.3763e-04\n",
      "Epoch 46/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5183 - categorical_accuracy: 0.7818 - val_loss: 0.5132 - val_categorical_accuracy: 0.7825 - lr: 6.1878e-04\n",
      "Epoch 47/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5094 - categorical_accuracy: 0.7901 - val_loss: 0.5355 - val_categorical_accuracy: 0.7675 - lr: 6.0050e-04\n",
      "Epoch 48/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5032 - categorical_accuracy: 0.7907 - val_loss: 0.4967 - val_categorical_accuracy: 0.8250 - lr: 5.8275e-04\n",
      "Epoch 49/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5048 - categorical_accuracy: 0.7940 - val_loss: 0.4793 - val_categorical_accuracy: 0.8175 - lr: 5.6553e-04\n",
      "Epoch 50/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4888 - categorical_accuracy: 0.8013 - val_loss: 0.5547 - val_categorical_accuracy: 0.7700 - lr: 5.4881e-04\n",
      "Epoch 51/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4816 - categorical_accuracy: 0.8049 - val_loss: 0.6830 - val_categorical_accuracy: 0.7650 - lr: 5.3259e-04\n",
      "Epoch 52/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4883 - categorical_accuracy: 0.7970 - val_loss: 0.7454 - val_categorical_accuracy: 0.7100 - lr: 5.1685e-04\n",
      "Epoch 53/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5987 - categorical_accuracy: 0.7811 - val_loss: 0.7822 - val_categorical_accuracy: 0.7950 - lr: 5.0158e-04\n",
      "Epoch 54/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.5292 - categorical_accuracy: 0.7984 - val_loss: 0.6935 - val_categorical_accuracy: 0.7625 - lr: 4.8675e-04\n",
      "Epoch 55/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.5114 - categorical_accuracy: 0.7964 - val_loss: 0.4714 - val_categorical_accuracy: 0.8175 - lr: 4.7237e-04\n",
      "Epoch 56/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4679 - categorical_accuracy: 0.8137 - val_loss: 2.2778 - val_categorical_accuracy: 0.7550 - lr: 4.5841e-04\n",
      "Epoch 57/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4505 - categorical_accuracy: 0.8182 - val_loss: 0.9077 - val_categorical_accuracy: 0.8225 - lr: 4.4486e-04\n",
      "Epoch 58/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4428 - categorical_accuracy: 0.8226 - val_loss: 0.4770 - val_categorical_accuracy: 0.8250 - lr: 4.3171e-04\n",
      "Epoch 59/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4447 - categorical_accuracy: 0.8212 - val_loss: 0.4217 - val_categorical_accuracy: 0.8250 - lr: 4.1895e-04\n",
      "Epoch 60/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4250 - categorical_accuracy: 0.8272 - val_loss: 0.4955 - val_categorical_accuracy: 0.8050 - lr: 4.0657e-04\n",
      "Epoch 61/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4327 - categorical_accuracy: 0.8247 - val_loss: 0.8202 - val_categorical_accuracy: 0.7900 - lr: 3.9455e-04\n",
      "Epoch 62/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4286 - categorical_accuracy: 0.8275 - val_loss: 0.4389 - val_categorical_accuracy: 0.8375 - lr: 3.8289e-04\n",
      "Epoch 63/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4308 - categorical_accuracy: 0.8278 - val_loss: 0.4544 - val_categorical_accuracy: 0.8075 - lr: 3.7158e-04\n",
      "Epoch 64/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4216 - categorical_accuracy: 0.8325 - val_loss: 0.3853 - val_categorical_accuracy: 0.8550 - lr: 3.6060e-04\n",
      "Epoch 65/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4129 - categorical_accuracy: 0.8355 - val_loss: 0.5055 - val_categorical_accuracy: 0.8050 - lr: 3.4994e-04\n",
      "Epoch 66/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.4033 - categorical_accuracy: 0.8381 - val_loss: 0.3810 - val_categorical_accuracy: 0.8575 - lr: 3.3960e-04\n",
      "Epoch 67/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4086 - categorical_accuracy: 0.8373 - val_loss: 0.4711 - val_categorical_accuracy: 0.8125 - lr: 3.2956e-04\n",
      "Epoch 68/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.4009 - categorical_accuracy: 0.8377 - val_loss: 0.4170 - val_categorical_accuracy: 0.8325 - lr: 3.1982e-04\n",
      "Epoch 69/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3896 - categorical_accuracy: 0.8445 - val_loss: 0.4068 - val_categorical_accuracy: 0.8450 - lr: 3.1037e-04\n",
      "Epoch 70/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3824 - categorical_accuracy: 0.8497 - val_loss: 0.4169 - val_categorical_accuracy: 0.8500 - lr: 3.0119e-04\n",
      "Epoch 71/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3812 - categorical_accuracy: 0.8459 - val_loss: 0.4065 - val_categorical_accuracy: 0.8475 - lr: 2.9229e-04\n",
      "Epoch 72/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3848 - categorical_accuracy: 0.8429 - val_loss: 0.4465 - val_categorical_accuracy: 0.8325 - lr: 2.8365e-04\n",
      "Epoch 73/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3796 - categorical_accuracy: 0.8447 - val_loss: 0.5531 - val_categorical_accuracy: 0.8075 - lr: 2.7527e-04\n",
      "Epoch 74/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3841 - categorical_accuracy: 0.8486 - val_loss: 0.3945 - val_categorical_accuracy: 0.8475 - lr: 2.6714e-04\n",
      "Epoch 75/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3708 - categorical_accuracy: 0.8511 - val_loss: 0.3998 - val_categorical_accuracy: 0.8600 - lr: 2.5924e-04\n",
      "Epoch 76/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3655 - categorical_accuracy: 0.8517 - val_loss: 0.4103 - val_categorical_accuracy: 0.8575 - lr: 2.5158e-04\n",
      "Epoch 77/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3543 - categorical_accuracy: 0.8619 - val_loss: 0.3816 - val_categorical_accuracy: 0.8600 - lr: 2.4414e-04\n",
      "Epoch 78/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3669 - categorical_accuracy: 0.8530 - val_loss: 0.3738 - val_categorical_accuracy: 0.8600 - lr: 2.3693e-04\n",
      "Epoch 79/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3590 - categorical_accuracy: 0.8571 - val_loss: 0.4100 - val_categorical_accuracy: 0.8600 - lr: 2.2993e-04\n",
      "Epoch 80/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3529 - categorical_accuracy: 0.8624 - val_loss: 0.4018 - val_categorical_accuracy: 0.8450 - lr: 2.2313e-04\n",
      "Epoch 81/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3505 - categorical_accuracy: 0.8634 - val_loss: 0.3675 - val_categorical_accuracy: 0.8600 - lr: 2.1654e-04\n",
      "Epoch 82/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3440 - categorical_accuracy: 0.8640 - val_loss: 0.4781 - val_categorical_accuracy: 0.8200 - lr: 2.1014e-04\n",
      "Epoch 83/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3382 - categorical_accuracy: 0.8668 - val_loss: 0.3891 - val_categorical_accuracy: 0.8575 - lr: 2.0393e-04\n",
      "Epoch 84/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3456 - categorical_accuracy: 0.8583 - val_loss: 0.4045 - val_categorical_accuracy: 0.8425 - lr: 1.9790e-04\n",
      "Epoch 85/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3334 - categorical_accuracy: 0.8704 - val_loss: 0.4019 - val_categorical_accuracy: 0.8525 - lr: 1.9205e-04\n",
      "Epoch 86/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3337 - categorical_accuracy: 0.8668 - val_loss: 0.4337 - val_categorical_accuracy: 0.8250 - lr: 1.8637e-04\n",
      "Epoch 87/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3290 - categorical_accuracy: 0.8675 - val_loss: 0.5372 - val_categorical_accuracy: 0.7775 - lr: 1.8087e-04\n",
      "Epoch 88/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3275 - categorical_accuracy: 0.8693 - val_loss: 0.3924 - val_categorical_accuracy: 0.8625 - lr: 1.7552e-04\n",
      "Epoch 89/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3176 - categorical_accuracy: 0.8741 - val_loss: 0.4212 - val_categorical_accuracy: 0.8550 - lr: 1.7033e-04\n",
      "Epoch 90/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3227 - categorical_accuracy: 0.8712 - val_loss: 0.4176 - val_categorical_accuracy: 0.8400 - lr: 1.6530e-04\n",
      "Epoch 91/240\n",
      "159/159 [==============================] - 186s 1s/step - loss: 0.3100 - categorical_accuracy: 0.8780 - val_loss: 0.4421 - val_categorical_accuracy: 0.8375 - lr: 1.6041e-04\n",
      "Epoch 92/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3195 - categorical_accuracy: 0.8750 - val_loss: 0.4135 - val_categorical_accuracy: 0.8400 - lr: 1.5567e-04\n",
      "Epoch 93/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3149 - categorical_accuracy: 0.8665 - val_loss: 0.3991 - val_categorical_accuracy: 0.8550 - lr: 1.5107e-04\n",
      "Epoch 94/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3064 - categorical_accuracy: 0.8791 - val_loss: 0.3707 - val_categorical_accuracy: 0.8575 - lr: 1.4661e-04\n",
      "Epoch 95/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3052 - categorical_accuracy: 0.8791 - val_loss: 0.4475 - val_categorical_accuracy: 0.8300 - lr: 1.4227e-04\n",
      "Epoch 96/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.3019 - categorical_accuracy: 0.8824 - val_loss: 0.3720 - val_categorical_accuracy: 0.8750 - lr: 1.3807e-04\n",
      "Epoch 97/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2972 - categorical_accuracy: 0.8789 - val_loss: 0.5468 - val_categorical_accuracy: 0.7825 - lr: 1.3399e-04\n",
      "Epoch 98/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.3023 - categorical_accuracy: 0.8818 - val_loss: 0.4077 - val_categorical_accuracy: 0.8550 - lr: 1.3003e-04\n",
      "Epoch 99/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2908 - categorical_accuracy: 0.8830 - val_loss: 0.3957 - val_categorical_accuracy: 0.8650 - lr: 1.2619e-04\n",
      "Epoch 100/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2809 - categorical_accuracy: 0.8899 - val_loss: 0.3709 - val_categorical_accuracy: 0.8650 - lr: 1.2246e-04\n",
      "Epoch 101/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2911 - categorical_accuracy: 0.8863 - val_loss: 0.3691 - val_categorical_accuracy: 0.8800 - lr: 1.1884e-04\n",
      "Epoch 102/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2817 - categorical_accuracy: 0.8893 - val_loss: 0.4008 - val_categorical_accuracy: 0.8775 - lr: 1.1533e-04\n",
      "Epoch 103/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2919 - categorical_accuracy: 0.8851 - val_loss: 0.4114 - val_categorical_accuracy: 0.8700 - lr: 1.1192e-04\n",
      "Epoch 104/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2905 - categorical_accuracy: 0.8843 - val_loss: 0.4083 - val_categorical_accuracy: 0.8725 - lr: 1.0861e-04\n",
      "Epoch 105/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2814 - categorical_accuracy: 0.8873 - val_loss: 0.3925 - val_categorical_accuracy: 0.8775 - lr: 1.0540e-04\n",
      "Epoch 106/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2852 - categorical_accuracy: 0.8851 - val_loss: 0.3864 - val_categorical_accuracy: 0.8675 - lr: 1.0228e-04\n",
      "Epoch 107/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2847 - categorical_accuracy: 0.8928 - val_loss: 0.3606 - val_categorical_accuracy: 0.8825 - lr: 9.9262e-05\n",
      "Epoch 108/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2735 - categorical_accuracy: 0.8928 - val_loss: 0.4795 - val_categorical_accuracy: 0.8400 - lr: 9.6328e-05\n",
      "Epoch 109/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2652 - categorical_accuracy: 0.8995 - val_loss: 0.3712 - val_categorical_accuracy: 0.8650 - lr: 9.3481e-05\n",
      "Epoch 110/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2798 - categorical_accuracy: 0.8906 - val_loss: 0.3648 - val_categorical_accuracy: 0.8900 - lr: 9.0718e-05\n",
      "Epoch 111/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2627 - categorical_accuracy: 0.8965 - val_loss: 0.4852 - val_categorical_accuracy: 0.8400 - lr: 8.8037e-05\n",
      "Epoch 112/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2688 - categorical_accuracy: 0.8943 - val_loss: 0.3644 - val_categorical_accuracy: 0.8850 - lr: 8.5435e-05\n",
      "Epoch 113/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2531 - categorical_accuracy: 0.8978 - val_loss: 0.3794 - val_categorical_accuracy: 0.8850 - lr: 8.2910e-05\n",
      "Epoch 114/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2751 - categorical_accuracy: 0.8923 - val_loss: 0.4167 - val_categorical_accuracy: 0.8725 - lr: 8.0460e-05\n",
      "Epoch 115/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2591 - categorical_accuracy: 0.8975 - val_loss: 0.3731 - val_categorical_accuracy: 0.8675 - lr: 7.8082e-05\n",
      "Epoch 116/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2571 - categorical_accuracy: 0.8984 - val_loss: 0.3784 - val_categorical_accuracy: 0.8800 - lr: 7.5774e-05\n",
      "Epoch 117/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2575 - categorical_accuracy: 0.9019 - val_loss: 0.3771 - val_categorical_accuracy: 0.9050 - lr: 7.3535e-05\n",
      "Epoch 118/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2597 - categorical_accuracy: 0.8975 - val_loss: 0.3614 - val_categorical_accuracy: 0.8600 - lr: 7.1362e-05\n",
      "Epoch 119/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2554 - categorical_accuracy: 0.8978 - val_loss: 0.3416 - val_categorical_accuracy: 0.8950 - lr: 6.9252e-05\n",
      "Epoch 120/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2430 - categorical_accuracy: 0.9039 - val_loss: 0.3724 - val_categorical_accuracy: 0.8825 - lr: 6.7206e-05\n",
      "Epoch 121/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2481 - categorical_accuracy: 0.9057 - val_loss: 0.4252 - val_categorical_accuracy: 0.8575 - lr: 6.5220e-05\n",
      "Epoch 122/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2468 - categorical_accuracy: 0.9003 - val_loss: 0.3728 - val_categorical_accuracy: 0.8850 - lr: 6.3292e-05\n",
      "Epoch 123/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2490 - categorical_accuracy: 0.9017 - val_loss: 0.3517 - val_categorical_accuracy: 0.8875 - lr: 6.1421e-05\n",
      "Epoch 124/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2467 - categorical_accuracy: 0.9016 - val_loss: 0.3895 - val_categorical_accuracy: 0.8750 - lr: 5.9606e-05\n",
      "Epoch 125/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2396 - categorical_accuracy: 0.9058 - val_loss: 0.3481 - val_categorical_accuracy: 0.8850 - lr: 5.7845e-05\n",
      "Epoch 126/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2299 - categorical_accuracy: 0.9105 - val_loss: 0.3779 - val_categorical_accuracy: 0.8900 - lr: 5.6135e-05\n",
      "Epoch 127/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2440 - categorical_accuracy: 0.9003 - val_loss: 0.3466 - val_categorical_accuracy: 0.8850 - lr: 5.4476e-05\n",
      "Epoch 128/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2382 - categorical_accuracy: 0.9108 - val_loss: 0.3922 - val_categorical_accuracy: 0.8900 - lr: 5.2866e-05\n",
      "Epoch 129/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2422 - categorical_accuracy: 0.9049 - val_loss: 0.3725 - val_categorical_accuracy: 0.8900 - lr: 5.1304e-05\n",
      "Epoch 130/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2329 - categorical_accuracy: 0.9112 - val_loss: 0.3931 - val_categorical_accuracy: 0.8875 - lr: 4.9787e-05\n",
      "Epoch 131/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2330 - categorical_accuracy: 0.9096 - val_loss: 0.3619 - val_categorical_accuracy: 0.8925 - lr: 4.8316e-05\n",
      "Epoch 132/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2276 - categorical_accuracy: 0.9074 - val_loss: 0.3817 - val_categorical_accuracy: 0.8875 - lr: 4.6888e-05\n",
      "Epoch 133/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2305 - categorical_accuracy: 0.9097 - val_loss: 0.3670 - val_categorical_accuracy: 0.8925 - lr: 4.5502e-05\n",
      "Epoch 134/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2254 - categorical_accuracy: 0.9129 - val_loss: 0.3677 - val_categorical_accuracy: 0.8950 - lr: 4.4157e-05\n",
      "Epoch 135/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2202 - categorical_accuracy: 0.9142 - val_loss: 0.4044 - val_categorical_accuracy: 0.8925 - lr: 4.2852e-05\n",
      "Epoch 136/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2203 - categorical_accuracy: 0.9124 - val_loss: 0.3863 - val_categorical_accuracy: 0.8925 - lr: 4.1586e-05\n",
      "Epoch 137/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2188 - categorical_accuracy: 0.9156 - val_loss: 0.3849 - val_categorical_accuracy: 0.8900 - lr: 4.0357e-05\n",
      "Epoch 138/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2212 - categorical_accuracy: 0.9107 - val_loss: 0.3964 - val_categorical_accuracy: 0.8975 - lr: 3.9164e-05\n",
      "Epoch 139/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2137 - categorical_accuracy: 0.9157 - val_loss: 0.3893 - val_categorical_accuracy: 0.9025 - lr: 3.8007e-05\n",
      "Epoch 140/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2200 - categorical_accuracy: 0.9138 - val_loss: 0.3963 - val_categorical_accuracy: 0.8975 - lr: 3.6883e-05\n",
      "Epoch 141/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2119 - categorical_accuracy: 0.9160 - val_loss: 0.4092 - val_categorical_accuracy: 0.8825 - lr: 3.5793e-05\n",
      "Epoch 142/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2197 - categorical_accuracy: 0.9170 - val_loss: 0.3678 - val_categorical_accuracy: 0.8975 - lr: 3.4735e-05\n",
      "Epoch 143/240\n",
      "159/159 [==============================] - 184s 1s/step - loss: 0.2183 - categorical_accuracy: 0.9149 - val_loss: 0.3970 - val_categorical_accuracy: 0.8925 - lr: 3.3709e-05\n",
      "Epoch 144/240\n",
      "159/159 [==============================] - 183s 1s/step - loss: 0.2205 - categorical_accuracy: 0.9167 - val_loss: 0.4104 - val_categorical_accuracy: 0.8950 - lr: 3.2713e-05\n",
      "Epoch 145/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2092 - categorical_accuracy: 0.9198 - val_loss: 0.3655 - val_categorical_accuracy: 0.9025 - lr: 3.1746e-05\n",
      "Epoch 146/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.2081 - categorical_accuracy: 0.9178 - val_loss: 0.4011 - val_categorical_accuracy: 0.8925 - lr: 3.0808e-05\n",
      "Epoch 147/240\n",
      "159/159 [==============================] - 188s 1s/step - loss: 0.1982 - categorical_accuracy: 0.9219 - val_loss: 0.4130 - val_categorical_accuracy: 0.8975 - lr: 2.9897e-05\n",
      "Epoch 148/240\n",
      "159/159 [==============================] - 187s 1s/step - loss: 0.2119 - categorical_accuracy: 0.9151 - val_loss: 0.4332 - val_categorical_accuracy: 0.8975 - lr: 2.9013e-05\n",
      "Epoch 149/240\n",
      "159/159 [==============================] - 92s 569ms/step - loss: 0.2131 - categorical_accuracy: 0.9134 - val_loss: 0.4257 - val_categorical_accuracy: 0.8900 - lr: 2.8156e-05\n",
      "Epoch 150/240\n",
      "159/159 [==============================] - 65s 403ms/step - loss: 0.2077 - categorical_accuracy: 0.9198 - val_loss: 0.4197 - val_categorical_accuracy: 0.8900 - lr: 2.7324e-05\n",
      "Epoch 151/240\n",
      "159/159 [==============================] - 207s 1s/step - loss: 0.2053 - categorical_accuracy: 0.9195 - val_loss: 0.3881 - val_categorical_accuracy: 0.8900 - lr: 2.6516e-05\n",
      "Epoch 152/240\n",
      "159/159 [==============================] - 210s 1s/step - loss: 0.2085 - categorical_accuracy: 0.9173 - val_loss: 0.4083 - val_categorical_accuracy: 0.8900 - lr: 2.5733e-05\n",
      "Epoch 153/240\n",
      "159/159 [==============================] - 202s 1s/step - loss: 0.1984 - categorical_accuracy: 0.9226 - val_loss: 0.3721 - val_categorical_accuracy: 0.8900 - lr: 2.4972e-05\n",
      "Epoch 154/240\n",
      "159/159 [==============================] - 179s 1s/step - loss: 0.2052 - categorical_accuracy: 0.9192 - val_loss: 0.3757 - val_categorical_accuracy: 0.8975 - lr: 2.4234e-05\n",
      "Epoch 155/240\n",
      "159/159 [==============================] - 83s 518ms/step - loss: 0.2016 - categorical_accuracy: 0.9226 - val_loss: 0.3985 - val_categorical_accuracy: 0.8925 - lr: 2.3518e-05\n",
      "Epoch 156/240\n",
      "159/159 [==============================] - 203s 1s/step - loss: 0.2072 - categorical_accuracy: 0.9181 - val_loss: 0.3934 - val_categorical_accuracy: 0.8875 - lr: 2.2823e-05\n",
      "Epoch 157/240\n",
      "159/159 [==============================] - 218s 1s/step - loss: 0.2063 - categorical_accuracy: 0.9171 - val_loss: 0.3787 - val_categorical_accuracy: 0.8950 - lr: 2.2148e-05\n",
      "Epoch 158/240\n",
      "159/159 [==============================] - 212s 1s/step - loss: 0.2017 - categorical_accuracy: 0.9200 - val_loss: 0.3838 - val_categorical_accuracy: 0.8875 - lr: 2.1494e-05\n",
      "Epoch 159/240\n",
      "159/159 [==============================] - 113s 701ms/step - loss: 0.1973 - categorical_accuracy: 0.9247 - val_loss: 0.3835 - val_categorical_accuracy: 0.8875 - lr: 2.0858e-05\n",
      "Epoch 160/240\n",
      "159/159 [==============================] - 99s 618ms/step - loss: 0.1975 - categorical_accuracy: 0.9239 - val_loss: 0.3796 - val_categorical_accuracy: 0.8900 - lr: 2.0242e-05\n",
      "Epoch 161/240\n",
      "159/159 [==============================] - 119s 744ms/step - loss: 0.1973 - categorical_accuracy: 0.9255 - val_loss: 0.3814 - val_categorical_accuracy: 0.8925 - lr: 1.9644e-05\n",
      "Epoch 162/240\n",
      "159/159 [==============================] - 158s 989ms/step - loss: 0.1961 - categorical_accuracy: 0.9255 - val_loss: 0.3845 - val_categorical_accuracy: 0.8900 - lr: 1.9063e-05\n",
      "Epoch 163/240\n",
      "159/159 [==============================] - 214s 1s/step - loss: 0.1960 - categorical_accuracy: 0.9215 - val_loss: 0.3832 - val_categorical_accuracy: 0.8925 - lr: 1.8500e-05\n",
      "Epoch 164/240\n",
      "159/159 [==============================] - 208s 1s/step - loss: 0.2004 - categorical_accuracy: 0.9233 - val_loss: 0.3744 - val_categorical_accuracy: 0.8925 - lr: 1.7953e-05\n",
      "Epoch 165/240\n",
      "159/159 [==============================] - 214s 1s/step - loss: 0.1885 - categorical_accuracy: 0.9278 - val_loss: 0.3694 - val_categorical_accuracy: 0.8975 - lr: 1.7422e-05\n",
      "Epoch 166/240\n",
      "159/159 [==============================] - 211s 1s/step - loss: 0.2008 - categorical_accuracy: 0.9193 - val_loss: 0.3746 - val_categorical_accuracy: 0.8950 - lr: 1.6908e-05\n",
      "Epoch 167/240\n",
      "159/159 [==============================] - 222s 1s/step - loss: 0.2005 - categorical_accuracy: 0.9226 - val_loss: 0.3833 - val_categorical_accuracy: 0.8900 - lr: 1.6408e-05\n",
      "Epoch 168/240\n",
      "159/159 [==============================] - 238s 1s/step - loss: 0.1959 - categorical_accuracy: 0.9230 - val_loss: 0.3890 - val_categorical_accuracy: 0.8875 - lr: 1.5923e-05\n",
      "Epoch 169/240\n",
      "159/159 [==============================] - 223s 1s/step - loss: 0.1923 - categorical_accuracy: 0.9278 - val_loss: 0.3900 - val_categorical_accuracy: 0.8925 - lr: 1.5452e-05\n",
      "Epoch 170/240\n",
      "159/159 [==============================] - 223s 1s/step - loss: 0.1915 - categorical_accuracy: 0.9239 - val_loss: 0.3778 - val_categorical_accuracy: 0.8900 - lr: 1.4996e-05\n",
      "Epoch 171/240\n",
      "159/159 [==============================] - 223s 1s/step - loss: 0.1994 - categorical_accuracy: 0.9204 - val_loss: 0.3748 - val_categorical_accuracy: 0.8925 - lr: 1.4552e-05\n",
      "Epoch 172/240\n",
      "159/159 [==============================] - 263s 2s/step - loss: 0.1846 - categorical_accuracy: 0.9256 - val_loss: 0.3660 - val_categorical_accuracy: 0.8900 - lr: 1.4122e-05\n",
      "Epoch 173/240\n",
      "159/159 [==============================] - 213s 1s/step - loss: 0.1814 - categorical_accuracy: 0.9319 - val_loss: 0.3753 - val_categorical_accuracy: 0.8825 - lr: 1.3705e-05\n",
      "Epoch 174/240\n",
      "159/159 [==============================] - 98s 609ms/step - loss: 0.1897 - categorical_accuracy: 0.9280 - val_loss: 0.3815 - val_categorical_accuracy: 0.8900 - lr: 1.3300e-05\n",
      "Epoch 175/240\n",
      "159/159 [==============================] - 65s 398ms/step - loss: 0.1854 - categorical_accuracy: 0.9256 - val_loss: 0.3876 - val_categorical_accuracy: 0.8850 - lr: 1.2907e-05\n",
      "Epoch 176/240\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.1897 - categorical_accuracy: 0.9261 - val_loss: 0.3822 - val_categorical_accuracy: 0.8950 - lr: 1.2525e-05\n",
      "Epoch 177/240\n",
      "159/159 [==============================] - 64s 394ms/step - loss: 0.1872 - categorical_accuracy: 0.9261 - val_loss: 0.3883 - val_categorical_accuracy: 0.9000 - lr: 1.2155e-05\n",
      "Epoch 178/240\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.1745 - categorical_accuracy: 0.9318 - val_loss: 0.4049 - val_categorical_accuracy: 0.8950 - lr: 1.1796e-05\n",
      "Epoch 179/240\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.1936 - categorical_accuracy: 0.9230 - val_loss: 0.3934 - val_categorical_accuracy: 0.8875 - lr: 1.1447e-05\n",
      "Epoch 180/240\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.1807 - categorical_accuracy: 0.9347 - val_loss: 0.3908 - val_categorical_accuracy: 0.8925 - lr: 1.1109e-05\n",
      "Epoch 181/240\n",
      "159/159 [==============================] - 65s 399ms/step - loss: 0.1915 - categorical_accuracy: 0.9226 - val_loss: 0.3898 - val_categorical_accuracy: 0.9000 - lr: 1.0781e-05\n",
      "Epoch 182/240\n",
      "159/159 [==============================] - 64s 394ms/step - loss: 0.1835 - categorical_accuracy: 0.9286 - val_loss: 0.3822 - val_categorical_accuracy: 0.8950 - lr: 1.0462e-05\n",
      "Epoch 183/240\n",
      "159/159 [==============================] - 65s 400ms/step - loss: 0.1921 - categorical_accuracy: 0.9226 - val_loss: 0.3830 - val_categorical_accuracy: 0.8975 - lr: 1.0153e-05\n",
      "Epoch 184/240\n",
      "159/159 [==============================] - 71s 441ms/step - loss: 0.1899 - categorical_accuracy: 0.9266 - val_loss: 0.3925 - val_categorical_accuracy: 0.9075 - lr: 9.8529e-06\n",
      "Epoch 185/240\n",
      "159/159 [==============================] - 220s 1s/step - loss: 0.1817 - categorical_accuracy: 0.9299 - val_loss: 0.3903 - val_categorical_accuracy: 0.9000 - lr: 9.5617e-06\n",
      "Epoch 186/240\n",
      "159/159 [==============================] - 224s 1s/step - loss: 0.1793 - categorical_accuracy: 0.9281 - val_loss: 0.3963 - val_categorical_accuracy: 0.8950 - lr: 9.2791e-06\n",
      "Epoch 187/240\n",
      "159/159 [==============================] - 226s 1s/step - loss: 0.1915 - categorical_accuracy: 0.9245 - val_loss: 0.3923 - val_categorical_accuracy: 0.8875 - lr: 9.0048e-06\n",
      "Epoch 188/240\n",
      "159/159 [==============================] - 82s 507ms/step - loss: 0.1952 - categorical_accuracy: 0.9241 - val_loss: 0.3848 - val_categorical_accuracy: 0.8900 - lr: 8.7387e-06\n",
      "Epoch 189/240\n",
      "159/159 [==============================] - 226s 1s/step - loss: 0.1890 - categorical_accuracy: 0.9278 - val_loss: 0.3802 - val_categorical_accuracy: 0.8950 - lr: 8.4804e-06\n",
      "Epoch 190/240\n",
      "159/159 [==============================] - 115s 716ms/step - loss: 0.1852 - categorical_accuracy: 0.9263 - val_loss: 0.3834 - val_categorical_accuracy: 0.8875 - lr: 8.2298e-06\n",
      "Epoch 191/240\n",
      "159/159 [==============================] - 212s 1s/step - loss: 0.1823 - categorical_accuracy: 0.9327 - val_loss: 0.3885 - val_categorical_accuracy: 0.8950 - lr: 7.9866e-06\n",
      "Epoch 192/240\n",
      "159/159 [==============================] - 190s 1s/step - loss: 0.1795 - categorical_accuracy: 0.9294 - val_loss: 0.3904 - val_categorical_accuracy: 0.8975 - lr: 7.7505e-06\n",
      "Epoch 193/240\n",
      "159/159 [==============================] - 114s 707ms/step - loss: 0.1907 - categorical_accuracy: 0.9242 - val_loss: 0.3932 - val_categorical_accuracy: 0.8950 - lr: 7.5215e-06\n",
      "Epoch 194/240\n",
      "159/159 [==============================] - 135s 841ms/step - loss: 0.1893 - categorical_accuracy: 0.9272 - val_loss: 0.3980 - val_categorical_accuracy: 0.8900 - lr: 7.2992e-06\n",
      "Epoch 195/240\n",
      "159/159 [==============================] - 101s 625ms/step - loss: 0.1815 - categorical_accuracy: 0.9285 - val_loss: 0.3957 - val_categorical_accuracy: 0.8950 - lr: 7.0835e-06\n",
      "Epoch 196/240\n",
      "159/159 [==============================] - 140s 875ms/step - loss: 0.1864 - categorical_accuracy: 0.9296 - val_loss: 0.3983 - val_categorical_accuracy: 0.8950 - lr: 6.8741e-06\n",
      "Epoch 197/240\n",
      "159/159 [==============================] - 72s 444ms/step - loss: 0.1809 - categorical_accuracy: 0.9311 - val_loss: 0.3954 - val_categorical_accuracy: 0.8900 - lr: 6.6709e-06\n",
      "Epoch 198/240\n",
      "159/159 [==============================] - 216s 1s/step - loss: 0.1794 - categorical_accuracy: 0.9274 - val_loss: 0.3932 - val_categorical_accuracy: 0.8925 - lr: 6.4738e-06\n",
      "Epoch 199/240\n",
      " 63/159 [==========>...................] - ETA: 2:06 - loss: 0.1853 - categorical_accuracy: 0.9226"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25128\\4172618143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m )\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Anaconda3_64\\envs\\garden\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='tanh'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=None ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/threemod/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.03)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "model.build()\n",
    "model.summary()\n",
    "\n",
    "# now with normalisation\n",
    "epochs=240\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=10,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f00e5265-142f-4b61-ab38-2cab5289760b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'binary_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25128\\1270641064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'binary_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_binary_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'binary_accuracy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90470b-a402-4948-9fe4-f57618c7d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=tf.compat.v1.data.make_one_shot_iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d64b-2ba7-4826-b54b-3d641f741a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    next_element = iterator.get_next()\n",
    "    im = resize_rescale_augment(next_element[0])\n",
    "    plt.imshow(np.flip(im[0,:,:,0:3], axis=2))\n",
    "    plt.title(convert_onehot(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21253b84-bc80-4976-8816-b49dee2293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onehot(next_element):\n",
    "    if (next_element[1].numpy() == np.array([0, 0, 1])).all(): return 'no industry'\n",
    "    elif (next_element[1].numpy() == np.array([0, 1, 0])).all(): return 'steel'\n",
    "    elif (next_element[1].numpy() == np.array([1, 0, 0])).all(): return 'coal'\n",
    "    else: return 'not valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f89dc-23ea-4317-a8ff-376357f954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_element[1].numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372a01e-8e19-45ee-a7fc-0a5540f19f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/path/to/file.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = foo\n",
    "spec.loader.exec_module(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6827d1-167e-47c0-ae4c-441f24174694",
   "metadata": {},
   "outputs": [],
   "source": [
    "! PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311393-972b-421b-b164-3f62c9effb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
