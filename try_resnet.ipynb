{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "37fde579-c955-4a16-a019-5ab53a8e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n",
    "from random import shuffle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "051cfc09-6a01-4a20-ba55-d8ad7e7fc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3f12c078-c191-4287-9704-f1ffca001cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# data_dir = pathlib.Path('E:/Users/sentinel_industry/downloaded_aois/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7bd5a4a4-fad7-449a-99c2-7f42e8090a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 230\n",
    "y_size = 230\n",
    "def load_features(name):\n",
    "    decoded = name.decode(\"UTF-8\")\n",
    "    if os.path.exists(decoded):\n",
    "        with open(decoded, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            label = tf.strings.split(tf.strings.split(name, '/')[-1], '\\\\')[-2]\n",
    "            if label == 'coal':\n",
    "                label = [1,0,0]\n",
    "            elif label == 'steel':\n",
    "                label = [0,1,0]\n",
    "            else: label = [0,0,1]\n",
    "            if (file[\"B02\"].shape[1]<230 or file[\"B02\"].shape[2]<230): \n",
    "                print(\"oh oh, downloaded patch too smol:\", decoded)\n",
    "            B02, B03, B04, B08 = file['B02'][0][0:x_size,0:y_size], file['B03'][0][0:x_size,0:y_size], file['B04'][0][0:x_size,0:y_size],file['B08'][0][0:x_size,0:y_size]\n",
    "            for channel in [ B02, B03, B04, B08]: channel = channel/channel.max()\n",
    "            features = np.array([ B02, B03, B04, B08]).transpose(1,2,0)\n",
    "            # features = np.expand_dims(features, axis=0)\n",
    "            return features, label\n",
    "            # I have commented the line below but this should return\n",
    "            # the features and the label in a one hot vector\n",
    "            # return file['features'], file['targets']\n",
    "    else:\n",
    "        print(\"Something went wrong!\")\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6f8d3b08-b09b-480d-8d8d-bf44131c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Users/sentinel_industry/downloaded_aois/coal/'\n",
    "\n",
    "pkl_files = glob.glob((path+\"*.pickle\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7def905d-f2c1-45f1-985c-aaf123860dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f15f640f-7002-40d2-899a-21b4090c2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel = 'E:/Users/sentinel_industry/downloaded_aois/steel/'\n",
    "pkl_files_steel = glob.glob((path_steel+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5e5a78e7-514d-4f65-a831-57faa0c5df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/steel/no_ind/'\n",
    "pkl_files_steel_no_ind = glob.glob((path_steel_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "076b0a09-9866-4fee-a244-2bd75892bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_coal_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/coal/no_ind/'\n",
    "pkl_files_coal_no_ind = glob.glob((path_coal_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "da24ac7d-0f3f-4cfe-b518-fef29417d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files_steel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "af872199-9192-48eb-8cea-9693c2291fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_files = pkl_files + pkl_files_steel + pkl_files_steel_no_ind + pkl_files_coal_no_ind\n",
    "shuffle(pkl_files)\n",
    "# pkl_files=pkl_files[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cfe3ca4f-ca84-4d80-9218-95fc89e8fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "\n",
    "# pkl_files = list(chain.from_iterable(zip(pkl_files, pkl_files_steel)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "07182a88-11f4-4b7d-a461-4debb2944063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8077\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dfc46d5e-854e-42c6-af9c-97123ce4b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len=len(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "21e3f5d5-620d-4e9d-8abb-ecee1ba2dac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((pkl_files))\n",
    "\n",
    "def data_loader(filename):\n",
    "    features, labels = tf.numpy_function(load_features, [filename], [tf.uint16, tf.int32])\n",
    "    # features.set_shape((None, 242,242,4))\n",
    "    # labels.set_shape(( 1))\n",
    "    return features, labels\n",
    "\n",
    "dataset = dataset.map(data_loader)\n",
    "               # load_features, [filename], [tf.uint16, tf.string])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "adaadc4a-c328-4c33-b9b7-3d2e140f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle(100, seed=42)\n",
    "\n",
    "train_size = np.floor(0.8 * dataset_len)\n",
    "valid_size = np.floor(0.1 * dataset_len)\n",
    "test_size = np.floor(0.1 * dataset_len)\n",
    "\n",
    "train = dataset.take(train_size, )\n",
    "remaining = dataset.skip(train_size)\n",
    "valid = remaining.take(valid_size,\n",
    ")\n",
    "test = remaining.skip(valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "80f35197-11ee-40af-bc9c-c5181c99583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.shuffle(100,  reshuffle_each_iteration=True, )\n",
    "valid = valid.shuffle(100,  reshuffle_each_iteration=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5c5ac712-d2ef-43e7-bc46-cfda264dc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seed = 42\n",
    "resize_rescale_augment = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values\n",
    "    layers.CenterCrop(140,140, ),\n",
    "    layers.RandomCrop(120,120, seed=in_seed, ),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "\n",
    "    # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cb8f934b-2604-4cae-90e3-c805ebb2c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map((\n",
    "#   lambda x, y: (resize_and_rescale(x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f31d628e-b02a-4e9a-b488-621dbd9c6f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 230, 4)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in dataset:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d27b0ce3-1d0b-45b1-ae8b-2d93678fab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.uint16, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ff9eae1f-d440-48fc-901e-214c9956fb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Users\\\\sentinel_industry'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f3d2ec65-044d-4736-b6c9-f4921a6d7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     resize_rescale_augment,\n",
    "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(3)\n",
    "# ])\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='relu'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=max ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/new/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.05)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "61a4893c-dc79-429a-9db4-07b6448b26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "080187fe-ffc5-4377-a03e-f9dedd1185e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_13 (Sequential)  (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,686,322\n",
      "Trainable params: 23,633,202\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5562cb60-b8d6-4768-8d53-b3b319dd6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "befec726-725f-4a3a-91cb-53edd07eb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !env LD_LIBRARY_PATH=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_LIBRARY_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_INCLUDE_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# # !set LD_INCLUDE_PATH=:/usr/local/cuda/include:/usr/local/cuda/extras/CUPTI/include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bf8bd085-6960-4fd9-b181-a397dba92350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "env: â€˜LD_LIBRARY_PATHâ€™: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!env LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a9d77-970f-4a15-8b88-72e435b512de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ac0f2df1-a1c4-4256-8207-c604ecb682a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22096), started 2:33:05 ago. (Use '!kill 22096' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-279a5ddbca41ac0f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-279a5ddbca41ac0f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir='E:/Users/sentinel_industry/logs/train/new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be530648-e9dc-4672-8686-9370d346b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "161/161 [==============================] - 413s 3s/step - loss: 3.5494 - categorical_accuracy: 0.4899 - val_loss: 0.9829 - val_categorical_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "161/161 [==============================] - 349s 2s/step - loss: 1.7942 - categorical_accuracy: 0.5719 - val_loss: 1912.9668 - val_categorical_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "161/161 [==============================] - 356s 2s/step - loss: 1.7061 - categorical_accuracy: 0.6480 - val_loss: 0.9800 - val_categorical_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "161/161 [==============================] - 325s 2s/step - loss: 1.0988 - categorical_accuracy: 0.6882 - val_loss: 0.8159 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "161/161 [==============================] - 361s 2s/step - loss: 0.9553 - categorical_accuracy: 0.7023 - val_loss: 0.6962 - val_categorical_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "161/161 [==============================] - 343s 2s/step - loss: 1.0961 - categorical_accuracy: 0.6967 - val_loss: 4.7970 - val_categorical_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "161/161 [==============================] - 375s 2s/step - loss: 1.3041 - categorical_accuracy: 0.6829 - val_loss: 0.8195 - val_categorical_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "161/161 [==============================] - 370s 2s/step - loss: 1.0034 - categorical_accuracy: 0.7208 - val_loss: 0.7989 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "161/161 [==============================] - 359s 2s/step - loss: 0.9810 - categorical_accuracy: 0.7382 - val_loss: 0.5252 - val_categorical_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "161/161 [==============================] - 318s 2s/step - loss: 0.7752 - categorical_accuracy: 0.7506 - val_loss: 0.5936 - val_categorical_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "161/161 [==============================] - 340s 2s/step - loss: 0.8349 - categorical_accuracy: 0.7609 - val_loss: 0.5538 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "135/161 [========================>.....] - ETA: 29s - loss: 0.7514 - categorical_accuracy: 0.7456"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb171cdb-c5d8-4f7d-b778-18aa7efc08bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e5265-142f-4b61-ab38-2cab5289760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90470b-a402-4948-9fe4-f57618c7d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=tf.compat.v1.data.make_one_shot_iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d64b-2ba7-4826-b54b-3d641f741a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    next_element = iterator.get_next()\n",
    "    im = resize_rescale_augment(next_element[0])\n",
    "    plt.imshow(np.flip(im[0,:,:,0:3], axis=2))\n",
    "    plt.title(convert_onehot(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21253b84-bc80-4976-8816-b49dee2293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onehot(next_element):\n",
    "    if (next_element[1].numpy() == np.array([0, 0, 1])).all(): return 'no industry'\n",
    "    elif (next_element[1].numpy() == np.array([0, 1, 0])).all(): return 'steel'\n",
    "    elif (next_element[1].numpy() == np.array([1, 0, 0])).all(): return 'coal'\n",
    "    else: return 'not valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f89dc-23ea-4317-a8ff-376357f954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_element[1].numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372a01e-8e19-45ee-a7fc-0a5540f19f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/path/to/file.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = foo\n",
    "spec.loader.exec_module(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6827d1-167e-47c0-ae4c-441f24174694",
   "metadata": {},
   "outputs": [],
   "source": [
    "! PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311393-972b-421b-b164-3f62c9effb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
