{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37fde579-c955-4a16-a019-5ab53a8e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "import pickle as pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "051cfc09-6a01-4a20-ba55-d8ad7e7fc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f12c078-c191-4287-9704-f1ffca001cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# data_dir = pathlib.Path('E:/Users/sentinel_industry/downloaded_aois/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bd5a4a4-fad7-449a-99c2-7f42e8090a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 230\n",
    "y_size = 230\n",
    "def load_features(name):\n",
    "    decoded = name.decode(\"UTF-8\")\n",
    "    if os.path.exists(decoded):\n",
    "        with open(decoded, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            label = tf.strings.split(tf.strings.split(name, '/')[-1], '\\\\')[-2]\n",
    "            if label == 'coal':\n",
    "                label = [1,0,0]\n",
    "            elif label == 'steel':\n",
    "                label = [0,1,0]\n",
    "            else: label = [0,0,1]\n",
    "            B02, B03, B04, B08 = file['B02'][0][0:x_size,0:y_size], file['B03'][0][0:x_size,0:y_size], file['B04'][0][0:x_size,0:y_size],file['B08'][0][0:x_size,0:y_size]\n",
    "            for channel in [ B02, B03, B04, B08]: channel = channel/channel.max()\n",
    "            features = np.array([ B02, B03, B04, B08]).transpose(1,2,0)\n",
    "            # features = np.expand_dims(features, axis=0)\n",
    "            return features, label\n",
    "            # I have commented the line below but this should return\n",
    "            # the features and the label in a one hot vector\n",
    "            # return file['features'], file['targets']\n",
    "    else:\n",
    "        print(\"Something went wrong!\")\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f8d3b08-b09b-480d-8d8d-bf44131c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Users/sentinel_industry/downloaded_aois/coal/'\n",
    "\n",
    "pkl_files = glob.glob((path+\"*.pickle\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7def905d-f2c1-45f1-985c-aaf123860dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f15f640f-7002-40d2-899a-21b4090c2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel = 'E:/Users/sentinel_industry/downloaded_aois/steel/'\n",
    "pkl_files_steel = glob.glob((path_steel+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e5a78e7-514d-4f65-a831-57faa0c5df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/steel/no_ind/'\n",
    "pkl_files_steel_no_ind = glob.glob((path_steel_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "076b0a09-9866-4fee-a244-2bd75892bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_coal_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/coal/no_ind/'\n",
    "pkl_files_coal_no_ind = glob.glob((path_coal_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da24ac7d-0f3f-4cfe-b518-fef29417d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files_steel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af872199-9192-48eb-8cea-9693c2291fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_files = pkl_files + pkl_files_steel + pkl_files_steel_no_ind + pkl_files_coal_no_ind\n",
    "shuffle(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cfe3ca4f-ca84-4d80-9218-95fc89e8fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "\n",
    "# pkl_files = list(chain.from_iterable(zip(pkl_files, pkl_files_steel)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07182a88-11f4-4b7d-a461-4debb2944063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6473\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfc46d5e-854e-42c6-af9c-97123ce4b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len=len(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21e3f5d5-620d-4e9d-8abb-ecee1ba2dac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((pkl_files))\n",
    "\n",
    "def data_loader(filename):\n",
    "    features, labels = tf.numpy_function(load_features, [filename], [tf.uint16, tf.int32])\n",
    "    # features.set_shape((None, 242,242,4))\n",
    "    # labels.set_shape(( 1))\n",
    "    return features, labels\n",
    "\n",
    "dataset = dataset.map(data_loader)\n",
    "               # load_features, [filename], [tf.uint16, tf.string])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adaadc4a-c328-4c33-b9b7-3d2e140f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle(100)\n",
    "\n",
    "train_size = np.floor(0.8 * dataset_len)\n",
    "valid_size = np.floor(0.1 * dataset_len)\n",
    "test_size = np.floor(0.1 * dataset_len)\n",
    "\n",
    "train = dataset.take(train_size)\n",
    "remaining = dataset.skip(train_size)\n",
    "valid = remaining.take(valid_size)\n",
    "test = remaining.skip(valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80f35197-11ee-40af-bc9c-c5181c99583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.shuffle(100,  reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c5ac712-d2ef-43e7-bc46-cfda264dc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seed = 42\n",
    "resize_rescale_augment = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values\n",
    "    # layers.RandomCrop(120,120, seed=in_seed, input_shape=(x_size,y_size,4)),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "    layers.CenterCrop(120,120, ),\n",
    "    # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb8f934b-2604-4cae-90e3-c805ebb2c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map((\n",
    "#   lambda x, y: (resize_and_rescale(x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f31d628e-b02a-4e9a-b488-621dbd9c6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 230, 4)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in dataset:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d27b0ce3-1d0b-45b1-ae8b-2d93678fab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.uint16, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3d2ec65-044d-4736-b6c9-f4921a6d7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     resize_rescale_augment,\n",
    "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(3)\n",
    "# ])\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='relu'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=max ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61a4893c-dc79-429a-9db4-07b6448b26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "080187fe-ffc5-4377-a03e-f9dedd1185e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_4 (Sequential)   (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 98307     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,686,322\n",
      "Trainable params: 23,633,202\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be530648-e9dc-4672-8686-9370d346b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 441s 3s/step - loss: 3.9492 - binary_accuracy: 0.3924 - val_loss: 2.8102 - val_binary_accuracy: 0.4333\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 427s 3s/step - loss: 1.7488 - binary_accuracy: 0.4528 - val_loss: 0.9518 - val_binary_accuracy: 0.3667\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 439s 3s/step - loss: 1.6674 - binary_accuracy: 0.5310 - val_loss: 859.7092 - val_binary_accuracy: 0.3667\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 439s 3s/step - loss: 1.2513 - binary_accuracy: 0.5549 - val_loss: 6.5606 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 450s 3s/step - loss: 1.2496 - binary_accuracy: 0.6199 - val_loss: 0.6250 - val_binary_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 449s 3s/step - loss: 1.1656 - binary_accuracy: 0.6198 - val_loss: 0.7130 - val_binary_accuracy: 0.5917\n",
      "Epoch 7/20\n",
      " 81/129 [=================>............] - ETA: 2:28 - loss: 0.9121 - binary_accuracy: 0.6585"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "  train.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE),\n",
    "  validation_data=valid.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=1,\n",
    "  epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb171cdb-c5d8-4f7d-b778-18aa7efc08bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e5265-142f-4b61-ab38-2cab5289760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90470b-a402-4948-9fe4-f57618c7d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=tf.compat.v1.data.make_one_shot_iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d64b-2ba7-4826-b54b-3d641f741a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    next_element = iterator.get_next()\n",
    "    im = resize_rescale_augment(next_element[0])\n",
    "    plt.imshow(np.flip(im[0,:,:,0:3], axis=2))\n",
    "    plt.title(convert_onehot(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21253b84-bc80-4976-8816-b49dee2293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onehot(next_element):\n",
    "    if (next_element[1].numpy() == np.array([0, 0, 1])).all(): return 'no industry'\n",
    "    elif (next_element[1].numpy() == np.array([0, 1, 0])).all(): return 'steel'\n",
    "    elif (next_element[1].numpy() == np.array([1, 0, 0])).all(): return 'coal'\n",
    "    else: return 'not valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f89dc-23ea-4317-a8ff-376357f954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_element[1].numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372a01e-8e19-45ee-a7fc-0a5540f19f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/path/to/file.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = foo\n",
    "spec.loader.exec_module(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6827d1-167e-47c0-ae4c-441f24174694",
   "metadata": {},
   "outputs": [],
   "source": [
    "! PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311393-972b-421b-b164-3f62c9effb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
