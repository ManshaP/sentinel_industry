{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "37fde579-c955-4a16-a019-5ab53a8e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "051cfc09-6a01-4a20-ba55-d8ad7e7fc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3f12c078-c191-4287-9704-f1ffca001cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# data_dir = pathlib.Path('E:/Users/sentinel_industry/downloaded_aois/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "7bd5a4a4-fad7-449a-99c2-7f42e8090a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 230\n",
    "y_size = 230\n",
    "ch1_mean, ch1_std = 970.4162, 1051.8454\n",
    "ch2_mean, ch2_std = 1176.249, 1031.262\n",
    "ch3_mean, ch3_std = 1273.2376, 1117.068\n",
    "ch4_mean, ch4_std = 2266.9050, 1241.5509\n",
    "means = [ch1_mean,ch2_mean,ch3_mean,ch4_mean]\n",
    "vari = [ch1_std, ch2_std, ch3_std, ch4_std]\n",
    "\n",
    "def load_features(name):\n",
    "    decoded = name.decode(\"UTF-8\")\n",
    "    if os.path.exists(decoded):\n",
    "        with open(decoded, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            label = tf.strings.split(tf.strings.split(name, '/')[-1], '\\\\')[-2]\n",
    "            if label == 'coal':\n",
    "                label = [1,0,0]\n",
    "            elif label == 'steel':\n",
    "                label = [0,1,0]\n",
    "            else: label = [0,0,1]\n",
    "            if (file[\"B02\"].shape[1]<230 or file[\"B02\"].shape[2]<230): \n",
    "                print(\"oh oh, downloaded patch too smol:\", decoded)\n",
    "            B02, B03, B04, B08 = file['B02'][0][0:x_size,0:y_size], file['B03'][0][0:x_size,0:y_size], file['B04'][0][0:x_size,0:y_size],file['B08'][0][0:x_size,0:y_size]\n",
    "            B02 = (B02-ch1_mean)/ch1_std\n",
    "            B03 = (B03-ch2_mean)/ch2_std\n",
    "            B04 = (B04-ch3_mean)/ch3_std\n",
    "            B08 = (B08-ch4_mean)/ch4_std\n",
    "            features = np.array([ B02, B03, B04, B08]).transpose(1,2,0)\n",
    "            # features = np.expand_dims(features, axis=0)\n",
    "            return features, label\n",
    "            # I have commented the line below but this should return\n",
    "            # the features and the label in a one hot vector\n",
    "            # return file['features'], file['targets']\n",
    "    else:\n",
    "        print(\"Something went wrong!\")\n",
    "        exit(-1)\n",
    "        \n",
    "def data_loader(filename):\n",
    "    features, labels = tf.numpy_function(load_features, [filename], [tf.double, tf.int32])\n",
    "    # features.set_shape((None, 242,242,4))\n",
    "    # labels.set_shape(( 1))\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "6f8d3b08-b09b-480d-8d8d-bf44131c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Users/sentinel_industry/downloaded_aois/coal/'\n",
    "\n",
    "pkl_files = glob.glob((path+\"*.pickle\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "7def905d-f2c1-45f1-985c-aaf123860dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2238\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "f15f640f-7002-40d2-899a-21b4090c2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel = 'E:/Users/sentinel_industry/downloaded_aois/steel/'\n",
    "pkl_files_steel = glob.glob((path_steel+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "5e5a78e7-514d-4f65-a831-57faa0c5df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_steel_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/steel/no_ind/'\n",
    "pkl_files_steel_no_ind = glob.glob((path_steel_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "076b0a09-9866-4fee-a244-2bd75892bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_coal_no_ind = 'E:/Users/sentinel_industry/downloaded_aois/coal/no_ind/'\n",
    "pkl_files_coal_no_ind = glob.glob((path_coal_no_ind+\"*.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "da24ac7d-0f3f-4cfe-b518-fef29417d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files_steel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "af872199-9192-48eb-8cea-9693c2291fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_files = pkl_files + pkl_files_steel + pkl_files_steel_no_ind + pkl_files_coal_no_ind\n",
    "random.Random(42).shuffle(pkl_files)\n",
    "# pkl_files=pkl_files[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d113d42-c436-4a56-9965-7aab23dfec82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "cfe3ca4f-ca84-4d80-9218-95fc89e8fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "\n",
    "# pkl_files = list(chain.from_iterable(zip(pkl_files, pkl_files_steel)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "07182a88-11f4-4b7d-a461-4debb2944063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7966\n"
     ]
    }
   ],
   "source": [
    "print(len(pkl_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "dfc46d5e-854e-42c6-af9c-97123ce4b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len=len(pkl_files)\n",
    "\n",
    "train_size = int(np.floor(0.8 * dataset_len))\n",
    "valid_size = int(np.floor(0.2 * dataset_len))\n",
    "test_size = int(np.floor(0.0 * dataset_len))\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices(pkl_files[0:train_size]).map(data_loader,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "valid = tf.data.Dataset.from_tensor_slices(pkl_files[train_size:train_size+valid_size]).map(data_loader,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test = tf.data.Dataset.from_tensor_slices(pkl_files[train_size+valid_size:]).map(data_loader,num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8828791-0bcc-4d3e-8a77-b761868d9f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "21e3f5d5-620d-4e9d-8abb-ecee1ba2dac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((pkl_files))\n",
    "# dataset = dataset.map(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "adaadc4a-c328-4c33-b9b7-3d2e140f92bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "0aca244f-4f18-4f58-93e8-c1b5ba21451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.map((lambda x, y : (tf.tanh(x),y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# valid = valid.map((lambda x, y : (tf.tanh(x),y)), num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "59a1465e-61f0-4083-8df6-5ce331cbde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = tf.data.experimental.load('savedata_valid')\n",
    "train = tf.data.experimental.load('savedata_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "80f35197-11ee-40af-bc9c-c5181c99583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.shuffle(100,  reshuffle_each_iteration=True)\n",
    "# valid = valid.shuffle(100,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ac712-d2ef-43e7-bc46-cfda264dc190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "cb8f934b-2604-4cae-90e3-c805ebb2c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map((\n",
    "#   lambda x, y: (resize_and_rescale(x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "f31d628e-b02a-4e9a-b488-621dbd9c6f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 230, 4)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in dataset:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "d27b0ce3-1d0b-45b1-ae8b-2d93678fab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float64, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ff9eae1f-d440-48fc-901e-214c9956fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# norm_layer=keras.layers.Normalization(mean=[ch1_mean, ch2_mean, ch3_mean,ch4_mean], variance=[ch1_std**2, ch2_std**2, ch3_std**2, ch4_std**2], input_shape=(x_size,y_size,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "676ae2c1-03cd-42bf-b40d-fe2926f9f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seed = 42\n",
    "resize_rescale_augment = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.2, seed=in_seed, input_shape=(x_size,y_size,4)),  # here, maybe try larger values\n",
    "    layers.CenterCrop(140,140, ),\n",
    "    layers.RandomCrop(120,120, seed=in_seed, ),  # to be changed with centercrop for data augmentation/ use centre first, then random?\n",
    "    \n",
    "    # layers.Rescaling(1./10000),#,input_shape=(240,240,4)), # I think the data is scaled to 10000\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=in_seed), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "f3d2ec65-044d-4736-b6c9-f4921a6d7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     resize_rescale_augment,\n",
    "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(3)\n",
    "# ])\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale_augment,\n",
    "    layers.Conv2D(3, 5, padding='same', activation='softmax'), # this seems like a bit of a brute force approach to handing a 3 channel image to resnet, \n",
    "                                                            # maybe try changing the source so it accepts 4 channels?\n",
    "    tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None, # if I don't use the pre trained weights from image net, does it matter that i don't use the preprocessing step which reorders RGB to BGR and zero-centers wrt imagenet?\n",
    "        input_shape=(120, 120, 3),\n",
    "        pooling=None ,\n",
    "        classes=3,),\n",
    "    layers.Flatten(), # does this make sense? or is there another way to get down to just three output dimensions?\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "log_dir = \"E:/Users/sentinel_industry/logs/train/new/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '120,140')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.03)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "61a4893c-dc79-429a-9db4-07b6448b26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "080187fe-ffc5-4377-a03e-f9dedd1185e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_40 (Sequential)  (None, 120, 120, 4)       0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 120, 120, 3)       303       \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,594,162\n",
      "Trainable params: 23,541,042\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "5562cb60-b8d6-4768-8d53-b3b319dd6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "befec726-725f-4a3a-91cb-53edd07eb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !env LD_LIBRARY_PATH=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_LIBRARY_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# os.environ['LD_INCLUDE_PATH']=\"C:\\Anaconda3_64\\pkgs\\cudatoolkit-11.7.0-ha6f8bbd_10\\Library\\bin\"\n",
    "# # !set LD_INCLUDE_PATH=:/usr/local/cuda/include:/usr/local/cuda/extras/CUPTI/include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "bf8bd085-6960-4fd9-b181-a397dba92350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "env: â€˜LD_LIBRARY_PATHâ€™: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!env LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a9d77-970f-4a15-8b88-72e435b512de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "ac0f2df1-a1c4-4256-8207-c604ecb682a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22096), started 2 days, 1:46:10 ago. (Use '!kill 22096' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4a650354ab0a7952\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4a650354ab0a7952\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir='E:/Users/sentinel_industry/logs/train/new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "be530648-e9dc-4672-8686-9370d346b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n",
      "159/159 [==============================] - 106s 596ms/step - loss: 1.7092 - categorical_accuracy: 0.5914 - val_loss: 1.1657 - val_categorical_accuracy: 0.5300 - lr: 0.0010\n",
      "Epoch 2/105\n",
      "159/159 [==============================] - 92s 566ms/step - loss: 0.8863 - categorical_accuracy: 0.6775 - val_loss: 1.1099 - val_categorical_accuracy: 0.5275 - lr: 0.0010\n",
      "Epoch 3/105\n",
      "159/159 [==============================] - 91s 559ms/step - loss: 0.8568 - categorical_accuracy: 0.6923 - val_loss: 4.8077 - val_categorical_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 4/105\n",
      "159/159 [==============================] - 85s 523ms/step - loss: 0.7539 - categorical_accuracy: 0.7258 - val_loss: 0.5682 - val_categorical_accuracy: 0.7850 - lr: 0.0010\n",
      "Epoch 5/105\n",
      "159/159 [==============================] - 65s 393ms/step - loss: 0.6175 - categorical_accuracy: 0.7486 - val_loss: 2.3243 - val_categorical_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 6/105\n",
      "159/159 [==============================] - 64s 400ms/step - loss: 0.5930 - categorical_accuracy: 0.7605 - val_loss: 0.5866 - val_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 7/105\n",
      "159/159 [==============================] - 80s 491ms/step - loss: 0.6158 - categorical_accuracy: 0.7594 - val_loss: 0.6695 - val_categorical_accuracy: 0.7775 - lr: 0.0010\n",
      "Epoch 8/105\n",
      "159/159 [==============================] - 80s 490ms/step - loss: 0.5790 - categorical_accuracy: 0.7706 - val_loss: 0.5567 - val_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 9/105\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.9892 - categorical_accuracy: 0.7068 - val_loss: 228.6534 - val_categorical_accuracy: 0.5300 - lr: 0.0010\n",
      "Epoch 10/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.9011 - categorical_accuracy: 0.6888 - val_loss: 6.4479 - val_categorical_accuracy: 0.6625 - lr: 0.0010\n",
      "Epoch 11/105\n",
      "159/159 [==============================] - 64s 399ms/step - loss: 0.7022 - categorical_accuracy: 0.7272 - val_loss: 1.0081 - val_categorical_accuracy: 0.7300 - lr: 0.0010\n",
      "Epoch 12/105\n",
      "159/159 [==============================] - 64s 400ms/step - loss: 0.7889 - categorical_accuracy: 0.7159 - val_loss: 158.6949 - val_categorical_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 13/105\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.8318 - categorical_accuracy: 0.7162 - val_loss: 1.3384 - val_categorical_accuracy: 0.7100 - lr: 0.0010\n",
      "Epoch 14/105\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.6373 - categorical_accuracy: 0.7476 - val_loss: 0.5621 - val_categorical_accuracy: 0.7875 - lr: 0.0010\n",
      "Epoch 15/105\n",
      "159/159 [==============================] - 66s 408ms/step - loss: 0.6684 - categorical_accuracy: 0.7429 - val_loss: 0.7322 - val_categorical_accuracy: 0.7425 - lr: 0.0010\n",
      "Epoch 16/105\n",
      "159/159 [==============================] - 66s 409ms/step - loss: 0.8140 - categorical_accuracy: 0.6975 - val_loss: 1.0112 - val_categorical_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 17/105\n",
      "159/159 [==============================] - 66s 410ms/step - loss: 1.0978 - categorical_accuracy: 0.5822 - val_loss: 1.1722 - val_categorical_accuracy: 0.5825 - lr: 0.0010\n",
      "Epoch 18/105\n",
      "159/159 [==============================] - 67s 415ms/step - loss: 1.1822 - categorical_accuracy: 0.5712 - val_loss: 1.1079 - val_categorical_accuracy: 0.5600 - lr: 0.0010\n",
      "Epoch 19/105\n",
      "159/159 [==============================] - 66s 412ms/step - loss: 0.8916 - categorical_accuracy: 0.6434 - val_loss: 18.1793 - val_categorical_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 20/105\n",
      "159/159 [==============================] - 65s 407ms/step - loss: 0.9115 - categorical_accuracy: 0.6553 - val_loss: 13.7741 - val_categorical_accuracy: 0.5325 - lr: 0.0010\n",
      "Epoch 21/105\n",
      "159/159 [==============================] - 66s 407ms/step - loss: 0.9178 - categorical_accuracy: 0.6791 - val_loss: 2.4582 - val_categorical_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 22/105\n",
      "159/159 [==============================] - 65s 403ms/step - loss: 0.8955 - categorical_accuracy: 0.6939 - val_loss: 0.7468 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 23/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.8511 - categorical_accuracy: 0.7113 - val_loss: 1.1692 - val_categorical_accuracy: 0.7425 - lr: 0.0010\n",
      "Epoch 24/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.8482 - categorical_accuracy: 0.7153 - val_loss: 0.9386 - val_categorical_accuracy: 0.5550 - lr: 0.0010\n",
      "Epoch 25/105\n",
      "159/159 [==============================] - 65s 402ms/step - loss: 0.7647 - categorical_accuracy: 0.7058 - val_loss: 0.7004 - val_categorical_accuracy: 0.7050 - lr: 0.0010\n",
      "Epoch 26/105\n",
      "159/159 [==============================] - 65s 402ms/step - loss: 1.2034 - categorical_accuracy: 0.6248 - val_loss: 12.4878 - val_categorical_accuracy: 0.3725 - lr: 0.0010\n",
      "Epoch 27/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 1.0473 - categorical_accuracy: 0.6057 - val_loss: 25.8781 - val_categorical_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 28/105\n",
      "159/159 [==============================] - 66s 413ms/step - loss: 0.8803 - categorical_accuracy: 0.6753 - val_loss: 0.7590 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n",
      "Epoch 29/105\n",
      "159/159 [==============================] - 67s 416ms/step - loss: 0.7826 - categorical_accuracy: 0.7061 - val_loss: 0.6700 - val_categorical_accuracy: 0.7225 - lr: 0.0010\n",
      "Epoch 30/105\n",
      "159/159 [==============================] - 65s 406ms/step - loss: 0.7239 - categorical_accuracy: 0.7088 - val_loss: 0.6445 - val_categorical_accuracy: 0.7525 - lr: 0.0010\n",
      "Epoch 31/105\n",
      "159/159 [==============================] - 66s 406ms/step - loss: 0.7260 - categorical_accuracy: 0.7179 - val_loss: 1.2373 - val_categorical_accuracy: 0.7350 - lr: 9.5123e-04\n",
      "Epoch 32/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.6748 - categorical_accuracy: 0.7289 - val_loss: 0.6389 - val_categorical_accuracy: 0.7450 - lr: 9.0484e-04\n",
      "Epoch 33/105\n",
      "159/159 [==============================] - 65s 404ms/step - loss: 0.6675 - categorical_accuracy: 0.7313 - val_loss: 0.8642 - val_categorical_accuracy: 0.7950 - lr: 8.6071e-04\n",
      "Epoch 34/105\n",
      "159/159 [==============================] - 65s 404ms/step - loss: 0.6866 - categorical_accuracy: 0.7439 - val_loss: 0.6450 - val_categorical_accuracy: 0.7575 - lr: 8.1873e-04\n",
      "Epoch 35/105\n",
      "159/159 [==============================] - 65s 404ms/step - loss: 0.6693 - categorical_accuracy: 0.7481 - val_loss: 1.2778 - val_categorical_accuracy: 0.7525 - lr: 7.7880e-04\n",
      "Epoch 36/105\n",
      "159/159 [==============================] - 66s 412ms/step - loss: 0.6254 - categorical_accuracy: 0.7483 - val_loss: 0.5505 - val_categorical_accuracy: 0.7775 - lr: 7.4082e-04\n",
      "Epoch 37/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.6502 - categorical_accuracy: 0.7613 - val_loss: 0.5632 - val_categorical_accuracy: 0.7700 - lr: 7.0469e-04\n",
      "Epoch 38/105\n",
      "159/159 [==============================] - 65s 403ms/step - loss: 0.6071 - categorical_accuracy: 0.7593 - val_loss: 1.3637 - val_categorical_accuracy: 0.7300 - lr: 6.7032e-04\n",
      "Epoch 39/105\n",
      "159/159 [==============================] - 65s 403ms/step - loss: 0.5932 - categorical_accuracy: 0.7690 - val_loss: 0.5580 - val_categorical_accuracy: 0.7750 - lr: 6.3763e-04\n",
      "Epoch 40/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.5459 - categorical_accuracy: 0.7805 - val_loss: 0.6142 - val_categorical_accuracy: 0.7350 - lr: 6.0653e-04\n",
      "Epoch 41/105\n",
      "159/159 [==============================] - 65s 407ms/step - loss: 0.5447 - categorical_accuracy: 0.7833 - val_loss: 0.6076 - val_categorical_accuracy: 0.7300 - lr: 5.7695e-04\n",
      "Epoch 42/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.5489 - categorical_accuracy: 0.7835 - val_loss: 0.7278 - val_categorical_accuracy: 0.7850 - lr: 5.4881e-04\n",
      "Epoch 43/105\n",
      "159/159 [==============================] - 65s 403ms/step - loss: 0.5304 - categorical_accuracy: 0.7921 - val_loss: 0.5940 - val_categorical_accuracy: 0.7425 - lr: 5.2205e-04\n",
      "Epoch 44/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.5304 - categorical_accuracy: 0.7923 - val_loss: 0.7535 - val_categorical_accuracy: 0.6525 - lr: 4.9659e-04\n",
      "Epoch 45/105\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.5066 - categorical_accuracy: 0.7965 - val_loss: 0.5046 - val_categorical_accuracy: 0.7850 - lr: 4.7237e-04\n",
      "Epoch 46/105\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.4858 - categorical_accuracy: 0.7994 - val_loss: 0.4910 - val_categorical_accuracy: 0.7925 - lr: 4.4933e-04\n",
      "Epoch 47/105\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.4865 - categorical_accuracy: 0.8069 - val_loss: 0.5192 - val_categorical_accuracy: 0.7925 - lr: 4.2742e-04\n",
      "Epoch 48/105\n",
      "159/159 [==============================] - 63s 393ms/step - loss: 0.4938 - categorical_accuracy: 0.7995 - val_loss: 0.5429 - val_categorical_accuracy: 0.7850 - lr: 4.0657e-04\n",
      "Epoch 49/105\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.4690 - categorical_accuracy: 0.8042 - val_loss: 0.9201 - val_categorical_accuracy: 0.6700 - lr: 3.8674e-04\n",
      "Epoch 50/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.4694 - categorical_accuracy: 0.8126 - val_loss: 0.8909 - val_categorical_accuracy: 0.6650 - lr: 3.6788e-04\n",
      "Epoch 51/105\n",
      "159/159 [==============================] - 65s 407ms/step - loss: 0.4723 - categorical_accuracy: 0.8118 - val_loss: 0.7098 - val_categorical_accuracy: 0.7275 - lr: 3.4994e-04\n",
      "Epoch 52/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.4646 - categorical_accuracy: 0.8097 - val_loss: 0.4953 - val_categorical_accuracy: 0.8075 - lr: 3.3287e-04\n",
      "Epoch 53/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.4612 - categorical_accuracy: 0.8201 - val_loss: 0.4912 - val_categorical_accuracy: 0.8075 - lr: 3.1664e-04\n",
      "Epoch 54/105\n",
      "159/159 [==============================] - 65s 407ms/step - loss: 0.4382 - categorical_accuracy: 0.8237 - val_loss: 0.5132 - val_categorical_accuracy: 0.7950 - lr: 3.0119e-04\n",
      "Epoch 55/105\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.4460 - categorical_accuracy: 0.8266 - val_loss: 0.5698 - val_categorical_accuracy: 0.7700 - lr: 2.8651e-04\n",
      "Epoch 56/105\n",
      "159/159 [==============================] - 63s 391ms/step - loss: 0.4220 - categorical_accuracy: 0.8285 - val_loss: 0.6934 - val_categorical_accuracy: 0.7000 - lr: 2.7253e-04\n",
      "Epoch 57/105\n",
      "159/159 [==============================] - 65s 402ms/step - loss: 0.4352 - categorical_accuracy: 0.8297 - val_loss: 0.8660 - val_categorical_accuracy: 0.8000 - lr: 2.5924e-04\n",
      "Epoch 58/105\n",
      "159/159 [==============================] - 66s 410ms/step - loss: 0.4330 - categorical_accuracy: 0.8329 - val_loss: 0.4674 - val_categorical_accuracy: 0.8100 - lr: 2.4660e-04\n",
      "Epoch 59/105\n",
      "159/159 [==============================] - 65s 403ms/step - loss: 0.4055 - categorical_accuracy: 0.8406 - val_loss: 0.4729 - val_categorical_accuracy: 0.8075 - lr: 2.3457e-04\n",
      "Epoch 60/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.4156 - categorical_accuracy: 0.8310 - val_loss: 0.4779 - val_categorical_accuracy: 0.8050 - lr: 2.2313e-04\n",
      "Epoch 61/105\n",
      "159/159 [==============================] - 66s 409ms/step - loss: 0.4107 - categorical_accuracy: 0.8366 - val_loss: 0.5329 - val_categorical_accuracy: 0.7875 - lr: 2.1225e-04\n",
      "Epoch 62/105\n",
      "159/159 [==============================] - 64s 397ms/step - loss: 0.4015 - categorical_accuracy: 0.8437 - val_loss: 0.4525 - val_categorical_accuracy: 0.8250 - lr: 2.0190e-04\n",
      "Epoch 63/105\n",
      "159/159 [==============================] - 65s 402ms/step - loss: 0.4036 - categorical_accuracy: 0.8434 - val_loss: 0.4380 - val_categorical_accuracy: 0.8325 - lr: 1.9205e-04\n",
      "Epoch 64/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 0.3809 - categorical_accuracy: 0.8465 - val_loss: 0.4456 - val_categorical_accuracy: 0.8350 - lr: 1.8268e-04\n",
      "Epoch 65/105\n",
      "159/159 [==============================] - 64s 400ms/step - loss: 0.3879 - categorical_accuracy: 0.8436 - val_loss: 0.4251 - val_categorical_accuracy: 0.8500 - lr: 1.7377e-04\n",
      "Epoch 66/105\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.3729 - categorical_accuracy: 0.8494 - val_loss: 0.4526 - val_categorical_accuracy: 0.8425 - lr: 1.6530e-04\n",
      "Epoch 67/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.3704 - categorical_accuracy: 0.8535 - val_loss: 0.4178 - val_categorical_accuracy: 0.8525 - lr: 1.5724e-04\n",
      "Epoch 68/105\n",
      "159/159 [==============================] - 64s 399ms/step - loss: 0.3672 - categorical_accuracy: 0.8506 - val_loss: 0.4367 - val_categorical_accuracy: 0.8325 - lr: 1.4957e-04\n",
      "Epoch 69/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 0.3721 - categorical_accuracy: 0.8524 - val_loss: 0.4227 - val_categorical_accuracy: 0.8650 - lr: 1.4227e-04\n",
      "Epoch 70/105\n",
      "159/159 [==============================] - 64s 400ms/step - loss: 0.3619 - categorical_accuracy: 0.8563 - val_loss: 0.4558 - val_categorical_accuracy: 0.8325 - lr: 1.3534e-04\n",
      "Epoch 71/105\n",
      "159/159 [==============================] - 64s 397ms/step - loss: 0.3622 - categorical_accuracy: 0.8541 - val_loss: 0.4134 - val_categorical_accuracy: 0.8525 - lr: 1.2874e-04\n",
      "Epoch 72/105\n",
      "159/159 [==============================] - 65s 405ms/step - loss: 0.3512 - categorical_accuracy: 0.8621 - val_loss: 0.4533 - val_categorical_accuracy: 0.8350 - lr: 1.2246e-04\n",
      "Epoch 73/105\n",
      "159/159 [==============================] - 64s 399ms/step - loss: 0.3455 - categorical_accuracy: 0.8619 - val_loss: 0.4313 - val_categorical_accuracy: 0.8475 - lr: 1.1648e-04\n",
      "Epoch 74/105\n",
      "159/159 [==============================] - 64s 400ms/step - loss: 0.3555 - categorical_accuracy: 0.8613 - val_loss: 0.4188 - val_categorical_accuracy: 0.8625 - lr: 1.1080e-04\n",
      "Epoch 75/105\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.3385 - categorical_accuracy: 0.8665 - val_loss: 0.4229 - val_categorical_accuracy: 0.8550 - lr: 1.0540e-04\n",
      "Epoch 76/105\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.3383 - categorical_accuracy: 0.8681 - val_loss: 0.4341 - val_categorical_accuracy: 0.8500 - lr: 1.0026e-04\n",
      "Epoch 77/105\n",
      "159/159 [==============================] - 64s 395ms/step - loss: 0.3370 - categorical_accuracy: 0.8662 - val_loss: 0.4033 - val_categorical_accuracy: 0.8650 - lr: 9.5369e-05\n",
      "Epoch 78/105\n",
      "159/159 [==============================] - 62s 386ms/step - loss: 0.3382 - categorical_accuracy: 0.8687 - val_loss: 0.4153 - val_categorical_accuracy: 0.8575 - lr: 9.0718e-05\n",
      "Epoch 79/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 0.3293 - categorical_accuracy: 0.8692 - val_loss: 0.4316 - val_categorical_accuracy: 0.8500 - lr: 8.6294e-05\n",
      "Epoch 80/105\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.3351 - categorical_accuracy: 0.8704 - val_loss: 0.4762 - val_categorical_accuracy: 0.8325 - lr: 8.2085e-05\n",
      "Epoch 81/105\n",
      "159/159 [==============================] - 64s 397ms/step - loss: 0.3292 - categorical_accuracy: 0.8684 - val_loss: 0.4418 - val_categorical_accuracy: 0.8450 - lr: 7.8082e-05\n",
      "Epoch 82/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 0.3268 - categorical_accuracy: 0.8748 - val_loss: 0.4077 - val_categorical_accuracy: 0.8675 - lr: 7.4274e-05\n",
      "Epoch 83/105\n",
      "159/159 [==============================] - 63s 394ms/step - loss: 0.3214 - categorical_accuracy: 0.8792 - val_loss: 0.4041 - val_categorical_accuracy: 0.8575 - lr: 7.0651e-05\n",
      "Epoch 84/105\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.3230 - categorical_accuracy: 0.8756 - val_loss: 0.4112 - val_categorical_accuracy: 0.8625 - lr: 6.7206e-05\n",
      "Epoch 85/105\n",
      "159/159 [==============================] - 64s 399ms/step - loss: 0.3157 - categorical_accuracy: 0.8763 - val_loss: 0.4444 - val_categorical_accuracy: 0.8350 - lr: 6.3928e-05\n",
      "Epoch 86/105\n",
      "159/159 [==============================] - 65s 406ms/step - loss: 0.3169 - categorical_accuracy: 0.8744 - val_loss: 0.4079 - val_categorical_accuracy: 0.8625 - lr: 6.0810e-05\n",
      "Epoch 87/105\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.3153 - categorical_accuracy: 0.8796 - val_loss: 0.4184 - val_categorical_accuracy: 0.8550 - lr: 5.7844e-05\n",
      "Epoch 88/105\n",
      "159/159 [==============================] - 63s 392ms/step - loss: 0.3048 - categorical_accuracy: 0.8827 - val_loss: 0.6194 - val_categorical_accuracy: 0.8525 - lr: 5.5023e-05\n",
      "Epoch 89/105\n",
      "159/159 [==============================] - 65s 404ms/step - loss: 0.3072 - categorical_accuracy: 0.8770 - val_loss: 0.4067 - val_categorical_accuracy: 0.8525 - lr: 5.2340e-05\n",
      "Epoch 90/105\n",
      "159/159 [==============================] - 65s 401ms/step - loss: 0.3079 - categorical_accuracy: 0.8799 - val_loss: 0.4047 - val_categorical_accuracy: 0.8700 - lr: 4.9787e-05\n",
      "Epoch 91/105\n",
      "159/159 [==============================] - 66s 409ms/step - loss: 0.3027 - categorical_accuracy: 0.8832 - val_loss: 0.4613 - val_categorical_accuracy: 0.8625 - lr: 4.7359e-05\n",
      "Epoch 92/105\n",
      "159/159 [==============================] - 63s 395ms/step - loss: 0.3023 - categorical_accuracy: 0.8799 - val_loss: 0.4154 - val_categorical_accuracy: 0.8625 - lr: 4.5049e-05\n",
      "Epoch 93/105\n",
      "159/159 [==============================] - 64s 396ms/step - loss: 0.3014 - categorical_accuracy: 0.8863 - val_loss: 0.3970 - val_categorical_accuracy: 0.8625 - lr: 4.2852e-05\n",
      "Epoch 94/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.3053 - categorical_accuracy: 0.8802 - val_loss: 0.5431 - val_categorical_accuracy: 0.8700 - lr: 4.0762e-05\n",
      "Epoch 95/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.2897 - categorical_accuracy: 0.8858 - val_loss: 0.5558 - val_categorical_accuracy: 0.8475 - lr: 3.8774e-05\n",
      "Epoch 96/105\n",
      "159/159 [==============================] - 65s 402ms/step - loss: 0.2948 - categorical_accuracy: 0.8803 - val_loss: 0.5057 - val_categorical_accuracy: 0.8550 - lr: 3.6883e-05\n",
      "Epoch 97/105\n",
      "159/159 [==============================] - 65s 402ms/step - loss: 0.2858 - categorical_accuracy: 0.8888 - val_loss: 0.4801 - val_categorical_accuracy: 0.8550 - lr: 3.5084e-05\n",
      "Epoch 98/105\n",
      "159/159 [==============================] - 65s 404ms/step - loss: 0.2906 - categorical_accuracy: 0.8829 - val_loss: 0.4876 - val_categorical_accuracy: 0.8675 - lr: 3.3373e-05\n",
      "Epoch 99/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.2903 - categorical_accuracy: 0.8917 - val_loss: 0.4960 - val_categorical_accuracy: 0.8500 - lr: 3.1746e-05\n",
      "Epoch 100/105\n",
      "159/159 [==============================] - 64s 400ms/step - loss: 0.2895 - categorical_accuracy: 0.8844 - val_loss: 0.4591 - val_categorical_accuracy: 0.8625 - lr: 3.0197e-05\n",
      "Epoch 101/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 0.2835 - categorical_accuracy: 0.8901 - val_loss: 0.5504 - val_categorical_accuracy: 0.8425 - lr: 2.8725e-05\n",
      "Epoch 102/105\n",
      "159/159 [==============================] - 64s 399ms/step - loss: 0.2942 - categorical_accuracy: 0.8869 - val_loss: 0.5143 - val_categorical_accuracy: 0.8600 - lr: 2.7324e-05\n",
      "Epoch 103/105\n",
      "159/159 [==============================] - 64s 398ms/step - loss: 0.2896 - categorical_accuracy: 0.8862 - val_loss: 0.5153 - val_categorical_accuracy: 0.8600 - lr: 2.5991e-05\n",
      "Epoch 104/105\n",
      "159/159 [==============================] - 64s 401ms/step - loss: 0.2847 - categorical_accuracy: 0.8881 - val_loss: 0.4004 - val_categorical_accuracy: 0.8625 - lr: 2.4724e-05\n",
      "Epoch 105/105\n",
      "159/159 [==============================] - 64s 399ms/step - loss: 0.2828 - categorical_accuracy: 0.8914 - val_loss: 0.4187 - val_categorical_accuracy: 0.8650 - lr: 2.3518e-05\n"
     ]
    }
   ],
   "source": [
    "# now with normalisation\n",
    "epochs=105\n",
    "batch_size = 40\n",
    "history = model.fit(\n",
    "    train.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_data=valid.batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE),\n",
    "    validation_steps=10,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb171cdb-c5d8-4f7d-b778-18aa7efc08bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e5265-142f-4b61-ab38-2cab5289760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90470b-a402-4948-9fe4-f57618c7d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=tf.compat.v1.data.make_one_shot_iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d64b-2ba7-4826-b54b-3d641f741a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    next_element = iterator.get_next()\n",
    "    im = resize_rescale_augment(next_element[0])\n",
    "    plt.imshow(np.flip(im[0,:,:,0:3], axis=2))\n",
    "    plt.title(convert_onehot(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21253b84-bc80-4976-8816-b49dee2293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onehot(next_element):\n",
    "    if (next_element[1].numpy() == np.array([0, 0, 1])).all(): return 'no industry'\n",
    "    elif (next_element[1].numpy() == np.array([0, 1, 0])).all(): return 'steel'\n",
    "    elif (next_element[1].numpy() == np.array([1, 0, 0])).all(): return 'coal'\n",
    "    else: return 'not valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f89dc-23ea-4317-a8ff-376357f954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_element[1].numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372a01e-8e19-45ee-a7fc-0a5540f19f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/path/to/file.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = foo\n",
    "spec.loader.exec_module(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6827d1-167e-47c0-ae4c-441f24174694",
   "metadata": {},
   "outputs": [],
   "source": [
    "! PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311393-972b-421b-b164-3f62c9effb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
